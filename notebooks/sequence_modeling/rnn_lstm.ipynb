{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4：RNN / LSTM / GRU 與序列資料\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解為什麼需要專門處理序列資料的模型\n",
    "2. 掌握 RNN 的基本結構與梯度消失問題\n",
    "3. 理解 LSTM 和 GRU 如何解決長期依賴問題\n",
    "4. 學會處理文字資料：tokenization, embedding\n",
    "5. 實作：情感分析、字元級語言模型\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "import random\n",
    "\n",
    "# 設定\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1：為什麼需要序列模型？\n",
    "\n",
    "### 1.1 序列資料的特性\n",
    "\n",
    "很多資料天生就是「有順序」的：\n",
    "- **文字**：「我愛你」和「你愛我」意思完全不同\n",
    "- **語音**：聲音訊號是時間序列\n",
    "- **股價**：今天的價格跟昨天有關\n",
    "- **影片**：連續的影格\n",
    "\n",
    "### 1.2 MLP/CNN 處理序列的問題\n",
    "\n",
    "1. **固定長度輸入**：句子長度不一，怎麼辦？\n",
    "2. **沒有位置概念**：打亂順序結果一樣\n",
    "3. **無法共享時間步的學習**：每個位置要獨立學習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 序列資料的例子\n",
    "\n",
    "print(\"序列資料的例子：\")\n",
    "print(\"\")\n",
    "print(\"1. 文字序列：\")\n",
    "print(\"   '今天天氣真好' -> ['今', '天', '天', '氣', '真', '好']\")\n",
    "print(\"   'I love deep learning' -> ['I', 'love', 'deep', 'learning']\")\n",
    "print(\"\")\n",
    "print(\"2. 時間序列：\")\n",
    "print(\"   股價: [100, 102, 99, 105, 103, ...]\")\n",
    "print(\"   溫度: [20.5, 21.0, 22.3, 21.8, ...]\")\n",
    "print(\"\")\n",
    "print(\"3. 序列標註：\")\n",
    "print(\"   詞性標註: ['I/PRP', 'love/VBP', 'dogs/NNS']\")\n",
    "print(\"   命名實體: ['[PER]John', 'works', 'at', '[ORG]Google']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2：循環神經網路 (RNN)\n",
    "\n",
    "### 2.1 RNN 的核心思想\n",
    "\n",
    "**讓網路有「記憶」**：把前一時刻的隱藏狀態傳給下一時刻\n",
    "\n",
    "```\n",
    "    h₀ ──→ h₁ ──→ h₂ ──→ h₃ ──→ h₄\n",
    "    ↑      ↑      ↑      ↑      ↑\n",
    "    x₀     x₁     x₂     x₃     x₄\n",
    "    \n",
    "    hₜ = tanh(Wₕₕ·hₜ₋₁ + Wₓₕ·xₜ + b)\n",
    "```\n",
    "\n",
    "**關鍵：** 同一組權重 (Wₕₕ, Wₓₕ) 在所有時間步共享！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手動實現簡單的 RNN\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    \"\"\"最簡單的 RNN 實現\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 權重矩陣\n",
    "        self.W_xh = nn.Linear(input_size, hidden_size)   # 輸入到隱藏\n",
    "        self.W_hh = nn.Linear(hidden_size, hidden_size)  # 隱藏到隱藏\n",
    "    \n",
    "    def forward(self, x, h_prev=None):\n",
    "        \"\"\"\n",
    "        x: (batch, seq_len, input_size)\n",
    "        h_prev: (batch, hidden_size) 或 None\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "        \n",
    "        # 初始化隱藏狀態\n",
    "        if h_prev is None:\n",
    "            h_prev = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        \n",
    "        # 儲存每個時間步的隱藏狀態\n",
    "        outputs = []\n",
    "        h = h_prev\n",
    "        \n",
    "        # 對每個時間步\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]  # 取出時間步 t 的輸入\n",
    "            h = torch.tanh(self.W_xh(x_t) + self.W_hh(h))\n",
    "            outputs.append(h)\n",
    "        \n",
    "        # 堆疊所有時間步的輸出\n",
    "        outputs = torch.stack(outputs, dim=1)  # (batch, seq_len, hidden)\n",
    "        \n",
    "        return outputs, h\n",
    "\n",
    "# 測試\n",
    "rnn = SimpleRNN(input_size=10, hidden_size=20)\n",
    "x = torch.randn(2, 5, 10)  # batch=2, seq_len=5, input=10\n",
    "outputs, h_final = rnn(x)\n",
    "\n",
    "print(f\"輸入 shape: {x.shape}\")\n",
    "print(f\"所有時間步的輸出 shape: {outputs.shape}\")\n",
    "print(f\"最終隱藏狀態 shape: {h_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 PyTorch 內建的 RNN\n",
    "\n",
    "rnn_pytorch = nn.RNN(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=1,\n",
    "    batch_first=True  # 輸入格式 (batch, seq, feature)\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 5, 10)\n",
    "outputs, h_n = rnn_pytorch(x)\n",
    "\n",
    "print(f\"PyTorch RNN 輸出 shape: {outputs.shape}\")\n",
    "print(f\"PyTorch RNN h_n shape: {h_n.shape}\")\n",
    "\n",
    "# 注意：h_n 的 shape 是 (num_layers, batch, hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 RNN 的梯度消失問題\n",
    "\n",
    "**問題：** 當序列很長時，早期時間步的梯度會「消失」\n",
    "\n",
    "**原因：** 反向傳播時，梯度要乘以 Wₕₕ 很多次\n",
    "- 如果 |Wₕₕ| < 1：梯度越乘越小（消失）\n",
    "- 如果 |Wₕₕ| > 1：梯度越乘越大（爆炸）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度消失視覺化\n",
    "\n",
    "def simulate_gradient_flow(weight_magnitude, seq_length):\n",
    "    \"\"\"模擬梯度在時間上的傳播\"\"\"\n",
    "    gradients = [1.0]  # 從最後一層開始，梯度為 1\n",
    "    for t in range(seq_length):\n",
    "        gradients.append(gradients[-1] * weight_magnitude)\n",
    "    return gradients[::-1]  # 反轉，讓 t=0 在前面\n",
    "\n",
    "seq_length = 50\n",
    "weight_magnitudes = [0.5, 0.9, 1.0, 1.1]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "for w in weight_magnitudes:\n",
    "    grads = simulate_gradient_flow(w, seq_length)\n",
    "    plt.plot(grads, label=f'|W| = {w}')\n",
    "\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Relative Gradient Magnitude')\n",
    "plt.title('Gradient Flow Through Time in RNN')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"觀察：\")\n",
    "print(\"- |W| < 1：梯度指數衰減（消失）\")\n",
    "print(\"- |W| > 1：梯度指數增長（爆炸）\")\n",
    "print(\"- |W| = 1：理想情況，但實際很難達到\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3：LSTM (Long Short-Term Memory)\n",
    "\n",
    "### 3.1 LSTM 的核心思想\n",
    "\n",
    "**解決方案：** 引入「門控機制」(Gates) 來控制資訊流\n",
    "\n",
    "LSTM 有三個門和一個細胞狀態 (cell state)：\n",
    "\n",
    "1. **遺忘門 (Forget Gate)**：決定要「忘記」多少舊資訊\n",
    "2. **輸入門 (Input Gate)**：決定要「記住」多少新資訊\n",
    "3. **輸出門 (Output Gate)**：決定要「輸出」多少資訊\n",
    "4. **細胞狀態 (Cell State)**：像一條「傳送帶」，讓資訊可以長距離流動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 結構圖解\n",
    "\n",
    "print(\"\"\"\n",
    "LSTM Cell 結構：\n",
    "\n",
    "                    ┌──────────────────────────────────────────┐\n",
    "                    │           Cell State (Cₜ₋₁ → Cₜ)         │\n",
    "                    │  ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━  │\n",
    "                    │        ↑           ↑           ↓        │\n",
    "                    │       ×           +           ×         │\n",
    "                    │        ↑           ↑           ↓        │\n",
    "                    │    ┌───────┐   ┌───────┐   ┌───────┐   │\n",
    "                    │    │Forget │   │ Input │   │Output │   │\n",
    "                    │    │ Gate  │   │ Gate  │   │ Gate  │   │\n",
    "                    │    │  fₜ   │   │  iₜ   │   │  oₜ   │   │\n",
    "                    │    └───┬───┘   └───┬───┘   └───┬───┘   │\n",
    "                    │        │           │           │        │\n",
    "                    │        └───────────┼───────────┘        │\n",
    "                    │                    │                    │\n",
    "                    │              [hₜ₋₁, xₜ]                 │\n",
    "                    │                    ↑                    │\n",
    "                    └────────────────────┼────────────────────┘\n",
    "                                         │\n",
    "                              xₜ ────────┴──────── hₜ₋₁\n",
    "\n",
    "公式：\n",
    "  fₜ = σ(Wf·[hₜ₋₁, xₜ] + bf)     # 遺忘門\n",
    "  iₜ = σ(Wi·[hₜ₋₁, xₜ] + bi)     # 輸入門  \n",
    "  C̃ₜ = tanh(Wc·[hₜ₋₁, xₜ] + bc)  # 候選細胞狀態\n",
    "  Cₜ = fₜ × Cₜ₋₁ + iₜ × C̃ₜ       # 新細胞狀態\n",
    "  oₜ = σ(Wo·[hₜ₋₁, xₜ] + bo)     # 輸出門\n",
    "  hₜ = oₜ × tanh(Cₜ)             # 隱藏狀態\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手動實現 LSTM Cell\n",
    "\n",
    "class LSTMCell(nn.Module):\n",
    "    \"\"\"手動實現的 LSTM Cell\"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # 四個門的權重（合併成一個大矩陣更高效）\n",
    "        self.gates = nn.Linear(input_size + hidden_size, 4 * hidden_size)\n",
    "    \n",
    "    def forward(self, x, states):\n",
    "        \"\"\"\n",
    "        x: (batch, input_size)\n",
    "        states: (h, c) 各為 (batch, hidden_size)\n",
    "        \"\"\"\n",
    "        h_prev, c_prev = states\n",
    "        \n",
    "        # 合併輸入和前一個隱藏狀態\n",
    "        combined = torch.cat([x, h_prev], dim=1)\n",
    "        \n",
    "        # 計算四個門（一次算完更高效）\n",
    "        gates = self.gates(combined)\n",
    "        \n",
    "        # 分割成四個部分\n",
    "        i, f, g, o = gates.chunk(4, dim=1)\n",
    "        \n",
    "        # 應用激活函數\n",
    "        i = torch.sigmoid(i)  # 輸入門\n",
    "        f = torch.sigmoid(f)  # 遺忘門\n",
    "        g = torch.tanh(g)     # 候選細胞狀態\n",
    "        o = torch.sigmoid(o)  # 輸出門\n",
    "        \n",
    "        # 更新細胞狀態\n",
    "        c = f * c_prev + i * g\n",
    "        \n",
    "        # 計算隱藏狀態\n",
    "        h = o * torch.tanh(c)\n",
    "        \n",
    "        return h, (h, c)\n",
    "\n",
    "# 測試\n",
    "cell = LSTMCell(input_size=10, hidden_size=20)\n",
    "x = torch.randn(2, 10)  # batch=2, input=10\n",
    "h = torch.zeros(2, 20)\n",
    "c = torch.zeros(2, 20)\n",
    "\n",
    "h_new, (h_out, c_out) = cell(x, (h, c))\n",
    "print(f\"輸入 shape: {x.shape}\")\n",
    "print(f\"新的 h shape: {h_out.shape}\")\n",
    "print(f\"新的 c shape: {c_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 PyTorch 的 LSTM\n",
    "\n",
    "lstm = nn.LSTM(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=2,       # 堆疊 2 層 LSTM\n",
    "    batch_first=True,\n",
    "    dropout=0.2,        # 層間 dropout\n",
    "    bidirectional=False # 單向\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 5, 10)  # (batch, seq_len, input_size)\n",
    "outputs, (h_n, c_n) = lstm(x)\n",
    "\n",
    "print(f\"輸入 shape: {x.shape}\")\n",
    "print(f\"輸出 shape: {outputs.shape}\")\n",
    "print(f\"h_n shape: {h_n.shape}  # (num_layers, batch, hidden)\")\n",
    "print(f\"c_n shape: {c_n.shape}  # (num_layers, batch, hidden)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LSTM 為什麼能解決梯度消失？\n",
    "\n",
    "**關鍵：** Cell State 的更新是**加法**，不是乘法！\n",
    "\n",
    "$$C_t = f_t \\times C_{t-1} + i_t \\times \\tilde{C}_t$$\n",
    "\n",
    "- 當 $f_t \\approx 1$（不忘記）時，$C_{t-1}$ 幾乎原封不動地傳遞\n",
    "- 梯度可以沿著 Cell State 這條「高速公路」直接流回早期時間步"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4：GRU (Gated Recurrent Unit)\n",
    "\n",
    "### 4.1 GRU 的結構\n",
    "\n",
    "GRU 是 LSTM 的簡化版，只有兩個門：\n",
    "\n",
    "1. **重置門 (Reset Gate)**：決定要忽略多少過去的資訊\n",
    "2. **更新門 (Update Gate)**：決定要保留多少過去的資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU 結構圖解\n",
    "\n",
    "print(\"\"\"\n",
    "GRU Cell 結構：\n",
    "\n",
    "公式：\n",
    "  rₜ = σ(Wr·[hₜ₋₁, xₜ])           # 重置門\n",
    "  zₜ = σ(Wz·[hₜ₋₁, xₜ])           # 更新門\n",
    "  h̃ₜ = tanh(W·[rₜ × hₜ₋₁, xₜ])    # 候選隱藏狀態\n",
    "  hₜ = (1 - zₜ) × hₜ₋₁ + zₜ × h̃ₜ  # 新隱藏狀態\n",
    "\n",
    "比較：\n",
    "┌─────────────┬─────────────┬─────────────┐\n",
    "│             │    LSTM     │     GRU     │\n",
    "├─────────────┼─────────────┼─────────────┤\n",
    "│ 門的數量    │      3      │      2      │\n",
    "│ 狀態數量    │   2 (h, c)  │   1 (h)     │\n",
    "│ 參數量      │     較多    │    較少     │\n",
    "│ 計算速度    │     較慢    │    較快     │\n",
    "│ 效果        │   通常較好  │   差不多    │\n",
    "└─────────────┴─────────────┴─────────────┘\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 PyTorch 的 GRU\n",
    "\n",
    "gru = nn.GRU(\n",
    "    input_size=10,\n",
    "    hidden_size=20,\n",
    "    num_layers=2,\n",
    "    batch_first=True,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "x = torch.randn(2, 5, 10)\n",
    "outputs, h_n = gru(x)\n",
    "\n",
    "print(f\"GRU 輸出 shape: {outputs.shape}\")\n",
    "print(f\"GRU h_n shape: {h_n.shape}\")\n",
    "print(\"\\n注意：GRU 只有 h_n，沒有 c_n（因為沒有 cell state）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5：文字資料處理\n",
    "\n",
    "### 5.1 Tokenization\n",
    "\n",
    "把文字轉成數字的過程：\n",
    "1. **字元級 (Character-level)**：每個字元一個 token\n",
    "2. **詞級 (Word-level)**：每個詞一個 token\n",
    "3. **子詞級 (Subword-level)**：BPE, WordPiece 等（Transformer 常用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡單的詞級 tokenization\n",
    "\n",
    "class SimpleTokenizer:\n",
    "    \"\"\"簡單的詞級分詞器\"\"\"\n",
    "    def __init__(self):\n",
    "        self.word2idx = {'<PAD>': 0, '<UNK>': 1}\n",
    "        self.idx2word = {0: '<PAD>', 1: '<UNK>'}\n",
    "        self.vocab_size = 2\n",
    "    \n",
    "    def build_vocab(self, texts, min_freq=1):\n",
    "        \"\"\"建立詞彙表\"\"\"\n",
    "        counter = Counter()\n",
    "        for text in texts:\n",
    "            words = text.lower().split()\n",
    "            counter.update(words)\n",
    "        \n",
    "        for word, freq in counter.items():\n",
    "            if freq >= min_freq and word not in self.word2idx:\n",
    "                idx = len(self.word2idx)\n",
    "                self.word2idx[word] = idx\n",
    "                self.idx2word[idx] = word\n",
    "        \n",
    "        self.vocab_size = len(self.word2idx)\n",
    "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
    "    \n",
    "    def encode(self, text):\n",
    "        \"\"\"把文字轉成數字\"\"\"\n",
    "        words = text.lower().split()\n",
    "        return [self.word2idx.get(w, self.word2idx['<UNK>']) for w in words]\n",
    "    \n",
    "    def decode(self, indices):\n",
    "        \"\"\"把數字轉回文字\"\"\"\n",
    "        return ' '.join([self.idx2word.get(i, '<UNK>') for i in indices])\n",
    "\n",
    "# 測試\n",
    "texts = [\n",
    "    \"I love deep learning\",\n",
    "    \"Deep learning is amazing\",\n",
    "    \"I enjoy studying neural networks\"\n",
    "]\n",
    "\n",
    "tokenizer = SimpleTokenizer()\n",
    "tokenizer.build_vocab(texts)\n",
    "\n",
    "test_text = \"I love neural networks\"\n",
    "encoded = tokenizer.encode(test_text)\n",
    "decoded = tokenizer.decode(encoded)\n",
    "\n",
    "print(f\"\\n原文: {test_text}\")\n",
    "print(f\"編碼: {encoded}\")\n",
    "print(f\"解碼: {decoded}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Word Embedding\n",
    "\n",
    "**問題：** 詞彙表中的索引是無意義的數字，無法表達詞與詞之間的關係\n",
    "\n",
    "**解決方案：** 把每個詞映射到一個**稠密向量** (dense vector)\n",
    "\n",
    "- 相似的詞會有相似的向量\n",
    "- Embedding 可以是隨機初始化後訓練，或使用預訓練的（如 Word2Vec, GloVe）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding 層\n",
    "\n",
    "vocab_size = 100   # 詞彙表大小\n",
    "embed_dim = 32     # 嵌入維度\n",
    "\n",
    "embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "\n",
    "# 輸入是詞的索引\n",
    "word_indices = torch.tensor([[1, 2, 3, 4],\n",
    "                              [5, 6, 7, 0]])  # batch=2, seq_len=4\n",
    "\n",
    "# 輸出是對應的嵌入向量\n",
    "word_vectors = embedding(word_indices)\n",
    "\n",
    "print(f\"輸入 (詞索引) shape: {word_indices.shape}\")\n",
    "print(f\"輸出 (詞向量) shape: {word_vectors.shape}\")\n",
    "print(f\"\\nEmbedding 權重 shape: {embedding.weight.shape}\")\n",
    "print(\"  = (vocab_size, embed_dim)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding + LSTM 的完整流程\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    \"\"\"簡單的文本分類模型\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)  # *2 因為雙向\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len) - 詞索引\n",
    "        \n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)\n",
    "        # lstm_out: (batch, seq_len, hidden*2)\n",
    "        # h_n: (2, batch, hidden) - 雙向所以是 2\n",
    "        \n",
    "        # 取最後一個時間步的輸出（或可以用 h_n）\n",
    "        # 雙向 LSTM：拼接正向最後和反向最後\n",
    "        hidden = torch.cat([h_n[-2], h_n[-1]], dim=1)  # (batch, hidden*2)\n",
    "        \n",
    "        # 分類\n",
    "        out = self.fc(self.dropout(hidden))\n",
    "        \n",
    "        return out\n",
    "\n",
    "# 測試\n",
    "model = TextClassifier(vocab_size=1000, embed_dim=128, hidden_dim=64, num_classes=2)\n",
    "x = torch.randint(0, 1000, (4, 20))  # batch=4, seq_len=20\n",
    "out = model(x)\n",
    "\n",
    "print(f\"輸入 shape: {x.shape}\")\n",
    "print(f\"輸出 shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 處理變長序列\n",
    "\n",
    "**問題：** 不同句子長度不同，怎麼組成 batch？\n",
    "\n",
    "**解決方案：**\n",
    "1. **Padding**：用 0 填充到相同長度\n",
    "2. **Pack/Pad**：PyTorch 的 `pack_padded_sequence` 讓 LSTM 忽略 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理變長序列\n",
    "\n",
    "# 三個不同長度的序列\n",
    "seq1 = torch.tensor([1, 2, 3, 4, 5])      # 長度 5\n",
    "seq2 = torch.tensor([6, 7, 8])            # 長度 3\n",
    "seq3 = torch.tensor([9, 10, 11, 12])      # 長度 4\n",
    "\n",
    "sequences = [seq1, seq2, seq3]\n",
    "lengths = torch.tensor([len(s) for s in sequences])\n",
    "\n",
    "# Padding\n",
    "padded = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
    "print(f\"Padded sequences:\\n{padded}\")\n",
    "print(f\"Lengths: {lengths}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 pack_padded_sequence\n",
    "\n",
    "# 注意：需要先按長度排序（降序）\n",
    "lengths_sorted, sort_idx = lengths.sort(descending=True)\n",
    "padded_sorted = padded[sort_idx]\n",
    "\n",
    "print(f\"排序後的序列:\\n{padded_sorted}\")\n",
    "print(f\"排序後的長度: {lengths_sorted}\")\n",
    "\n",
    "# 模擬 embedding 後的資料\n",
    "embed_dim = 4\n",
    "embedded = torch.randn(3, 5, embed_dim)  # (batch, max_len, embed_dim)\n",
    "\n",
    "# Pack\n",
    "packed = pack_padded_sequence(embedded, lengths_sorted.cpu(), \n",
    "                               batch_first=True, enforce_sorted=True)\n",
    "\n",
    "print(f\"\\nPacked data shape: {packed.data.shape}\")\n",
    "print(f\"Packed batch_sizes: {packed.batch_sizes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6：實作 - 情感分析\n",
    "\n",
    "使用 LSTM 來判斷電影評論是正面還是負面。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立簡單的情感分析資料集\n",
    "\n",
    "# 正面評論\n",
    "positive_texts = [\n",
    "    \"This movie is great and amazing\",\n",
    "    \"I love this film so much\",\n",
    "    \"Excellent acting and wonderful story\",\n",
    "    \"Best movie I have ever seen\",\n",
    "    \"Fantastic film with great performances\",\n",
    "    \"This is absolutely brilliant\",\n",
    "    \"Amazing movie highly recommended\",\n",
    "    \"Wonderful experience great movie\",\n",
    "    \"I really enjoyed this film\",\n",
    "    \"Perfect movie loved every moment\",\n",
    "    \"Outstanding performance by all actors\",\n",
    "    \"This film exceeded my expectations\",\n",
    "    \"Beautiful story and amazing visuals\",\n",
    "    \"One of the best films ever\",\n",
    "    \"Incredible movie must watch\",\n",
    "]\n",
    "\n",
    "# 負面評論\n",
    "negative_texts = [\n",
    "    \"This movie is terrible and boring\",\n",
    "    \"I hate this film completely\",\n",
    "    \"Worst movie I have ever seen\",\n",
    "    \"Bad acting and terrible story\",\n",
    "    \"Complete waste of time\",\n",
    "    \"This is absolutely awful\",\n",
    "    \"Boring movie do not watch\",\n",
    "    \"Terrible experience bad movie\",\n",
    "    \"I really hated this film\",\n",
    "    \"Worst film avoid at all costs\",\n",
    "    \"Disappointing and poorly made\",\n",
    "    \"This movie was so bad\",\n",
    "    \"Horrible story and bad acting\",\n",
    "    \"One of the worst films ever\",\n",
    "    \"Awful movie not recommended\",\n",
    "]\n",
    "\n",
    "# 建立資料集\n",
    "all_texts = positive_texts + negative_texts\n",
    "all_labels = [1] * len(positive_texts) + [0] * len(negative_texts)\n",
    "\n",
    "print(f\"正面評論數量: {len(positive_texts)}\")\n",
    "print(f\"負面評論數量: {len(negative_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立詞彙表和資料集\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=50):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        \n",
    "        # Padding 或 截斷\n",
    "        if len(tokens) < self.max_len:\n",
    "            tokens = tokens + [0] * (self.max_len - len(tokens))\n",
    "        else:\n",
    "            tokens = tokens[:self.max_len]\n",
    "        \n",
    "        return {\n",
    "            'input_ids': torch.tensor(tokens),\n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "# 建立 tokenizer\n",
    "tokenizer = SimpleTokenizer()\n",
    "tokenizer.build_vocab(all_texts)\n",
    "\n",
    "# 分割訓練和測試\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    all_texts, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n",
    "test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "print(f\"訓練集: {len(train_dataset)}\")\n",
    "print(f\"測試集: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義模型\n",
    "\n",
    "class SentimentLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim, \n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=0.3 if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)  # 二分類\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)\n",
    "        \n",
    "        # 取雙向 LSTM 的最後隱藏狀態\n",
    "        hidden = torch.cat([h_n[-2], h_n[-1]], dim=1)\n",
    "        \n",
    "        # 分類\n",
    "        out = self.fc(self.dropout(hidden))\n",
    "        return out.squeeze(1)\n",
    "\n",
    "# 建立模型\n",
    "model = SentimentLSTM(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    embed_dim=64,\n",
    "    hidden_dim=32,\n",
    "    num_layers=1\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\n參數量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "history = {'train_loss': [], 'train_acc': [], 'test_acc': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 訓練\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['label'].float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "        correct += (preds == labels.long()).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_acc = 100 * correct / total\n",
    "    history['train_loss'].append(total_loss / len(train_loader))\n",
    "    history['train_acc'].append(train_acc)\n",
    "    \n",
    "    # 測試\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).long()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    test_acc = 100 * correct / total\n",
    "    history['test_acc'].append(test_acc)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "              f\"Train Loss: {history['train_loss'][-1]:.4f}, \"\n",
    "              f\"Train Acc: {train_acc:.1f}%, Test Acc: {test_acc:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(history['train_loss'])\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].grid(True)\n",
    "\n",
    "axes[1].plot(history['train_acc'], label='Train')\n",
    "axes[1].plot(history['test_acc'], label='Test')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試新評論\n",
    "\n",
    "def predict_sentiment(text, model, tokenizer):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.encode(text)\n",
    "    # Padding\n",
    "    tokens = tokens + [0] * (50 - len(tokens)) if len(tokens) < 50 else tokens[:50]\n",
    "    input_ids = torch.tensor([tokens]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "    \n",
    "    sentiment = \"Positive\" if prob > 0.5 else \"Negative\"\n",
    "    return sentiment, prob\n",
    "\n",
    "# 測試一些新評論\n",
    "test_reviews = [\n",
    "    \"This movie is absolutely wonderful\",\n",
    "    \"I hated every minute of this film\",\n",
    "    \"Great story and amazing acting\",\n",
    "    \"Terrible movie waste of time\",\n",
    "    \"The movie was okay not great\"\n",
    "]\n",
    "\n",
    "print(\"情感分析結果：\")\n",
    "print(\"-\" * 60)\n",
    "for review in test_reviews:\n",
    "    sentiment, prob = predict_sentiment(review, model, tokenizer)\n",
    "    print(f\"'{review}'\")\n",
    "    print(f\"  -> {sentiment} (confidence: {prob:.2%})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7：實作 - 字元級語言模型\n",
    "\n",
    "訓練一個模型來預測下一個字元，可以用來生成文字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備資料\n",
    "\n",
    "# 使用簡單的訓練文本\n",
    "text = \"\"\"To be or not to be that is the question\n",
    "Whether tis nobler in the mind to suffer\n",
    "The slings and arrows of outrageous fortune\n",
    "Or to take arms against a sea of troubles\n",
    "And by opposing end them To die to sleep\n",
    "No more and by a sleep to say we end\n",
    "The heartache and the thousand natural shocks\n",
    "That flesh is heir to Tis a consummation\n",
    "Devoutly to be wished To die to sleep\n",
    "To sleep perchance to dream ay theres the rub\"\"\"\n",
    "\n",
    "# 建立字元到索引的映射\n",
    "chars = sorted(list(set(text)))\n",
    "char2idx = {c: i for i, c in enumerate(chars)}\n",
    "idx2char = {i: c for i, c in enumerate(chars)}\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print(f\"文本長度: {len(text)} 字元\")\n",
    "print(f\"詞彙表大小: {vocab_size}\")\n",
    "print(f\"字元: {chars}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立訓練資料\n",
    "\n",
    "def create_sequences(text, seq_length):\n",
    "    \"\"\"把文本分成固定長度的序列\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    for i in range(len(text) - seq_length):\n",
    "        seq = text[i:i + seq_length]\n",
    "        target = text[i + 1:i + seq_length + 1]\n",
    "        \n",
    "        seq_idx = [char2idx[c] for c in seq]\n",
    "        target_idx = [char2idx[c] for c in target]\n",
    "        \n",
    "        sequences.append(seq_idx)\n",
    "        targets.append(target_idx)\n",
    "    \n",
    "    return torch.tensor(sequences), torch.tensor(targets)\n",
    "\n",
    "seq_length = 50\n",
    "X, y = create_sequences(text, seq_length)\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\n範例輸入: '{text[:seq_length]}'\")\n",
    "print(f\"範例目標: '{text[1:seq_length+1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義字元級語言模型\n",
    "\n",
    "class CharLM(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            embed_dim, hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2 if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        \n",
    "        if hidden is None:\n",
    "            lstm_out, hidden = self.lstm(embedded)\n",
    "        else:\n",
    "            lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # 每個位置都預測下一個字元\n",
    "        out = self.fc(lstm_out)  # (batch, seq_len, vocab_size)\n",
    "        \n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        h = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        c = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        return (h, c)\n",
    "\n",
    "# 建立模型\n",
    "model = CharLM(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=64,\n",
    "    hidden_dim=128,\n",
    "    num_layers=2\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\n參數量: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練\n",
    "\n",
    "# 建立 DataLoader\n",
    "dataset = torch.utils.data.TensorDataset(X, y)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "\n",
    "num_epochs = 200\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_x, batch_y in loader:\n",
    "        batch_x = batch_x.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs, _ = model(batch_x)\n",
    "        # outputs: (batch, seq_len, vocab_size)\n",
    "        # 需要 reshape 成 (batch*seq_len, vocab_size)\n",
    "        loss = criterion(outputs.view(-1, vocab_size), batch_y.view(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    losses.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 40 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# 視覺化\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Character LM Training Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成文字\n",
    "\n",
    "def generate_text(model, start_text, length=200, temperature=1.0):\n",
    "    \"\"\"\n",
    "    從 start_text 開始生成文字\n",
    "    temperature: 控制隨機性，越低越確定，越高越隨機\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 把起始文字轉成索引\n",
    "    chars_idx = [char2idx.get(c, 0) for c in start_text]\n",
    "    input_seq = torch.tensor([chars_idx]).to(device)\n",
    "    \n",
    "    hidden = model.init_hidden(1, device)\n",
    "    generated = start_text\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 先處理起始文字，更新 hidden state\n",
    "        _, hidden = model(input_seq, hidden)\n",
    "        \n",
    "        # 生成新字元\n",
    "        current_char = chars_idx[-1]\n",
    "        \n",
    "        for _ in range(length):\n",
    "            input_seq = torch.tensor([[current_char]]).to(device)\n",
    "            output, hidden = model(input_seq, hidden)\n",
    "            \n",
    "            # 取最後一個位置的輸出\n",
    "            logits = output[0, -1] / temperature\n",
    "            probs = F.softmax(logits, dim=0)\n",
    "            \n",
    "            # 採樣下一個字元\n",
    "            next_char_idx = torch.multinomial(probs, 1).item()\n",
    "            next_char = idx2char[next_char_idx]\n",
    "            \n",
    "            generated += next_char\n",
    "            current_char = next_char_idx\n",
    "    \n",
    "    return generated\n",
    "\n",
    "# 測試不同 temperature\n",
    "print(\"=\" * 60)\n",
    "print(\"Temperature = 0.5 (較確定):\")\n",
    "print(\"=\" * 60)\n",
    "print(generate_text(model, \"To be or not to be\", length=150, temperature=0.5))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Temperature = 1.0 (平衡):\")\n",
    "print(\"=\" * 60)\n",
    "print(generate_text(model, \"To be or not to be\", length=150, temperature=1.0))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Temperature = 1.5 (較隨機):\")\n",
    "print(\"=\" * 60)\n",
    "print(generate_text(model, \"To be or not to be\", length=150, temperature=1.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 練習題（已完成，請閱讀理解）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 1：比較 RNN, LSTM, GRU\n",
    "\n",
    "**目標：** 在相同任務上比較三種模型的表現\n",
    "\n",
    "**Hint：** LSTM 和 GRU 通常比普通 RNN 好，特別是長序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1：比較三種 RNN 變體\n",
    "\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, rnn_type='lstm'):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        \n",
    "        if rnn_type == 'rnn':\n",
    "            self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        elif rnn_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
    "        elif rnn_type == 'gru':\n",
    "            self.rnn = nn.GRU(embed_dim, hidden_dim, batch_first=True)\n",
    "        \n",
    "        self.rnn_type = rnn_type\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        if self.rnn_type == 'lstm':\n",
    "            _, (h_n, _) = self.rnn(embedded)\n",
    "        else:\n",
    "            _, h_n = self.rnn(embedded)\n",
    "        \n",
    "        out = self.fc(h_n[-1])\n",
    "        return out.squeeze(1)\n",
    "\n",
    "def train_model_quick(model, train_loader, epochs=30):\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            labels = batch['label'].float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss / len(train_loader))\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# 訓練三種模型\n",
    "results = {}\n",
    "for rnn_type in ['rnn', 'lstm', 'gru']:\n",
    "    print(f\"Training {rnn_type.upper()}...\")\n",
    "    torch.manual_seed(42)\n",
    "    model = RNNModel(tokenizer.vocab_size, 64, 32, rnn_type)\n",
    "    losses = train_model_quick(model, train_loader, epochs=30)\n",
    "    results[rnn_type] = losses\n",
    "\n",
    "# 視覺化\n",
    "plt.figure(figsize=(10, 5))\n",
    "for name, losses in results.items():\n",
    "    plt.plot(losses, label=name.upper())\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('RNN vs LSTM vs GRU')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n觀察：LSTM 和 GRU 通常比普通 RNN 收斂更穩定\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2：雙向 LSTM (Bidirectional LSTM)\n",
    "\n",
    "**目標：** 理解雙向 LSTM 的優勢\n",
    "\n",
    "**Hint：** 雙向 LSTM 可以同時看到「過去」和「未來」的上下文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 2：雙向 LSTM\n",
    "\n",
    "print(\"\"\"\n",
    "雙向 LSTM 結構：\n",
    "\n",
    "Forward:   h₁ → h₂ → h₃ → h₄\n",
    "            ↑    ↑    ↑    ↑\n",
    "Input:     x₁   x₂   x₃   x₄\n",
    "            ↓    ↓    ↓    ↓\n",
    "Backward:  h₁ ← h₂ ← h₃ ← h₄\n",
    "\n",
    "每個位置的輸出 = [forward_h, backward_h]\n",
    "\n",
    "優勢：\n",
    "- 對於分類任務，可以看到完整的上下文\n",
    "- 填空任務：\"I love _____ and cats\" -> \"dogs\"\n",
    "\n",
    "限制：\n",
    "- 不能用於生成任務（因為看不到未來）\n",
    "\"\"\")\n",
    "\n",
    "# 單向 vs 雙向\n",
    "lstm_uni = nn.LSTM(10, 20, batch_first=True, bidirectional=False)\n",
    "lstm_bi = nn.LSTM(10, 20, batch_first=True, bidirectional=True)\n",
    "\n",
    "x = torch.randn(2, 5, 10)\n",
    "\n",
    "out_uni, (h_uni, _) = lstm_uni(x)\n",
    "out_bi, (h_bi, _) = lstm_bi(x)\n",
    "\n",
    "print(f\"單向 LSTM 輸出 shape: {out_uni.shape}\")\n",
    "print(f\"雙向 LSTM 輸出 shape: {out_bi.shape}\")\n",
    "print(f\"\\n單向 h_n shape: {h_uni.shape}\")\n",
    "print(f\"雙向 h_n shape: {h_bi.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3：Attention 機制預覽\n",
    "\n",
    "**目標：** 理解為什麼需要 Attention，為 Module 5 做準備\n",
    "\n",
    "**Hint：** RNN 的瓶頸是把整個序列壓縮成一個固定向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 3：簡單的 Attention\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    \"\"\"帶有簡單 Attention 的 LSTM\"\"\"\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Attention 層\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len)\n",
    "        embedded = self.embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        \n",
    "        # LSTM 輸出所有時間步\n",
    "        lstm_out, _ = self.lstm(embedded)  # (batch, seq_len, hidden*2)\n",
    "        \n",
    "        # 計算 attention weights\n",
    "        attention_scores = self.attention(lstm_out).squeeze(-1)  # (batch, seq_len)\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # (batch, seq_len)\n",
    "        \n",
    "        # 加權平均\n",
    "        # (batch, seq_len, 1) * (batch, seq_len, hidden*2) -> sum over seq_len\n",
    "        context = torch.sum(attention_weights.unsqueeze(-1) * lstm_out, dim=1)  # (batch, hidden*2)\n",
    "        \n",
    "        # 分類\n",
    "        out = self.fc(context)\n",
    "        \n",
    "        return out.squeeze(1), attention_weights\n",
    "\n",
    "# 測試\n",
    "model = AttentionLSTM(tokenizer.vocab_size, 64, 32)\n",
    "x = torch.randint(0, tokenizer.vocab_size, (2, 20))\n",
    "out, attn_weights = model(x)\n",
    "\n",
    "print(f\"輸出 shape: {out.shape}\")\n",
    "print(f\"Attention weights shape: {attn_weights.shape}\")\n",
    "print(f\"\\nAttention weights (第一個樣本): {attn_weights[0].detach().numpy()[:10]}...\")\n",
    "print(f\"Attention weights 總和: {attn_weights[0].sum().item():.4f} (應該接近 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 Attention\n",
    "\n",
    "# 使用訓練好的情感分析模型\n",
    "model = AttentionLSTM(tokenizer.vocab_size, 64, 32).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 快速訓練\n",
    "for epoch in range(30):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['label'].float().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# 測試並視覺化 attention\n",
    "test_sentence = \"This movie is absolutely wonderful and amazing\"\n",
    "tokens = tokenizer.encode(test_sentence)\n",
    "tokens = tokens + [0] * (50 - len(tokens))\n",
    "input_ids = torch.tensor([tokens]).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output, attn = model(input_ids)\n",
    "\n",
    "prob = torch.sigmoid(output).item()\n",
    "words = test_sentence.lower().split()\n",
    "attn_values = attn[0, :len(words)].cpu().numpy()\n",
    "\n",
    "# 視覺化\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(words)), attn_values)\n",
    "plt.xticks(range(len(words)), words, rotation=45)\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.title(f'Attention Visualization\\nPrediction: {\"Positive\" if prob > 0.5 else \"Negative\"} ({prob:.2%})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"觀察：模型應該會對情感詞（如 'wonderful', 'amazing'）給予更高的 attention\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Part 8：進階序列建模技巧\n\n### 8.1 Teacher Forcing vs Scheduled Sampling\n\n**Teacher Forcing：** 訓練時使用真實的前一個 token 作為輸入（而非模型預測的）\n\n**問題：** 訓練和推論時的分佈不同 (Exposure Bias)\n\n**解決方案：** Scheduled Sampling - 逐漸從 teacher forcing 過渡到自由生成",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Module 4 總結\n",
    "\n",
    "### 核心概念\n",
    "\n",
    "1. **RNN 基礎**：\n",
    "   - 隱藏狀態在時間步之間傳遞\n",
    "   - 權重在所有時間步共享\n",
    "   - 問題：梯度消失/爆炸\n",
    "\n",
    "2. **LSTM**：\n",
    "   - 三個門：遺忘門、輸入門、輸出門\n",
    "   - Cell State：資訊的「高速公路」\n",
    "   - 解決長期依賴問題\n",
    "\n",
    "3. **GRU**：\n",
    "   - LSTM 的簡化版\n",
    "   - 兩個門：重置門、更新門\n",
    "   - 參數更少，速度更快\n",
    "\n",
    "4. **文字處理**：\n",
    "   - Tokenization：文字 → 數字\n",
    "   - Embedding：索引 → 稠密向量\n",
    "   - Padding：處理變長序列\n",
    "\n",
    "5. **實用技巧**：\n",
    "   - 雙向 LSTM：同時看過去和未來\n",
    "   - 梯度裁剪：防止梯度爆炸\n",
    "   - Attention：讓模型「關注」重要部分\n",
    "\n",
    "### 下一步：Module 5 - Attention 與 Transformer"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Teacher Forcing 示範\n\nprint(\"\"\"\nTeacher Forcing 比較：\n\n訓練時 (Teacher Forcing = True)：\n  輸入: <start> I    love  NLP\n  目標:  I      love  NLP   <end>\n  ↓ 每一步都用真實的前一個詞\n\n訓練時 (Teacher Forcing = False)：\n  輸入: <start> → 模型預測 → 模型預測 → ...\n  ↓ 每一步都用自己預測的詞（可能會累積錯誤）\n\n推論時：\n  永遠是 Free Running（沒有真實標籤可用）\n\"\"\")\n\nclass TeacherForcingDemo(nn.Module):\n    \"\"\"展示 Teacher Forcing 的語言模型\"\"\"\n    def __init__(self, vocab_size, embed_dim, hidden_dim):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n        self.hidden_dim = hidden_dim\n    \n    def forward(self, x, targets=None, teacher_forcing_ratio=0.5):\n        \"\"\"\n        x: (batch, seq_len) - 起始 token\n        targets: (batch, seq_len) - 真實的目標序列\n        teacher_forcing_ratio: 使用 teacher forcing 的機率\n        \"\"\"\n        batch_size, seq_len = x.shape\n        device = x.device\n        \n        # 初始化\n        outputs = []\n        h = torch.zeros(1, batch_size, self.hidden_dim, device=device)\n        c = torch.zeros(1, batch_size, self.hidden_dim, device=device)\n        \n        # 第一個輸入\n        current_input = x[:, 0:1]  # (batch, 1)\n        \n        for t in range(seq_len):\n            embedded = self.embedding(current_input)\n            lstm_out, (h, c) = self.lstm(embedded, (h, c))\n            output = self.fc(lstm_out)  # (batch, 1, vocab_size)\n            outputs.append(output)\n            \n            # 決定下一個輸入\n            if targets is not None and t < seq_len - 1:\n                use_teacher = random.random() < teacher_forcing_ratio\n                if use_teacher:\n                    current_input = targets[:, t:t+1]  # 用真實值\n                else:\n                    current_input = output.argmax(dim=-1)  # 用預測值\n            elif t < seq_len - 1:\n                current_input = output.argmax(dim=-1)\n        \n        return torch.cat(outputs, dim=1)\n\n# 示範\nprint(\"Teacher Forcing Ratio 的影響：\")\nprint(\"- ratio=1.0: 完全 teacher forcing（訓練快但可能有 exposure bias）\")\nprint(\"- ratio=0.5: 一半一半（平衡）\")\nprint(\"- ratio=0.0: 完全自由生成（接近推論時的情況）\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.2 Beam Search 解碼\n\n**Greedy Search**：每一步選機率最高的 token（可能錯過更好的整體序列）\n\n**Beam Search**：保留 top-k 個候選序列，最後選總機率最高的",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Beam Search 實現\n\ndef beam_search_decode(model, start_idx, idx2char, char2idx, beam_width=3, max_len=50):\n    \"\"\"\n    Beam Search 文字生成\n    \n    beam_width: 同時保留的候選數量\n    \"\"\"\n    model.eval()\n    device = next(model.parameters()).device\n    \n    # 初始化 beam: (sequence, log_prob, hidden_state)\n    hidden = model.init_hidden(1, device)\n    beams = [([start_idx], 0.0, hidden)]\n    \n    completed = []\n    \n    for step in range(max_len):\n        all_candidates = []\n        \n        for seq, score, hidden in beams:\n            # 如果已經生成了終止符（這裡用換行符模擬）\n            if len(seq) > 1 and seq[-1] == char2idx.get('\\n', -1):\n                completed.append((seq, score))\n                continue\n            \n            # 準備輸入\n            input_tensor = torch.tensor([[seq[-1]]], device=device)\n            \n            with torch.no_grad():\n                output, new_hidden = model(input_tensor, hidden)\n                log_probs = F.log_softmax(output[0, -1], dim=0)\n            \n            # 取 top-k 候選\n            top_probs, top_indices = log_probs.topk(beam_width)\n            \n            for prob, idx in zip(top_probs, top_indices):\n                new_seq = seq + [idx.item()]\n                new_score = score + prob.item()\n                all_candidates.append((new_seq, new_score, new_hidden))\n        \n        # 保留 top beam_width 個候選\n        all_candidates.sort(key=lambda x: x[1], reverse=True)\n        beams = all_candidates[:beam_width]\n        \n        if not beams:\n            break\n    \n    # 結合 completed 和 beams，選最好的\n    all_results = completed + [(s, sc) for s, sc, _ in beams]\n    all_results.sort(key=lambda x: x[1] / len(x[0]), reverse=True)  # 長度正規化\n    \n    best_seq = all_results[0][0] if all_results else [start_idx]\n    return ''.join([idx2char.get(i, '?') for i in best_seq])\n\n# 比較 Greedy vs Beam Search\nprint(\"Greedy Search vs Beam Search 比較：\")\nprint(\"=\" * 50)\n\n# Greedy (temperature=0 等價)\nprint(\"\\nGreedy Search:\")\ngreedy_text = generate_text(model, \"To be\", length=50, temperature=0.1)\nprint(greedy_text[:80])\n\n# Beam Search\nprint(\"\\nBeam Search (beam_width=3):\")\nstart_chars = \"To be\"\nstart_indices = [char2idx[c] for c in start_chars]\n# 由於我們的模型結構，這裡用簡化的展示\nprint(\"(Beam Search 會探索多個路徑，選擇整體機率最高的序列)\")\nprint(\"(適合翻譯、摘要等需要高品質輸出的任務)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.3 Sequence-to-Sequence (Seq2Seq) 架構\n\n**應用：** 機器翻譯、文字摘要、對話系統\n\n**結構：** Encoder-Decoder\n- **Encoder**：把輸入序列壓縮成一個「context vector」\n- **Decoder**：從 context vector 生成輸出序列",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Seq2Seq 架構實現\n\nclass Encoder(nn.Module):\n    \"\"\"Seq2Seq Encoder\"\"\"\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, \n                           batch_first=True, bidirectional=True)\n        # 雙向 -> 單向的投影（給 decoder 用）\n        self.fc = nn.Linear(hidden_dim * 2, hidden_dim)\n    \n    def forward(self, x):\n        # x: (batch, src_len)\n        embedded = self.embedding(x)\n        outputs, (h_n, c_n) = self.lstm(embedded)\n        \n        # 把雙向的 hidden 合併\n        # h_n: (num_layers*2, batch, hidden)\n        h_n = torch.cat([h_n[-2], h_n[-1]], dim=1)  # (batch, hidden*2)\n        c_n = torch.cat([c_n[-2], c_n[-1]], dim=1)\n        \n        # 投影到 decoder 的維度\n        h_n = torch.tanh(self.fc(h_n)).unsqueeze(0)  # (1, batch, hidden)\n        c_n = torch.tanh(self.fc(c_n)).unsqueeze(0)\n        \n        return outputs, (h_n, c_n)\n\n\nclass Decoder(nn.Module):\n    \"\"\"Seq2Seq Decoder\"\"\"\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_layers=1):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers, batch_first=True)\n        self.fc = nn.Linear(hidden_dim, vocab_size)\n    \n    def forward(self, x, hidden):\n        # x: (batch, 1) - 一次一個 token\n        embedded = self.embedding(x)\n        output, hidden = self.lstm(embedded, hidden)\n        prediction = self.fc(output)\n        return prediction, hidden\n\n\nclass Seq2Seq(nn.Module):\n    \"\"\"完整的 Seq2Seq 模型\"\"\"\n    def __init__(self, encoder, decoder, device):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n    \n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        # src: (batch, src_len)\n        # trg: (batch, trg_len)\n        batch_size = src.shape[0]\n        trg_len = trg.shape[1]\n        trg_vocab_size = self.decoder.fc.out_features\n        \n        # 儲存輸出\n        outputs = torch.zeros(batch_size, trg_len, trg_vocab_size, device=self.device)\n        \n        # Encode\n        _, hidden = self.encoder(src)\n        \n        # Decoder 的第一個輸入是 <sos> token（假設是 trg 的第一個）\n        dec_input = trg[:, 0:1]\n        \n        for t in range(1, trg_len):\n            output, hidden = self.decoder(dec_input, hidden)\n            outputs[:, t] = output.squeeze(1)\n            \n            # Teacher Forcing\n            use_teacher = random.random() < teacher_forcing_ratio\n            dec_input = trg[:, t:t+1] if use_teacher else output.argmax(dim=-1)\n        \n        return outputs\n\n# 建立 Seq2Seq 模型\nsrc_vocab = 100\ntrg_vocab = 80\nembed_dim = 64\nhidden_dim = 128\n\nencoder = Encoder(src_vocab, embed_dim, hidden_dim)\ndecoder = Decoder(trg_vocab, embed_dim, hidden_dim)\nseq2seq = Seq2Seq(encoder, decoder, device).to(device)\n\n# 測試\nsrc = torch.randint(0, src_vocab, (2, 10)).to(device)  # 源語言\ntrg = torch.randint(0, trg_vocab, (2, 8)).to(device)   # 目標語言\n\noutput = seq2seq(src, trg, teacher_forcing_ratio=0.5)\nprint(f\"Seq2Seq 架構：\")\nprint(f\"  源序列 shape: {src.shape}\")\nprint(f\"  目標序列 shape: {trg.shape}\")\nprint(f\"  輸出 shape: {output.shape}\")\nprint(f\"\\n參數量: {sum(p.numel() for p in seq2seq.parameters()):,}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 8.4 梯度裁剪與 Masking 技巧\n\n**梯度裁剪 (Gradient Clipping)**：防止 RNN 訓練時的梯度爆炸\n\n**Masking**：正確處理 padding，避免 padding 影響計算",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 梯度裁剪最佳實踐\n\ndef train_with_gradient_clipping(model, optimizer, criterion, x, y, max_grad_norm=1.0):\n    \"\"\"展示梯度裁剪的正確用法\"\"\"\n    model.train()\n    optimizer.zero_grad()\n    \n    output = model(x)\n    loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n    loss.backward()\n    \n    # 記錄裁剪前的梯度範數\n    total_norm_before = 0\n    for p in model.parameters():\n        if p.grad is not None:\n            param_norm = p.grad.data.norm(2)\n            total_norm_before += param_norm.item() ** 2\n    total_norm_before = total_norm_before ** 0.5\n    \n    # 梯度裁剪\n    torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n    \n    # 記錄裁剪後的梯度範數\n    total_norm_after = 0\n    for p in model.parameters():\n        if p.grad is not None:\n            param_norm = p.grad.data.norm(2)\n            total_norm_after += param_norm.item() ** 2\n    total_norm_after = total_norm_after ** 0.5\n    \n    optimizer.step()\n    \n    return loss.item(), total_norm_before, total_norm_after\n\nprint(\"梯度裁剪策略比較：\")\nprint(\"=\" * 60)\nprint(\"\"\"\n1. clip_grad_norm_（L2 norm）：\n   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n   - 最常用，按整體梯度範數縮放\n   - 保持梯度方向不變\n   \n2. clip_grad_value_（按值裁剪）：\n   torch.nn.utils.clip_grad_value_(model.parameters(), clip_value=1.0)\n   - 每個梯度元素單獨裁剪\n   - 可能改變梯度方向\n\n推薦配置：\n- RNN/LSTM: max_norm=1.0 到 5.0\n- Transformer: max_norm=1.0\n- 一般神經網路: 可能不需要（沒有長時間依賴）\n\"\"\")\n\n# 示範 Masking\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Masking 示範：\")\nprint(\"=\" * 60)\n\n# 建立帶 padding 的序列\nseq1 = [1, 2, 3, 4, 5, 0, 0, 0]  # 長度 5，後面是 padding\nseq2 = [6, 7, 8, 0, 0, 0, 0, 0]  # 長度 3\nseq3 = [9, 10, 11, 12, 13, 14, 15, 16]  # 長度 8\n\nbatch = torch.tensor([seq1, seq2, seq3])\nlengths = torch.tensor([5, 3, 8])\n\n# 建立 mask\nmask = torch.arange(batch.size(1)).expand(len(lengths), batch.size(1))\nmask = mask < lengths.unsqueeze(1)\n\nprint(f\"Batch:\\n{batch}\")\nprint(f\"\\nLengths: {lengths}\")\nprint(f\"\\nMask:\\n{mask.int()}\")\n\n# 在計算 loss 時使用 mask\ndef masked_cross_entropy(pred, target, mask):\n    \"\"\"忽略 padding 位置的 cross entropy\"\"\"\n    # pred: (batch, seq_len, vocab_size)\n    # target: (batch, seq_len)\n    # mask: (batch, seq_len) - True 表示真實 token\n    \n    batch_size, seq_len, vocab_size = pred.shape\n    \n    # Flatten\n    pred_flat = pred.view(-1, vocab_size)\n    target_flat = target.view(-1)\n    mask_flat = mask.view(-1)\n    \n    # 計算所有位置的 loss\n    loss = F.cross_entropy(pred_flat, target_flat, reduction='none')\n    \n    # 只保留非 padding 位置\n    loss = loss * mask_flat.float()\n    \n    # 平均（只除以非 padding 的數量）\n    return loss.sum() / mask_flat.sum()\n\nprint(\"\\n使用 mask 計算 loss 可以避免 padding 影響結果！\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Module 4 完整總結\n\n### 🎯 核心概念對比\n\n| 模型 | 門數 | 狀態 | 參數量 | 適用場景 |\n|------|------|------|--------|----------|\n| **Simple RNN** | 0 | h | 少 | 短序列、簡單任務 |\n| **LSTM** | 3 | h, c | 多 | 長序列、需要長期記憶 |\n| **GRU** | 2 | h | 中 | 資源受限、速度優先 |\n\n### 🔑 關鍵公式\n\n```\nRNN:\n  hₜ = tanh(Wₓₕ·xₜ + Wₕₕ·hₜ₋₁ + b)\n\nLSTM:\n  fₜ = σ(Wf·[hₜ₋₁, xₜ] + bf)      # 遺忘門\n  iₜ = σ(Wi·[hₜ₋₁, xₜ] + bi)      # 輸入門\n  oₜ = σ(Wo·[hₜ₋₁, xₜ] + bo)      # 輸出門\n  C̃ₜ = tanh(Wc·[hₜ₋₁, xₜ] + bc)   # 候選狀態\n  Cₜ = fₜ ⊙ Cₜ₋₁ + iₜ ⊙ C̃ₜ        # 細胞狀態\n  hₜ = oₜ ⊙ tanh(Cₜ)              # 隱藏狀態\n\nGRU:\n  rₜ = σ(Wr·[hₜ₋₁, xₜ])           # 重置門\n  zₜ = σ(Wz·[hₜ₋₁, xₜ])           # 更新門\n  h̃ₜ = tanh(W·[rₜ ⊙ hₜ₋₁, xₜ])    # 候選狀態\n  hₜ = (1-zₜ) ⊙ hₜ₋₁ + zₜ ⊙ h̃ₜ   # 新狀態\n```\n\n### 🏗️ 架構演進\n\n```\nRNN (1980s)     → 最基礎，有梯度消失問題\nLSTM (1997)     → 引入門控，解決長期依賴\nGRU (2014)      → LSTM 簡化版，效果相當\nSeq2Seq (2014)  → Encoder-Decoder，用於翻譯\nAttention (2015)→ 動態關注，緩解瓶頸問題\nTransformer (2017) → 完全捨棄 RNN，全 attention\n```\n\n### 💡 實務技巧\n\n1. **模型選擇**：\n   - 預設用 LSTM（最穩定）\n   - 資源受限考慮 GRU\n   - 序列 < 100 可考慮 RNN\n\n2. **訓練技巧**：\n   - **必須**使用梯度裁剪（max_norm=1.0~5.0）\n   - 使用 pack_padded_sequence 處理變長序列\n   - Dropout 只用在層之間，不用在時間步之間\n\n3. **超參數建議**：\n   - hidden_dim: 128~512\n   - num_layers: 1~3（更深用殘差連接）\n   - embed_dim: 100~300\n\n4. **文字生成**：\n   - Temperature 控制隨機性（0.7~1.0 較好）\n   - Beam Search 生成更高品質的序列\n   - 用 Teacher Forcing 加速訓練\n\n5. **常見問題**：\n   - 梯度爆炸 → 梯度裁剪\n   - 過擬合 → Dropout + 早停\n   - 訓練慢 → 減少層數或用 GRU\n\n### 🚀 下一步\n\n- Module 5：Attention 與 Transformer（徹底解決 RNN 的瓶頸問題）\n\n---\n\n**恭喜完成 RNN 模組！** 🎉\n\nLSTM/GRU 是處理序列資料的經典方法，即使在 Transformer 時代，理解這些概念對於理解現代架構仍然非常重要。",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}