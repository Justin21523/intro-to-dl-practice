{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 7: Autoencoder 與 VAE\n",
    "\n",
    "## 學習目標\n",
    "- 理解 Autoencoder 的編碼器-解碼器架構\n",
    "- 掌握潛在空間 (Latent Space) 的概念\n",
    "- 學習 VAE 的數學原理與實現\n",
    "- 使用 VAE 生成 MNIST 手寫數字\n",
    "\n",
    "## 為什麼要學 Autoencoder？\n",
    "\n",
    "Autoencoder 是**生成模型**的基礎，理解它能幫助你：\n",
    "1. 資料壓縮與降維\n",
    "2. 特徵學習\n",
    "3. 異常檢測\n",
    "4. 圖像生成（VAE、Diffusion 的基礎）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "# 設定\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "# 可視化設定\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: Autoencoder 基礎\n",
    "\n",
    "### 直觀理解\n",
    "\n",
    "Autoencoder 就像是一個「壓縮-解壓」系統：\n",
    "\n",
    "```\n",
    "輸入 x ──► [編碼器] ──► 潛在表示 z ──► [解碼器] ──► 重建 x'\n",
    "(784)       壓縮         (32)          解壓        (784)\n",
    "\n",
    "目標：讓 x' 盡可能接近 x\n",
    "```\n",
    "\n",
    "**為什麼有用？**\n",
    "- 潛在空間 z 捕捉了資料的**本質特徵**\n",
    "- 強迫網路學習重要的表示（降維）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    最簡單的全連接 Autoencoder\n",
    "    \n",
    "    結構：\n",
    "    - 編碼器：784 -> 256 -> 64 -> latent_dim\n",
    "    - 解碼器：latent_dim -> 64 -> 256 -> 784\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 編碼器：將輸入壓縮到潛在空間\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, latent_dim),\n",
    "        )\n",
    "        \n",
    "        # 解碼器：從潛在空間重建輸入\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 784),\n",
    "            nn.Sigmoid(),  # 輸出在 [0, 1] 範圍\n",
    "        )\n",
    "        \n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"編碼：x -> z\"\"\"\n",
    "        x = x.view(-1, 784)  # 展平\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"解碼：z -> x'\"\"\"\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"完整前向傳播\"\"\"\n",
    "        z = self.encode(x)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, z\n",
    "\n",
    "# 測試\n",
    "model = SimpleAutoencoder(latent_dim=32)\n",
    "x = torch.randn(4, 1, 28, 28)  # 模擬 MNIST 輸入\n",
    "x_recon, z = model(x)\n",
    "\n",
    "print(\"Simple Autoencoder 測試：\")\n",
    "print(f\"輸入形狀: {x.shape}\")\n",
    "print(f\"潛在表示形狀: {z.shape}\")\n",
    "print(f\"重建輸出形狀: {x_recon.shape}\")\n",
    "print(f\"\\n壓縮比: {784 / 32:.1f}x (784 -> 32)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入 MNIST 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料載入\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(f\"訓練集大小: {len(train_dataset)}\")\n",
    "print(f\"測試集大小: {len(test_dataset)}\")\n",
    "\n",
    "# 顯示一些樣本\n",
    "fig, axes = plt.subplots(2, 10, figsize=(12, 3))\n",
    "for i in range(10):\n",
    "    idx = np.random.randint(len(train_dataset))\n",
    "    img, label = train_dataset[idx]\n",
    "    axes[0, i].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[0, i].axis('off')\n",
    "    axes[0, i].set_title(str(label))\n",
    "    \n",
    "    idx = np.random.randint(len(train_dataset))\n",
    "    img, label = train_dataset[idx]\n",
    "    axes[1, i].imshow(img.squeeze(), cmap='gray')\n",
    "    axes[1, i].axis('off')\n",
    "    axes[1, i].set_title(str(label))\n",
    "\n",
    "plt.suptitle('MNIST 樣本')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練 Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(model, train_loader, epochs=10, lr=1e-3):\n",
    "    \"\"\"\n",
    "    訓練 Autoencoder\n",
    "    \n",
    "    損失函數：重建損失（MSE 或 BCE）\n",
    "    目標：最小化輸入與重建之間的差異\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # 使用 BCE 損失（因為像素值在 [0,1]）\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    history = {'loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # 前向傳播\n",
    "            recon, _ = model(data)\n",
    "            \n",
    "            # 計算重建損失\n",
    "            loss = criterion(recon, data.view(-1, 784))\n",
    "            \n",
    "            # 反向傳播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        history['loss'].append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 訓練\n",
    "ae_model = SimpleAutoencoder(latent_dim=32).to(device)\n",
    "history = train_autoencoder(ae_model, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(model, test_loader, n_samples=10):\n",
    "    \"\"\"\n",
    "    可視化重建結果\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 取得一批測試資料\n",
    "    data, _ = next(iter(test_loader))\n",
    "    data = data[:n_samples].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        recon, _ = model(data)\n",
    "    \n",
    "    # 繪製\n",
    "    fig, axes = plt.subplots(2, n_samples, figsize=(15, 3))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 原始圖像\n",
    "        axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_title('原始', fontsize=12)\n",
    "        \n",
    "        # 重建圖像\n",
    "        axes[1, i].imshow(recon[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_title('重建', fontsize=12)\n",
    "    \n",
    "    plt.suptitle('Autoencoder 重建效果')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_reconstruction(ae_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 潛在空間可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_latent_space(model, test_loader, n_samples=3000):\n",
    "    \"\"\"\n",
    "    將潛在空間用 t-SNE 或 PCA 降維後可視化\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    latents = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device)\n",
    "            _, z = model(data)\n",
    "            latents.append(z.cpu())\n",
    "            labels_list.append(labels)\n",
    "            \n",
    "            if len(latents) * data.shape[0] >= n_samples:\n",
    "                break\n",
    "    \n",
    "    latents = torch.cat(latents, dim=0)[:n_samples].numpy()\n",
    "    labels_list = torch.cat(labels_list, dim=0)[:n_samples].numpy()\n",
    "    \n",
    "    # PCA 降到 2D\n",
    "    pca = PCA(n_components=2)\n",
    "    latents_2d = pca.fit_transform(latents)\n",
    "    \n",
    "    # 繪製\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(latents_2d[:, 0], latents_2d[:, 1], \n",
    "                         c=labels_list, cmap='tab10', alpha=0.6, s=10)\n",
    "    plt.colorbar(scatter, label='數字類別')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('Autoencoder 潛在空間 (PCA 投影)')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"PCA 解釋變異比: {pca.explained_variance_ratio_.sum()*100:.1f}%\")\n",
    "\n",
    "visualize_latent_space(ae_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: 卷積 Autoencoder\n",
    "\n",
    "對於圖像，使用卷積層效果更好："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    卷積 Autoencoder\n",
    "    \n",
    "    使用卷積進行編碼，轉置卷積進行解碼\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 編碼器\n",
    "        # 輸入: [B, 1, 28, 28]\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # [B, 32, 14, 14]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),  # [B, 64, 7, 7]\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 全連接到潛在空間\n",
    "        self.encoder_fc = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        \n",
    "        # 從潛在空間解碼\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        \n",
    "        # 解碼器\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),  # [B, 32, 14, 14]\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # [B, 1, 28, 28]\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def encode(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.encoder_conv(x)\n",
    "        h = h.view(h.size(0), -1)  # 展平\n",
    "        z = self.encoder_fc(h)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.decoder_fc(z)\n",
    "        h = h.view(h.size(0), 64, 7, 7)  # 重塑\n",
    "        x_recon = self.decoder_conv(h)\n",
    "        return x_recon\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        z = self.encode(x)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, z\n",
    "\n",
    "# 測試\n",
    "conv_ae = ConvAutoencoder(latent_dim=32)\n",
    "x = torch.randn(4, 1, 28, 28)\n",
    "x_recon, z = conv_ae(x)\n",
    "\n",
    "print(\"Conv Autoencoder 測試：\")\n",
    "print(f\"輸入形狀: {x.shape}\")\n",
    "print(f\"潛在表示形狀: {z.shape}\")\n",
    "print(f\"重建輸出形狀: {x_recon.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練卷積 Autoencoder\n",
    "def train_conv_autoencoder(model, train_loader, epochs=10, lr=1e-3):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()  # 使用 MSE\n",
    "    \n",
    "    history = {'loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            recon, _ = model(data)\n",
    "            loss = criterion(recon, data)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * data.size(0)\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader.dataset)\n",
    "        history['loss'].append(avg_loss)\n",
    "        \n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.6f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "conv_ae_model = ConvAutoencoder(latent_dim=32).to(device)\n",
    "history = train_conv_autoencoder(conv_ae_model, train_loader, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較重建效果\n",
    "def compare_reconstruction(fc_model, conv_model, test_loader, n_samples=10):\n",
    "    fc_model.eval()\n",
    "    conv_model.eval()\n",
    "    \n",
    "    data, _ = next(iter(test_loader))\n",
    "    data = data[:n_samples].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        recon_fc, _ = fc_model(data)\n",
    "        recon_conv, _ = conv_model(data)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, n_samples, figsize=(15, 4.5))\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        # 原始\n",
    "        axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[0, i].set_ylabel('原始', fontsize=12)\n",
    "        \n",
    "        # FC 重建\n",
    "        axes[1, i].imshow(recon_fc[i].cpu().view(28, 28), cmap='gray')\n",
    "        axes[1, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[1, i].set_ylabel('FC AE', fontsize=12)\n",
    "        \n",
    "        # Conv 重建\n",
    "        axes[2, i].imshow(recon_conv[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[2, i].axis('off')\n",
    "        if i == 0:\n",
    "            axes[2, i].set_ylabel('Conv AE', fontsize=12)\n",
    "    \n",
    "    plt.suptitle('FC vs Conv Autoencoder 重建比較')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_reconstruction(ae_model, conv_ae_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Variational Autoencoder (VAE)\n",
    "\n",
    "### VAE 的直觀理解\n",
    "\n",
    "普通 Autoencoder 的問題：潛在空間不連續、不規則\n",
    "\n",
    "```\n",
    "普通 AE 的潛在空間：\n",
    "    ┌───────────────────┐\n",
    "    │  •••   ∘∘∘       │   不同數字聚在一起\n",
    "    │    ×××    ○○     │   但空間有「空洞」\n",
    "    │  △△△         ◇◇ │   從空洞採樣會得到奇怪結果\n",
    "    └───────────────────┘\n",
    "\n",
    "VAE 的潛在空間：\n",
    "    ┌───────────────────┐\n",
    "    │   ∘•×△○◇ 平滑過渡  │   強制潛在空間接近標準正態分佈\n",
    "    │  • ∘ × △ ○ ◇     │   可以從任意位置採樣\n",
    "    │ • ∘ × △ ○ ◇      │   得到有意義的輸出\n",
    "    └───────────────────┘\n",
    "```\n",
    "\n",
    "### VAE 的關鍵改變\n",
    "\n",
    "1. **編碼器輸出分佈參數**而非點：\n",
    "   - 輸出 $\\mu$ 和 $\\sigma$（均值和標準差）\n",
    "   - $z \\sim \\mathcal{N}(\\mu, \\sigma^2)$\n",
    "\n",
    "2. **增加 KL 散度損失**：\n",
    "   - 強制潛在分佈接近標準正態分佈 $\\mathcal{N}(0, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE 數學\n",
    "\n",
    "**損失函數** = 重建損失 + KL 散度\n",
    "\n",
    "$$\\mathcal{L} = \\mathbb{E}_{z \\sim q(z|x)}[\\log p(x|z)] - \\text{KL}(q(z|x) || p(z))$$\n",
    "\n",
    "其中：\n",
    "- 第一項：重建損失（希望從 z 能重建出 x）\n",
    "- 第二項：KL 散度（希望 q(z|x) 接近先驗 p(z) = N(0,1)）\n",
    "\n",
    "**KL 散度的解析解**（當 q(z|x) 是高斯分佈時）：\n",
    "\n",
    "$$\\text{KL} = -\\frac{1}{2} \\sum_{j=1}^{J} (1 + \\log(\\sigma_j^2) - \\mu_j^2 - \\sigma_j^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Autoencoder\n",
    "    \n",
    "    關鍵改變：\n",
    "    1. 編碼器輸出 mu 和 log_var\n",
    "    2. 使用重參數化技巧進行採樣\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim: int = 32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # 編碼器\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        # 輸出 mu 和 log_var\n",
    "        self.fc_mu = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64 * 7 * 7, latent_dim)\n",
    "        \n",
    "        # 解碼器\n",
    "        self.decoder_fc = nn.Linear(latent_dim, 64 * 7 * 7)\n",
    "        \n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def encode(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        編碼：返回分佈參數 (mu, log_var)\n",
    "        \"\"\"\n",
    "        h = self.encoder_conv(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        \n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_logvar(h)\n",
    "        \n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        重參數化技巧 (Reparameterization Trick)\n",
    "        \n",
    "        z = mu + sigma * epsilon, 其中 epsilon ~ N(0, 1)\n",
    "        \n",
    "        這讓採樣過程可微分！\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * log_var)  # sigma = exp(0.5 * log(sigma^2))\n",
    "        epsilon = torch.randn_like(std)  # 從標準正態採樣\n",
    "        z = mu + std * epsilon\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h = self.decoder_fc(z)\n",
    "        h = h.view(h.size(0), 64, 7, 7)\n",
    "        return self.decoder_conv(h)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decode(z)\n",
    "        return x_recon, mu, log_var\n",
    "\n",
    "# 測試\n",
    "vae = VAE(latent_dim=32)\n",
    "x = torch.randn(4, 1, 28, 28)\n",
    "x_recon, mu, log_var = vae(x)\n",
    "\n",
    "print(\"VAE 測試：\")\n",
    "print(f\"輸入形狀: {x.shape}\")\n",
    "print(f\"mu 形狀: {mu.shape}\")\n",
    "print(f\"log_var 形狀: {log_var.shape}\")\n",
    "print(f\"重建輸出形狀: {x_recon.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE 損失函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, log_var, kl_weight=1.0):\n",
    "    \"\"\"\n",
    "    VAE 損失 = 重建損失 + KL 散度\n",
    "    \n",
    "    Args:\n",
    "        recon_x: 重建圖像 [B, 1, 28, 28]\n",
    "        x: 原始圖像 [B, 1, 28, 28]\n",
    "        mu: 編碼器輸出的均值 [B, latent_dim]\n",
    "        log_var: 編碼器輸出的對數方差 [B, latent_dim]\n",
    "        kl_weight: KL 項的權重（可用於 beta-VAE）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 重建損失 (Binary Cross Entropy)\n",
    "    recon_loss = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    \n",
    "    # KL 散度: -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    \n",
    "    total_loss = recon_loss + kl_weight * kl_loss\n",
    "    \n",
    "    return total_loss, recon_loss, kl_loss\n",
    "\n",
    "# 測試損失計算\n",
    "x = torch.rand(4, 1, 28, 28)  # 注意：BCE 需要輸入在 [0,1]\n",
    "vae = VAE(latent_dim=32)\n",
    "x_recon, mu, log_var = vae(x)\n",
    "\n",
    "total, recon, kl = vae_loss(x_recon, x, mu, log_var)\n",
    "print(f\"總損失: {total.item():.2f}\")\n",
    "print(f\"重建損失: {recon.item():.2f}\")\n",
    "print(f\"KL 散度: {kl.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練 VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, epochs=15, lr=1e-3, kl_weight=1.0):\n",
    "    \"\"\"\n",
    "    訓練 VAE\n",
    "    \"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    history = {'total_loss': [], 'recon_loss': [], 'kl_loss': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        total_recon = 0\n",
    "        total_kl = 0\n",
    "        \n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            # 前向傳播\n",
    "            recon, mu, log_var = model(data)\n",
    "            \n",
    "            # 計算損失\n",
    "            loss, recon_loss, kl_loss = vae_loss(recon, data, mu, log_var, kl_weight)\n",
    "            \n",
    "            # 反向傳播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_recon += recon_loss.item()\n",
    "            total_kl += kl_loss.item()\n",
    "        \n",
    "        n = len(train_loader.dataset)\n",
    "        history['total_loss'].append(total_loss / n)\n",
    "        history['recon_loss'].append(total_recon / n)\n",
    "        history['kl_loss'].append(total_kl / n)\n",
    "        \n",
    "        if (epoch + 1) % 3 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            print(f\"  Total: {history['total_loss'][-1]:.2f}, \"\n",
    "                  f\"Recon: {history['recon_loss'][-1]:.2f}, \"\n",
    "                  f\"KL: {history['kl_loss'][-1]:.2f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# 訓練\n",
    "vae_model = VAE(latent_dim=32).to(device)\n",
    "vae_history = train_vae(vae_model, train_loader, epochs=15, kl_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製訓練曲線\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].plot(vae_history['total_loss'])\n",
    "axes[0].set_title('總損失')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "\n",
    "axes[1].plot(vae_history['recon_loss'])\n",
    "axes[1].set_title('重建損失')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "\n",
    "axes[2].plot(vae_history['kl_loss'])\n",
    "axes[2].set_title('KL 散度')\n",
    "axes[2].set_xlabel('Epoch')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE 生成新樣本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, n_samples=20):\n",
    "    \"\"\"\n",
    "    從 VAE 生成新樣本\n",
    "    \n",
    "    步驟：從標準正態分佈採樣 z，然後解碼\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 從標準正態分佈採樣\n",
    "        z = torch.randn(n_samples, model.latent_dim).to(device)\n",
    "        \n",
    "        # 解碼生成圖像\n",
    "        samples = model.decode(z)\n",
    "    \n",
    "    # 可視化\n",
    "    n_cols = 10\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 1.5 * n_rows))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_rows == 1 and n_cols == 1 else axes\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        axes[i].imshow(samples[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    # 隱藏多餘的子圖\n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('VAE 生成的新樣本（從 N(0,1) 採樣 z）')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "generate_samples(vae_model, n_samples=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 潛在空間探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_vae_latent_space(model, test_loader, n_samples=5000):\n",
    "    \"\"\"\n",
    "    可視化 VAE 的潛在空間\n",
    "    \n",
    "    與普通 AE 比較，VAE 的潛在空間應該更規整\n",
    "    \"\"\"\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    mus = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encode(data)\n",
    "            mus.append(mu.cpu())\n",
    "            labels_list.append(labels)\n",
    "            \n",
    "            if len(mus) * data.shape[0] >= n_samples:\n",
    "                break\n",
    "    \n",
    "    mus = torch.cat(mus, dim=0)[:n_samples].numpy()\n",
    "    labels_list = torch.cat(labels_list, dim=0)[:n_samples].numpy()\n",
    "    \n",
    "    # PCA 降維\n",
    "    pca = PCA(n_components=2)\n",
    "    mus_2d = pca.fit_transform(mus)\n",
    "    \n",
    "    # 繪製\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(mus_2d[:, 0], mus_2d[:, 1], \n",
    "                         c=labels_list, cmap='tab10', alpha=0.6, s=10)\n",
    "    plt.colorbar(scatter, label='數字類別')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title('VAE 潛在空間 (mu 的 PCA 投影)')\n",
    "    \n",
    "    # 添加參考圓（標準正態分佈的等高線）\n",
    "    circle = plt.Circle((0, 0), 2, fill=False, linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.gca().add_patch(circle)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_vae_latent_space(vae_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_space_interpolation(model, test_loader):\n",
    "    \"\"\"\n",
    "    潛在空間插值：展示兩個數字之間的平滑過渡\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # 取得兩個不同的樣本\n",
    "    data, labels = next(iter(test_loader))\n",
    "    \n",
    "    # 找到兩個不同數字\n",
    "    idx1, idx2 = 0, 1\n",
    "    while labels[idx1] == labels[idx2]:\n",
    "        idx2 += 1\n",
    "    \n",
    "    x1 = data[idx1:idx1+1].to(device)\n",
    "    x2 = data[idx2:idx2+1].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mu1, _ = model.encode(x1)\n",
    "        mu2, _ = model.encode(x2)\n",
    "        \n",
    "        # 在潛在空間中進行線性插值\n",
    "        n_steps = 10\n",
    "        interpolations = []\n",
    "        \n",
    "        for alpha in np.linspace(0, 1, n_steps):\n",
    "            z = (1 - alpha) * mu1 + alpha * mu2\n",
    "            x_interp = model.decode(z)\n",
    "            interpolations.append(x_interp)\n",
    "        \n",
    "        interpolations = torch.cat(interpolations, dim=0)\n",
    "    \n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(1, n_steps + 2, figsize=(14, 1.5))\n",
    "    \n",
    "    # 原始圖像 1\n",
    "    axes[0].imshow(x1.cpu().squeeze(), cmap='gray')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(f'{labels[idx1].item()}')\n",
    "    \n",
    "    # 插值結果\n",
    "    for i in range(n_steps):\n",
    "        axes[i+1].imshow(interpolations[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[i+1].axis('off')\n",
    "    \n",
    "    # 原始圖像 2\n",
    "    axes[-1].imshow(x2.cpu().squeeze(), cmap='gray')\n",
    "    axes[-1].axis('off')\n",
    "    axes[-1].set_title(f'{labels[idx2].item()}')\n",
    "    \n",
    "    plt.suptitle('VAE 潛在空間插值')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "latent_space_interpolation(vae_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D 潛在空間的 VAE（更好的可視化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練一個 2D 潛在空間的 VAE\n",
    "vae_2d = VAE(latent_dim=2).to(device)\n",
    "vae_2d_history = train_vae(vae_2d, train_loader, epochs=20, kl_weight=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_2d_latent_manifold(model, n_points=20, range_val=3):\n",
    "    \"\"\"\n",
    "    在 2D 潛在空間中網格採樣，生成圖像流形\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # 建立網格\n",
    "    z1 = np.linspace(-range_val, range_val, n_points)\n",
    "    z2 = np.linspace(-range_val, range_val, n_points)\n",
    "    \n",
    "    # 生成圖像\n",
    "    canvas = np.zeros((28 * n_points, 28 * n_points))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, z2_val in enumerate(z2[::-1]):  # 上到下\n",
    "            for j, z1_val in enumerate(z1):     # 左到右\n",
    "                z = torch.tensor([[z1_val, z2_val]], dtype=torch.float32).to(device)\n",
    "                x = model.decode(z)\n",
    "                canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x.cpu().squeeze().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(canvas, cmap='gray')\n",
    "    plt.xlabel('z1')\n",
    "    plt.ylabel('z2')\n",
    "    plt.title('VAE 2D 潛在空間流形')\n",
    "    \n",
    "    # 添加座標標籤\n",
    "    plt.xticks(np.linspace(0, 28*n_points, 5), \n",
    "               [f'{v:.1f}' for v in np.linspace(-range_val, range_val, 5)])\n",
    "    plt.yticks(np.linspace(0, 28*n_points, 5), \n",
    "               [f'{v:.1f}' for v in np.linspace(range_val, -range_val, 5)])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "visualize_2d_latent_manifold(vae_2d, n_points=15, range_val=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_latent_distribution(model, test_loader):\n",
    "    \"\"\"\n",
    "    繪製 2D 潛在空間中各類別的分佈\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    mus = []\n",
    "    labels_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in test_loader:\n",
    "            data = data.to(device)\n",
    "            mu, _ = model.encode(data)\n",
    "            mus.append(mu.cpu())\n",
    "            labels_list.append(labels)\n",
    "    \n",
    "    mus = torch.cat(mus, dim=0).numpy()\n",
    "    labels_list = torch.cat(labels_list, dim=0).numpy()\n",
    "    \n",
    "    # 繪製\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, 10))\n",
    "    \n",
    "    for digit in range(10):\n",
    "        mask = labels_list == digit\n",
    "        plt.scatter(mus[mask, 0], mus[mask, 1], \n",
    "                   c=[colors[digit]], alpha=0.5, s=10, label=str(digit))\n",
    "    \n",
    "    plt.xlabel('z1')\n",
    "    plt.ylabel('z2')\n",
    "    plt.title('VAE 2D 潛在空間分佈')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加標準正態參考\n",
    "    circle = plt.Circle((0, 0), 2, fill=False, linestyle='--', color='gray', alpha=0.5)\n",
    "    plt.gca().add_patch(circle)\n",
    "    \n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "\n",
    "plot_2d_latent_distribution(vae_2d, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Beta-VAE 與 Disentangled 表示\n",
    "\n",
    "Beta-VAE 透過增加 KL 項的權重來學習「解糾纏」的表示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比較不同 beta 值的效果\n",
    "def train_and_compare_betas(betas=[0.1, 1.0, 4.0], epochs=10):\n",
    "    \"\"\"\n",
    "    訓練不同 beta 值的 VAE 並比較結果\n",
    "    \n",
    "    beta < 1: 更好的重建，但潛在空間可能不規整\n",
    "    beta = 1: 標準 VAE\n",
    "    beta > 1: 更規整的潛在空間，但重建可能模糊\n",
    "    \"\"\"\n",
    "    \n",
    "    models = {}\n",
    "    histories = {}\n",
    "    \n",
    "    for beta in betas:\n",
    "        print(f\"\\n訓練 beta={beta} 的 VAE...\")\n",
    "        model = VAE(latent_dim=32).to(device)\n",
    "        history = train_vae(model, train_loader, epochs=epochs, kl_weight=beta)\n",
    "        models[beta] = model\n",
    "        histories[beta] = history\n",
    "    \n",
    "    return models, histories\n",
    "\n",
    "# 訓練（可能需要幾分鐘）\n",
    "beta_models, beta_histories = train_and_compare_betas([0.1, 1.0, 4.0], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_beta_reconstructions(models, test_loader):\n",
    "    \"\"\"\n",
    "    比較不同 beta VAE 的重建效果\n",
    "    \"\"\"\n",
    "    \n",
    "    data, _ = next(iter(test_loader))\n",
    "    data = data[:8].to(device)\n",
    "    \n",
    "    betas = list(models.keys())\n",
    "    n_samples = data.shape[0]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(betas) + 1, n_samples, figsize=(12, 4))\n",
    "    \n",
    "    # 原始圖像\n",
    "    for i in range(n_samples):\n",
    "        axes[0, i].imshow(data[i].cpu().squeeze(), cmap='gray')\n",
    "        axes[0, i].axis('off')\n",
    "    axes[0, 0].set_ylabel('原始', fontsize=10)\n",
    "    \n",
    "    # 各 beta 的重建\n",
    "    for row, beta in enumerate(betas, 1):\n",
    "        model = models[beta]\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            recon, _, _ = model(data)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            axes[row, i].imshow(recon[i].cpu().squeeze(), cmap='gray')\n",
    "            axes[row, i].axis('off')\n",
    "        axes[row, 0].set_ylabel(f'β={beta}', fontsize=10)\n",
    "    \n",
    "    plt.suptitle('不同 β 值的 VAE 重建比較')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_beta_reconstructions(beta_models, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 練習題\n",
    "\n",
    "### 練習 1: 條件 VAE (CVAE)\n",
    "\n",
    "**目標**: 實現條件 VAE，可以指定要生成的數字類別\n",
    "\n",
    "**提示**: 將類別標籤編碼後與輸入/潛在變量連接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1: 條件 VAE\n",
    "# Hint: 使用 one-hot 編碼將類別資訊加入編碼器和解碼器\n",
    "\n",
    "class ConditionalVAE(nn.Module):\n",
    "    \"\"\"\n",
    "    條件 VAE：可以指定生成特定類別\n",
    "    \n",
    "    修改：\n",
    "    1. 編碼器輸入：x + 類別 one-hot\n",
    "    2. 解碼器輸入：z + 類別 one-hot\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim: int = 32, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # 編碼器（輸入增加 num_classes 維度）\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(784 + num_classes, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(256, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256, latent_dim)\n",
    "        \n",
    "        # 解碼器（輸入增加 num_classes 維度）\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 784),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def encode(self, x: torch.Tensor, c: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        編碼：x + 條件 -> (mu, log_var)\n",
    "        \n",
    "        Args:\n",
    "            x: 輸入圖像 [B, 1, 28, 28]\n",
    "            c: 類別標籤 [B] (整數)\n",
    "        \"\"\"\n",
    "        # 展平圖像\n",
    "        x_flat = x.view(x.size(0), -1)  # [B, 784]\n",
    "        \n",
    "        # One-hot 編碼類別\n",
    "        c_onehot = F.one_hot(c, num_classes=self.num_classes).float()  # [B, num_classes]\n",
    "        \n",
    "        # 連接\n",
    "        x_cond = torch.cat([x_flat, c_onehot], dim=1)  # [B, 784 + num_classes]\n",
    "        \n",
    "        h = self.encoder(x_cond)\n",
    "        mu = self.fc_mu(h)\n",
    "        log_var = self.fc_logvar(h)\n",
    "        \n",
    "        return mu, log_var\n",
    "    \n",
    "    def reparameterize(self, mu: torch.Tensor, log_var: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def decode(self, z: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        解碼：z + 條件 -> x\n",
    "        \"\"\"\n",
    "        c_onehot = F.one_hot(c, num_classes=self.num_classes).float()\n",
    "        z_cond = torch.cat([z, c_onehot], dim=1)\n",
    "        return self.decoder(z_cond)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor, c: torch.Tensor):\n",
    "        mu, log_var = self.encode(x, c)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_recon = self.decode(z, c)\n",
    "        return x_recon, mu, log_var\n",
    "\n",
    "def train_cvae(model, train_loader, epochs=15, lr=1e-3):\n",
    "    \"\"\"訓練條件 VAE\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            recon, mu, log_var = model(data, labels)\n",
    "            loss, _, _ = vae_loss(recon.view(-1, 1, 28, 28), data, mu, log_var)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader.dataset):.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 訓練 CVAE\n",
    "cvae = ConditionalVAE(latent_dim=32, num_classes=10).to(device)\n",
    "cvae = train_cvae(cvae, train_loader, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_conditional_samples(model, n_per_class=5):\n",
    "    \"\"\"\n",
    "    使用 CVAE 為每個類別生成樣本\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(10, n_per_class, figsize=(n_per_class * 1.5, 15))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for digit in range(10):\n",
    "            # 為這個數字生成 n_per_class 個樣本\n",
    "            z = torch.randn(n_per_class, model.latent_dim).to(device)\n",
    "            c = torch.full((n_per_class,), digit, dtype=torch.long).to(device)\n",
    "            \n",
    "            samples = model.decode(z, c)\n",
    "            \n",
    "            for i in range(n_per_class):\n",
    "                axes[digit, i].imshow(samples[i].cpu().view(28, 28), cmap='gray')\n",
    "                axes[digit, i].axis('off')\n",
    "            \n",
    "            axes[digit, 0].set_ylabel(str(digit), fontsize=14, rotation=0, labelpad=15)\n",
    "    \n",
    "    plt.suptitle('條件 VAE 生成結果（每行一個數字）', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "generate_conditional_samples(cvae, n_per_class=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: VAE 異常檢測\n",
    "\n",
    "**目標**: 使用 VAE 的重建誤差來檢測異常樣本\n",
    "\n",
    "**提示**: 異常樣本的重建誤差通常較高"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 2: VAE 異常檢測\n",
    "\n",
    "class VAEAnomalyDetector:\n",
    "    \"\"\"\n",
    "    使用 VAE 進行異常檢測\n",
    "    \n",
    "    原理：\n",
    "    - VAE 在正常資料上訓練\n",
    "    - 對於異常資料，重建誤差會較高\n",
    "    - 設定閾值來判斷是否為異常\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vae_model, threshold_percentile: float = 95):\n",
    "        self.model = vae_model\n",
    "        self.threshold = None\n",
    "        self.threshold_percentile = threshold_percentile\n",
    "    \n",
    "    def compute_reconstruction_error(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"計算重建誤差\"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            x_recon, mu, log_var = self.model(x)\n",
    "            # 使用 MSE 作為重建誤差\n",
    "            error = F.mse_loss(x_recon, x.view(x.size(0), -1), reduction='none')\n",
    "            error = error.mean(dim=1)  # 每個樣本的平均誤差\n",
    "        return error\n",
    "    \n",
    "    def fit_threshold(self, train_loader):\n",
    "        \"\"\"在正常資料上計算閾值\"\"\"\n",
    "        all_errors = []\n",
    "        \n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            errors = self.compute_reconstruction_error(data)\n",
    "            all_errors.append(errors.cpu())\n",
    "        \n",
    "        all_errors = torch.cat(all_errors)\n",
    "        self.threshold = np.percentile(all_errors.numpy(), self.threshold_percentile)\n",
    "        \n",
    "        print(f\"閾值設定為 {self.threshold_percentile}th 百分位數: {self.threshold:.6f}\")\n",
    "        return self.threshold\n",
    "    \n",
    "    def predict(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        預測是否為異常\n",
    "        \n",
    "        Returns:\n",
    "            is_anomaly: 布林張量\n",
    "            errors: 重建誤差\n",
    "        \"\"\"\n",
    "        errors = self.compute_reconstruction_error(x)\n",
    "        is_anomaly = errors > self.threshold\n",
    "        return is_anomaly, errors\n",
    "\n",
    "# 訓練一個只在某些數字上的 VAE\n",
    "# 然後用其他數字作為「異常」\n",
    "\n",
    "# 建立只包含 0-4 的訓練集\n",
    "normal_digits = [0, 1, 2, 3, 4]\n",
    "anomaly_digits = [5, 6, 7, 8, 9]\n",
    "\n",
    "normal_indices = [i for i, (_, label) in enumerate(train_dataset) if label in normal_digits]\n",
    "normal_subset = torch.utils.data.Subset(train_dataset, normal_indices)\n",
    "normal_loader = DataLoader(normal_subset, batch_size=128, shuffle=True)\n",
    "\n",
    "print(f\"正常資料數量: {len(normal_subset)}\")\n",
    "\n",
    "# 訓練 VAE\n",
    "anomaly_vae = VAE(latent_dim=16).to(device)\n",
    "train_vae(anomaly_vae, normal_loader, epochs=10)\n",
    "\n",
    "# 設定檢測器\n",
    "detector = VAEAnomalyDetector(anomaly_vae, threshold_percentile=95)\n",
    "detector.fit_threshold(normal_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試異常檢測\n",
    "def test_anomaly_detection(detector, test_loader, normal_digits, anomaly_digits):\n",
    "    \"\"\"\n",
    "    測試異常檢測效果\n",
    "    \"\"\"\n",
    "    normal_errors = []\n",
    "    anomaly_errors = []\n",
    "    \n",
    "    for data, labels in test_loader:\n",
    "        data = data.to(device)\n",
    "        _, errors = detector.predict(data)\n",
    "        errors = errors.cpu().numpy()\n",
    "        labels = labels.numpy()\n",
    "        \n",
    "        for err, label in zip(errors, labels):\n",
    "            if label in normal_digits:\n",
    "                normal_errors.append(err)\n",
    "            else:\n",
    "                anomaly_errors.append(err)\n",
    "    \n",
    "    # 計算檢測率\n",
    "    threshold = detector.threshold\n",
    "    \n",
    "    tp = sum(1 for e in anomaly_errors if e > threshold)  # 真正例：異常被檢測為異常\n",
    "    fn = sum(1 for e in anomaly_errors if e <= threshold) # 假負例：異常被檢測為正常\n",
    "    fp = sum(1 for e in normal_errors if e > threshold)   # 假正例：正常被檢測為異常\n",
    "    tn = sum(1 for e in normal_errors if e <= threshold)  # 真負例：正常被檢測為正常\n",
    "    \n",
    "    print(\"\\n異常檢測結果：\")\n",
    "    print(f\"正常數字: {normal_digits}\")\n",
    "    print(f\"異常數字: {anomaly_digits}\")\n",
    "    print(f\"\\n混淆矩陣:\")\n",
    "    print(f\"           預測正常  預測異常\")\n",
    "    print(f\"實際正常     {tn:5d}     {fp:5d}\")\n",
    "    print(f\"實際異常     {fn:5d}     {tp:5d}\")\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n精確率: {precision:.4f}\")\n",
    "    print(f\"召回率: {recall:.4f}\")\n",
    "    print(f\"F1 分數: {f1:.4f}\")\n",
    "    \n",
    "    # 繪製誤差分佈\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.hist(normal_errors, bins=50, alpha=0.5, label=f'正常 ({normal_digits})', density=True)\n",
    "    plt.hist(anomaly_errors, bins=50, alpha=0.5, label=f'異常 ({anomaly_digits})', density=True)\n",
    "    plt.axvline(threshold, color='r', linestyle='--', label=f'閾值 ({threshold:.4f})')\n",
    "    plt.xlabel('重建誤差')\n",
    "    plt.ylabel('密度')\n",
    "    plt.title('VAE 異常檢測 - 重建誤差分佈')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "test_anomaly_detection(detector, test_loader, normal_digits, anomaly_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3: 潛在空間算術\n",
    "\n",
    "**目標**: 探索潛在空間中的語義運算（類似 word2vec 的 king - man + woman = queen）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 3: 潛在空間算術\n",
    "\n",
    "def get_class_mean_latent(model, data_loader, target_class):\n",
    "    \"\"\"\n",
    "    計算特定類別在潛在空間中的平均位置\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            mask = labels == target_class\n",
    "            if mask.any():\n",
    "                data = data[mask].to(device)\n",
    "                mu, _ = model.encode(data)\n",
    "                latents.append(mu.cpu())\n",
    "    \n",
    "    all_latents = torch.cat(latents, dim=0)\n",
    "    mean_latent = all_latents.mean(dim=0)\n",
    "    return mean_latent\n",
    "\n",
    "def latent_arithmetic_demo(model, test_loader):\n",
    "    \"\"\"\n",
    "    潛在空間算術示範\n",
    "    \n",
    "    例如：某個 3 - 平均的 3 + 平均的 8 = 看起來像 8 的結果\n",
    "    \"\"\"\n",
    "    \n",
    "    # 計算各類別的平均潛在向量\n",
    "    class_means = {}\n",
    "    for digit in range(10):\n",
    "        class_means[digit] = get_class_mean_latent(model, test_loader, digit)\n",
    "    \n",
    "    # 取一個具體的樣本\n",
    "    data, labels = next(iter(test_loader))\n",
    "    \n",
    "    # 找一個 3\n",
    "    idx_3 = (labels == 3).nonzero()[0].item()\n",
    "    sample_3 = data[idx_3:idx_3+1].to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z_sample_3, _ = model.encode(sample_3)\n",
    "        \n",
    "        # 算術：sample_3 - mean_3 + mean_8\n",
    "        z_transformed = z_sample_3 - class_means[3].to(device) + class_means[8].to(device)\n",
    "        \n",
    "        # 解碼\n",
    "        original = model.decode(z_sample_3)\n",
    "        transformed = model.decode(z_transformed)\n",
    "    \n",
    "    # 可視化\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(10, 2.5))\n",
    "    \n",
    "    axes[0].imshow(sample_3.cpu().squeeze(), cmap='gray')\n",
    "    axes[0].set_title('原始 (3)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(model.decode(class_means[3].unsqueeze(0).to(device)).cpu().squeeze().view(28, 28), cmap='gray')\n",
    "    axes[1].set_title('平均 3')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    axes[2].imshow(model.decode(class_means[8].unsqueeze(0).to(device)).cpu().squeeze().view(28, 28), cmap='gray')\n",
    "    axes[2].set_title('平均 8')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    axes[3].imshow(transformed.cpu().squeeze().view(28, 28), cmap='gray')\n",
    "    axes[3].set_title('原始 - 平均3 + 平均8')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.suptitle('潛在空間算術: 3 → 8 風格轉換')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 更多轉換示範\n",
    "    print(\"\\n更多風格轉換示範:\")\n",
    "    fig, axes = plt.subplots(4, 11, figsize=(14, 6))\n",
    "    \n",
    "    for row, source_digit in enumerate([1, 4, 7, 9]):\n",
    "        # 找一個源數字樣本\n",
    "        idx = (labels == source_digit).nonzero()[0].item()\n",
    "        sample = data[idx:idx+1].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            z_sample, _ = model.encode(sample)\n",
    "        \n",
    "        axes[row, 0].imshow(sample.cpu().squeeze(), cmap='gray')\n",
    "        axes[row, 0].axis('off')\n",
    "        axes[row, 0].set_title(f'原始 {source_digit}' if row == 0 else '')\n",
    "        \n",
    "        for col, target_digit in enumerate(range(10)):\n",
    "            with torch.no_grad():\n",
    "                z_transformed = z_sample - class_means[source_digit].to(device) + class_means[target_digit].to(device)\n",
    "                transformed = model.decode(z_transformed)\n",
    "            \n",
    "            axes[row, col+1].imshow(transformed.cpu().squeeze().view(28, 28), cmap='gray')\n",
    "            axes[row, col+1].axis('off')\n",
    "            if row == 0:\n",
    "                axes[row, col+1].set_title(f'→{target_digit}')\n",
    "    \n",
    "    plt.suptitle('潛在空間算術：行 = 源數字，列 = 目標風格')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "latent_arithmetic_demo(vae_model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 總結\n",
    "\n",
    "### 本模組重點\n",
    "\n",
    "1. **Autoencoder 基礎**\n",
    "   - 編碼器壓縮、解碼器重建\n",
    "   - 潛在空間捕捉資料本質特徵\n",
    "   - 可用於降維、特徵學習\n",
    "\n",
    "2. **VAE 關鍵改進**\n",
    "   - 編碼器輸出分佈參數 (μ, σ)\n",
    "   - 重參數化技巧使採樣可微分\n",
    "   - KL 散度正則化潛在空間\n",
    "\n",
    "3. **VAE 損失函數**\n",
    "   ```python\n",
    "   loss = reconstruction_loss + β * KL_divergence\n",
    "   KL = -0.5 * sum(1 + log_var - mu^2 - exp(log_var))\n",
    "   ```\n",
    "\n",
    "4. **應用**\n",
    "   - 生成新樣本\n",
    "   - 潛在空間插值\n",
    "   - 條件生成 (CVAE)\n",
    "   - 異常檢測\n",
    "   - 潛在空間算術\n",
    "\n",
    "### 重要概念\n",
    "\n",
    "```\n",
    "普通 AE: x → z → x'\n",
    "   VAE: x → (μ, σ) → z ~ N(μ, σ²) → x'\n",
    "              ↓\n",
    "         KL(N(μ,σ²) || N(0,1)) 正則化\n",
    "```\n",
    "\n",
    "### 下一步\n",
    "\n",
    "在下一個模組中，我們將學習 **GAN 和 Diffusion 模型**，這是更強大的生成模型，能生成更高品質的圖像。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## Module 7 完整總結\n\n### 🎯 核心概念\n\n| 模型 | 潛在表示 | 損失函數 | 生成能力 |\n|------|----------|----------|----------|\n| **AE** | 確定性向量 z | 重建損失 | 差（空洞） |\n| **VAE** | 分佈 N(μ, σ²) | 重建 + KL | 好（連續） |\n| **β-VAE** | 分佈（更正則化）| 重建 + β·KL | 更解糾纏 |\n| **CVAE** | 條件分佈 | 重建 + KL | 可控生成 |\n\n### 🔑 關鍵公式\n\n```\nVAE 損失:\n  L = E[log p(x|z)] - KL(q(z|x) || p(z))\n    = Recon Loss + KL Divergence\n\nKL 散度（高斯分佈）:\n  KL = -0.5 * Σ(1 + log(σ²) - μ² - σ²)\n\n重參數化技巧:\n  z = μ + σ * ε, where ε ~ N(0, 1)\n```\n\n### 💡 實務技巧\n\n1. **潛在維度選擇**：\n   - MNIST: 2-32 維\n   - 複雜圖像: 64-512 維\n   - 太小會丟失資訊，太大會過擬合\n\n2. **β 值調整**：\n   - β < 1: 重建優先（更清晰但潛在空間可能不規整）\n   - β = 1: 標準 VAE\n   - β > 1: 潛在空間更規整（解糾纏）但可能模糊\n\n3. **訓練穩定性**：\n   - 使用 KL annealing（逐漸增加 KL 權重）\n   - 監控 KL 是否 collapse（變成 0）\n\n4. **架構建議**：\n   - 圖像用卷積 VAE\n   - 使用 BatchNorm 穩定訓練\n   - 解碼器最後一層用 Sigmoid（如果輸入在 [0,1]）\n\n### 🚀 下一步\n\n- Module 8：GAN 與 Diffusion（更強大的生成模型）\n\n---\n\n**恭喜完成 VAE 模組！** 🎉\n\nVAE 是生成模型的重要基石，它的潛在空間概念也是理解 Stable Diffusion 等現代生成模型的關鍵。掌握了 VAE，你就為學習更先進的生成模型打下了堅實基礎。",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}