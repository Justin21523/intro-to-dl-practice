{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型合併 (Model Merging)\n",
    "\n",
    "本 notebook 對應李宏毅老師 2025 Spring ML HW9，探討如何合併多個微調模型來獲得綜合能力。\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "1. 理解模型合併的動機與挑戰\n",
    "2. 學習基本的權重平均方法\n",
    "3. 掌握 Task Arithmetic 技術\n",
    "4. 了解 TIES Merging 方法\n",
    "5. 使用 mergekit 進行實際操作\n",
    "\n",
    "## 參考資源\n",
    "\n",
    "- [Model Soups](https://arxiv.org/abs/2203.05482) - Averaging weights of multiple fine-tuned models\n",
    "- [Task Arithmetic](https://arxiv.org/abs/2212.04089) - Editing Models with Task Vectors\n",
    "- [TIES-Merging](https://arxiv.org/abs/2306.01708) - Resolving Interference When Merging Models\n",
    "- [mergekit](https://github.com/cg123/mergekit) - Model merging toolkit\n",
    "- [2025 Spring HW9](https://speech.ee.ntu.edu.tw/~hylee/ml/2025-spring.php)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 為什麼需要模型合併？\n",
    "\n",
    "### 1.1 動機與場景\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                      模型合併的動機                                       │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  場景 1: 結合多種能力                                                    │\n",
    "│  ─────────────────────                                                  │\n",
    "│  ┌──────────────┐   ┌──────────────┐   ┌──────────────┐                │\n",
    "│  │ Model A      │   │ Model B      │   │ Model C      │                │\n",
    "│  │ (程式碼能力) │ + │ (數學能力)   │ + │ (對話能力)   │                │\n",
    "│  └──────────────┘   └──────────────┘   └──────────────┘                │\n",
    "│           │                 │                 │                         │\n",
    "│           └─────────────────┼─────────────────┘                         │\n",
    "│                             ▼                                           │\n",
    "│                    ┌──────────────┐                                     │\n",
    "│                    │ Merged Model │                                     │\n",
    "│                    │ (全能模型)   │                                     │\n",
    "│                    └──────────────┘                                     │\n",
    "│                                                                         │\n",
    "│  場景 2: 避免訓練成本                                                    │\n",
    "│  ───────────────────                                                    │\n",
    "│  • 多個社群已經微調好的模型                                               │\n",
    "│  • 不需要重新訓練，直接合併權重                                           │\n",
    "│  • 節省 GPU 時間和資料收集成本                                            │\n",
    "│                                                                         │\n",
    "│  場景 3: 提升泛化能力 (Model Soups)                                      │\n",
    "│  ─────────────────────────────────                                      │\n",
    "│  • 同一任務的多個微調模型（不同超參數）                                    │\n",
    "│  • 合併後比單一模型泛化更好                                               │\n",
    "│  • 類似 ensemble 但只需要一個模型                                        │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 1.2 核心挑戰：權重干擾 (Weight Interference)\n",
    "\n",
    "直接平均不同任務的模型權重可能導致性能下降，因為不同任務的優化方向可能衝突。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 設定\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基本方法：Weight Averaging\n",
    "\n",
    "### 2.1 簡單平均 (Uniform Averaging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "    \"\"\"簡單的 MLP 模型用於展示合併概念\"\"\"\n",
    "    def __init__(self, input_dim=10, hidden_dim=32, output_dim=5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "\n",
    "def uniform_averaging(models: List[nn.Module]) -> OrderedDict:\n",
    "    \"\"\"\n",
    "    簡單的權重平均\n",
    "    \n",
    "    θ_merged = (1/N) * Σ θ_i\n",
    "    \"\"\"\n",
    "    if len(models) == 0:\n",
    "        raise ValueError(\"At least one model is required\")\n",
    "    \n",
    "    # 取得第一個模型的 state_dict 作為基準\n",
    "    merged_state = OrderedDict()\n",
    "    \n",
    "    # 初始化為零\n",
    "    for key, param in models[0].state_dict().items():\n",
    "        merged_state[key] = torch.zeros_like(param)\n",
    "    \n",
    "    # 累加所有模型的權重\n",
    "    for model in models:\n",
    "        state = model.state_dict()\n",
    "        for key in merged_state:\n",
    "            merged_state[key] += state[key]\n",
    "    \n",
    "    # 除以模型數量得到平均\n",
    "    n_models = len(models)\n",
    "    for key in merged_state:\n",
    "        merged_state[key] /= n_models\n",
    "    \n",
    "    return merged_state\n",
    "\n",
    "\n",
    "def weighted_averaging(models: List[nn.Module], \n",
    "                      weights: List[float]) -> OrderedDict:\n",
    "    \"\"\"\n",
    "    加權平均\n",
    "    \n",
    "    θ_merged = Σ w_i * θ_i, where Σ w_i = 1\n",
    "    \"\"\"\n",
    "    assert len(models) == len(weights)\n",
    "    assert abs(sum(weights) - 1.0) < 1e-6, \"Weights must sum to 1\"\n",
    "    \n",
    "    merged_state = OrderedDict()\n",
    "    \n",
    "    for key, param in models[0].state_dict().items():\n",
    "        merged_state[key] = torch.zeros_like(param)\n",
    "    \n",
    "    for model, w in zip(models, weights):\n",
    "        state = model.state_dict()\n",
    "        for key in merged_state:\n",
    "            merged_state[key] += w * state[key]\n",
    "    \n",
    "    return merged_state\n",
    "\n",
    "\n",
    "# 測試\n",
    "print(\"Weight Averaging 示範\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 創建三個模型（模擬不同任務微調後的模型）\n",
    "model_a = SimpleModel()\n",
    "model_b = SimpleModel()\n",
    "model_c = SimpleModel()\n",
    "\n",
    "# 簡單平均\n",
    "merged_uniform = uniform_averaging([model_a, model_b, model_c])\n",
    "print(f\"\\n簡單平均結果:\")\n",
    "print(f\"  fc1.weight 形狀: {merged_uniform['fc1.weight'].shape}\")\n",
    "print(f\"  fc1.weight 平均值: {merged_uniform['fc1.weight'].mean().item():.4f}\")\n",
    "\n",
    "# 加權平均\n",
    "weights = [0.5, 0.3, 0.2]  # Model A 權重較高\n",
    "merged_weighted = weighted_averaging([model_a, model_b, model_c], weights)\n",
    "print(f\"\\n加權平均結果 (weights={weights}):\")\n",
    "print(f\"  fc1.weight 平均值: {merged_weighted['fc1.weight'].mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Soups: 找到最佳權重組合\n",
    "def greedy_soup(\n",
    "    models: List[nn.Module],\n",
    "    val_data: Tuple[torch.Tensor, torch.Tensor],\n",
    "    base_model: nn.Module\n",
    ") -> Tuple[List[int], nn.Module]:\n",
    "    \"\"\"\n",
    "    Greedy Soup: 貪婪選擇要加入的模型\n",
    "    \n",
    "    演算法：\n",
    "    1. 從驗證分數最高的模型開始\n",
    "    2. 嘗試加入每個未選中的模型\n",
    "    3. 如果加入後分數提升，則保留\n",
    "    4. 重複直到沒有改進\n",
    "    \"\"\"\n",
    "    X_val, y_val = val_data\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def evaluate(model):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(X_val)\n",
    "            loss = criterion(output, y_val)\n",
    "            acc = (output.argmax(dim=1) == y_val).float().mean()\n",
    "        return acc.item()\n",
    "    \n",
    "    # 評估所有模型\n",
    "    scores = [evaluate(m) for m in models]\n",
    "    print(f\"Individual model scores: {[f'{s:.2%}' for s in scores]}\")\n",
    "    \n",
    "    # 從最好的模型開始\n",
    "    best_idx = np.argmax(scores)\n",
    "    selected = [best_idx]\n",
    "    \n",
    "    # 創建合併模型\n",
    "    merged = deepcopy(base_model)\n",
    "    merged.load_state_dict(models[best_idx].state_dict())\n",
    "    best_score = evaluate(merged)\n",
    "    \n",
    "    print(f\"\\nStarting with model {best_idx}, score: {best_score:.2%}\")\n",
    "    \n",
    "    # 貪婪添加\n",
    "    available = set(range(len(models))) - set(selected)\n",
    "    \n",
    "    while available:\n",
    "        best_candidate = None\n",
    "        best_new_score = best_score\n",
    "        \n",
    "        for idx in available:\n",
    "            # 嘗試加入這個模型\n",
    "            candidate_models = [models[i] for i in selected] + [models[idx]]\n",
    "            merged_state = uniform_averaging(candidate_models)\n",
    "            \n",
    "            temp_model = deepcopy(base_model)\n",
    "            temp_model.load_state_dict(merged_state)\n",
    "            score = evaluate(temp_model)\n",
    "            \n",
    "            if score > best_new_score:\n",
    "                best_new_score = score\n",
    "                best_candidate = idx\n",
    "        \n",
    "        if best_candidate is not None:\n",
    "            selected.append(best_candidate)\n",
    "            available.remove(best_candidate)\n",
    "            best_score = best_new_score\n",
    "            print(f\"Added model {best_candidate}, new score: {best_score:.2%}\")\n",
    "            \n",
    "            # 更新合併模型\n",
    "            selected_models = [models[i] for i in selected]\n",
    "            merged.load_state_dict(uniform_averaging(selected_models))\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    print(f\"\\nFinal soup: models {selected}, score: {best_score:.2%}\")\n",
    "    return selected, merged\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Greedy Soup 示範\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 創建一些模擬數據\n",
    "X_val = torch.randn(100, 10)\n",
    "y_val = torch.randint(0, 5, (100,))\n",
    "\n",
    "# 簡單訓練幾個不同的模型（模擬不同超參數或種子）\n",
    "def quick_train(model, X, y, epochs=50):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for _ in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(X), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "models = []\n",
    "for i in range(5):\n",
    "    torch.manual_seed(i)\n",
    "    m = SimpleModel()\n",
    "    # 用不同子集訓練\n",
    "    idx = torch.randperm(len(X_val))[:80]\n",
    "    m = quick_train(m, X_val[idx], y_val[idx])\n",
    "    models.append(m)\n",
    "\n",
    "base_model = SimpleModel()\n",
    "selected, merged_model = greedy_soup(models, (X_val, y_val), base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Task Arithmetic\n",
    "\n",
    "### 3.1 Task Vectors 概念\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                        Task Arithmetic 概念                              │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  核心想法：微調可以表示為「任務向量」的加法                                │\n",
    "│                                                                         │\n",
    "│  Task Vector 定義：                                                      │\n",
    "│  ─────────────────                                                      │\n",
    "│  τ_task = θ_finetuned - θ_pretrained                                   │\n",
    "│                                                                         │\n",
    "│  τ 代表了從 pretrained 到 task-specific 模型的「方向」                    │\n",
    "│                                                                         │\n",
    "│  操作：                                                                  │\n",
    "│  ──────                                                                 │\n",
    "│                                                                         │\n",
    "│  1. 任務加法 (Adding tasks)                                             │\n",
    "│     θ_multi = θ_pre + τ_A + τ_B                                        │\n",
    "│     → 獲得 Task A 和 Task B 的能力                                       │\n",
    "│                                                                         │\n",
    "│  2. 任務否定 (Negating tasks)                                           │\n",
    "│     θ_new = θ_pre - τ_toxic                                            │\n",
    "│     → 減少模型的有毒輸出傾向                                             │\n",
    "│                                                                         │\n",
    "│  3. 縮放 (Scaling)                                                      │\n",
    "│     θ_scaled = θ_pre + λ * τ                                           │\n",
    "│     → λ 控制任務能力的強度                                               │\n",
    "│                                                                         │\n",
    "│  視覺化：                                                                │\n",
    "│  ┌─────────────────────────────────────────────────────────────┐       │\n",
    "│  │                                                             │       │\n",
    "│  │                           * θ_A (Math model)                │       │\n",
    "│  │                          /                                  │       │\n",
    "│  │                         / τ_A                               │       │\n",
    "│  │                        /                                    │       │\n",
    "│  │    θ_pre * ─────────────────────────* θ_A+B (Multi-task)   │       │\n",
    "│  │                        \\             /                      │       │\n",
    "│  │                         \\ τ_B       / τ_A + τ_B             │       │\n",
    "│  │                          \\         /                        │       │\n",
    "│  │                           * θ_B (Code model)                │       │\n",
    "│  │                                                             │       │\n",
    "│  └─────────────────────────────────────────────────────────────┘       │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_task_vector(\n",
    "    pretrained_state: OrderedDict,\n",
    "    finetuned_state: OrderedDict\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    計算 Task Vector: τ = θ_finetuned - θ_pretrained\n",
    "    \"\"\"\n",
    "    task_vector = OrderedDict()\n",
    "    \n",
    "    for key in pretrained_state:\n",
    "        task_vector[key] = finetuned_state[key] - pretrained_state[key]\n",
    "    \n",
    "    return task_vector\n",
    "\n",
    "\n",
    "def apply_task_vector(\n",
    "    base_state: OrderedDict,\n",
    "    task_vector: OrderedDict,\n",
    "    scaling_factor: float = 1.0\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    應用 Task Vector: θ_new = θ_base + λ * τ\n",
    "    \"\"\"\n",
    "    new_state = OrderedDict()\n",
    "    \n",
    "    for key in base_state:\n",
    "        new_state[key] = base_state[key] + scaling_factor * task_vector[key]\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "\n",
    "def add_task_vectors(\n",
    "    task_vectors: List[OrderedDict],\n",
    "    weights: Optional[List[float]] = None\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    合併多個 Task Vectors\n",
    "    \n",
    "    τ_combined = Σ w_i * τ_i\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0] * len(task_vectors)\n",
    "    \n",
    "    combined = OrderedDict()\n",
    "    \n",
    "    for key in task_vectors[0]:\n",
    "        combined[key] = torch.zeros_like(task_vectors[0][key])\n",
    "        for tv, w in zip(task_vectors, weights):\n",
    "            combined[key] += w * tv[key]\n",
    "    \n",
    "    return combined\n",
    "\n",
    "\n",
    "# 示範 Task Arithmetic\n",
    "print(\"Task Arithmetic 示範\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 創建 pretrained 模型\n",
    "torch.manual_seed(0)\n",
    "pretrained = SimpleModel()\n",
    "pretrained_state = deepcopy(pretrained.state_dict())\n",
    "\n",
    "# 創建 Task A 微調模型（例如：數學任務）\n",
    "torch.manual_seed(1)\n",
    "finetuned_a = SimpleModel()\n",
    "# 模擬微調（實際上會用真實數據）\n",
    "for param in finetuned_a.parameters():\n",
    "    param.data += torch.randn_like(param) * 0.1\n",
    "\n",
    "# 創建 Task B 微調模型（例如：程式碼任務）\n",
    "torch.manual_seed(2)\n",
    "finetuned_b = SimpleModel()\n",
    "for param in finetuned_b.parameters():\n",
    "    param.data += torch.randn_like(param) * 0.1\n",
    "\n",
    "# 計算 Task Vectors\n",
    "task_vector_a = compute_task_vector(pretrained_state, finetuned_a.state_dict())\n",
    "task_vector_b = compute_task_vector(pretrained_state, finetuned_b.state_dict())\n",
    "\n",
    "print(f\"Task Vector A (fc1.weight) norm: {task_vector_a['fc1.weight'].norm().item():.4f}\")\n",
    "print(f\"Task Vector B (fc1.weight) norm: {task_vector_b['fc1.weight'].norm().item():.4f}\")\n",
    "\n",
    "# 合併 Task Vectors\n",
    "combined_tv = add_task_vectors([task_vector_a, task_vector_b], weights=[0.5, 0.5])\n",
    "print(f\"Combined Task Vector norm: {combined_tv['fc1.weight'].norm().item():.4f}\")\n",
    "\n",
    "# 應用到 pretrained 模型\n",
    "merged_state = apply_task_vector(pretrained_state, combined_tv, scaling_factor=1.0)\n",
    "print(f\"Merged model fc1.weight mean: {merged_state['fc1.weight'].mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化不同 scaling factor 的效果\n",
    "def visualize_task_arithmetic():\n",
    "    \"\"\"視覺化 Task Arithmetic 的概念\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 1. Task Vector 在 2D 空間的表示\n",
    "    ax = axes[0]\n",
    "    \n",
    "    # 原點 = pretrained\n",
    "    origin = np.array([0, 0])\n",
    "    \n",
    "    # Task vectors\n",
    "    tv_a = np.array([2, 1])   # Math task\n",
    "    tv_b = np.array([0.5, 2]) # Code task\n",
    "    tv_combined = tv_a + tv_b\n",
    "    \n",
    "    # 繪製向量\n",
    "    ax.arrow(0, 0, tv_a[0], tv_a[1], head_width=0.15, head_length=0.1, fc='blue', ec='blue', label='τ_math')\n",
    "    ax.arrow(0, 0, tv_b[0], tv_b[1], head_width=0.15, head_length=0.1, fc='red', ec='red', label='τ_code')\n",
    "    ax.arrow(0, 0, tv_combined[0], tv_combined[1], head_width=0.15, head_length=0.1, fc='green', ec='green', label='τ_combined')\n",
    "    \n",
    "    # 標記點\n",
    "    ax.scatter([0], [0], s=100, c='black', zorder=5, label='θ_pretrained')\n",
    "    ax.scatter([tv_a[0]], [tv_a[1]], s=100, c='blue', zorder=5)\n",
    "    ax.scatter([tv_b[0]], [tv_b[1]], s=100, c='red', zorder=5)\n",
    "    ax.scatter([tv_combined[0]], [tv_combined[1]], s=100, c='green', zorder=5)\n",
    "    \n",
    "    # 虛線表示組合路徑\n",
    "    ax.plot([tv_a[0], tv_combined[0]], [tv_a[1], tv_combined[1]], 'g--', alpha=0.5)\n",
    "    ax.plot([tv_b[0], tv_combined[0]], [tv_b[1], tv_combined[1]], 'g--', alpha=0.5)\n",
    "    \n",
    "    ax.set_xlim([-0.5, 4])\n",
    "    ax.set_ylim([-0.5, 4])\n",
    "    ax.set_xlabel('Weight Space Dimension 1')\n",
    "    ax.set_ylabel('Weight Space Dimension 2')\n",
    "    ax.set_title('Task Arithmetic: Adding Task Vectors')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # 2. Scaling Factor 的效果\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    scaling_factors = np.linspace(0, 2, 50)\n",
    "    task_performance = 1 - np.exp(-scaling_factors) + 0.1 * np.random.randn(50) * 0.1  # 模擬\n",
    "    general_performance = 1 - 0.3 * scaling_factors + 0.1 * np.random.randn(50) * 0.1  # 模擬\n",
    "    \n",
    "    ax2.plot(scaling_factors, task_performance, 'b-', linewidth=2, label='Task Performance')\n",
    "    ax2.plot(scaling_factors, general_performance, 'r-', linewidth=2, label='General Performance')\n",
    "    \n",
    "    # 標記最佳點\n",
    "    combined = task_performance + general_performance\n",
    "    best_idx = np.argmax(combined)\n",
    "    ax2.axvline(x=scaling_factors[best_idx], color='green', linestyle='--', label=f'Optimal λ={scaling_factors[best_idx]:.2f}')\n",
    "    \n",
    "    ax2.set_xlabel('Scaling Factor (λ)')\n",
    "    ax2.set_ylabel('Performance')\n",
    "    ax2.set_title('Effect of Scaling Factor')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n關鍵觀察：\")\n",
    "    print(\"1. Task vectors 可以在權重空間中相加\")\n",
    "    print(\"2. Scaling factor λ 控制任務能力的強度\")\n",
    "    print(\"3. 需要平衡任務性能和通用能力\")\n",
    "\n",
    "visualize_task_arithmetic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TIES-Merging\n",
    "\n",
    "### 4.1 TIES 方法概覽\n",
    "\n",
    "TIES = **T**rim, **I**ncrease magnitude, **E**lect **S**ign\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                        TIES-Merging 流程                                 │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  問題：直接合併 task vectors 會有干擾（interference）                     │\n",
    "│                                                                         │\n",
    "│  解決方案：TIES 三步驟                                                   │\n",
    "│                                                                         │\n",
    "│  Step 1: TRIM - 修剪小值                                                │\n",
    "│  ────────────────────────                                               │\n",
    "│  • 將 magnitude 較小的參數設為 0                                         │\n",
    "│  • 保留 top-k% 最大的參數                                                │\n",
    "│  • 減少噪音影響                                                          │\n",
    "│                                                                         │\n",
    "│  Step 2: ELECT SIGN - 選擇符號                                          │\n",
    "│  ─────────────────────────                                              │\n",
    "│  • 對於每個參數位置，統計各 task vector 的符號                            │\n",
    "│  • 選擇「多數票」的符號作為最終符號                                       │\n",
    "│  • 只保留符號一致的值                                                    │\n",
    "│                                                                         │\n",
    "│  Step 3: DISJOINT MERGE - 合併                                          │\n",
    "│  ─────────────────────────                                              │\n",
    "│  • 對於每個參數位置，平均所有符號一致的值                                  │\n",
    "│  • 忽略符號不一致的值（它們會互相抵消）                                    │\n",
    "│                                                                         │\n",
    "│  視覺化範例：                                                            │\n",
    "│  ┌─────────────────────────────────────────────────────────────┐       │\n",
    "│  │  Parameter position i:                                      │       │\n",
    "│  │                                                             │       │\n",
    "│  │  τ_A[i] = +0.5   ─┐                                        │       │\n",
    "│  │  τ_B[i] = +0.3   ─┼─→ 符號一致 (+) → merged = avg(+0.5, +0.3) = +0.4│\n",
    "│  │  τ_C[i] = -0.2   ─┘     被忽略（少數）                       │       │\n",
    "│  │                                                             │       │\n",
    "│  └─────────────────────────────────────────────────────────────┘       │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ties_merging(\n",
    "    task_vectors: List[OrderedDict],\n",
    "    trim_ratio: float = 0.2,\n",
    "    scaling_factor: float = 1.0\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    TIES-Merging 實作\n",
    "    \n",
    "    Args:\n",
    "        task_vectors: 多個 task vectors\n",
    "        trim_ratio: 要修剪掉的比例 (0-1)\n",
    "        scaling_factor: 最終縮放係數\n",
    "    \"\"\"\n",
    "    merged = OrderedDict()\n",
    "    \n",
    "    for key in task_vectors[0]:\n",
    "        # 收集所有 task vectors 在這個參數位置的值\n",
    "        values = torch.stack([tv[key] for tv in task_vectors])  # [num_tasks, ...]\n",
    "        \n",
    "        # Step 1: TRIM - 修剪小值\n",
    "        trimmed_values = []\n",
    "        for tv in values:\n",
    "            # 計算閾值\n",
    "            magnitudes = tv.abs()\n",
    "            threshold = torch.quantile(magnitudes.flatten(), trim_ratio)\n",
    "            \n",
    "            # 修剪\n",
    "            trimmed = tv.clone()\n",
    "            trimmed[magnitudes < threshold] = 0\n",
    "            trimmed_values.append(trimmed)\n",
    "        \n",
    "        trimmed_values = torch.stack(trimmed_values)  # [num_tasks, ...]\n",
    "        \n",
    "        # Step 2: ELECT SIGN - 選擇符號\n",
    "        # 計算每個位置的符號投票\n",
    "        signs = torch.sign(trimmed_values)  # [num_tasks, ...]\n",
    "        sign_sum = signs.sum(dim=0)  # 正數表示正號多，負數表示負號多\n",
    "        elected_sign = torch.sign(sign_sum)  # 多數票符號\n",
    "        \n",
    "        # 處理平票的情況（設為 0）\n",
    "        elected_sign[sign_sum == 0] = 0\n",
    "        \n",
    "        # Step 3: DISJOINT MERGE - 只合併符號一致的值\n",
    "        # 創建 mask：只保留符號與 elected_sign 一致的值\n",
    "        mask = (signs == elected_sign.unsqueeze(0)) & (trimmed_values != 0)\n",
    "        \n",
    "        # 計算符合條件的值的平均\n",
    "        masked_values = trimmed_values * mask.float()\n",
    "        count = mask.float().sum(dim=0).clamp(min=1)  # 避免除以零\n",
    "        merged_param = masked_values.sum(dim=0) / count\n",
    "        \n",
    "        merged[key] = scaling_factor * merged_param\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "# 測試 TIES-Merging\n",
    "print(\"TIES-Merging 示範\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 使用之前創建的 task vectors\n",
    "ties_merged = ties_merging(\n",
    "    [task_vector_a, task_vector_b],\n",
    "    trim_ratio=0.2,\n",
    "    scaling_factor=1.0\n",
    ")\n",
    "\n",
    "print(f\"TIES merged fc1.weight norm: {ties_merged['fc1.weight'].norm().item():.4f}\")\n",
    "print(f\"Simple average norm: {combined_tv['fc1.weight'].norm().item():.4f}\")\n",
    "\n",
    "# 比較稀疏性\n",
    "ties_sparsity = (ties_merged['fc1.weight'] == 0).float().mean().item()\n",
    "simple_sparsity = (combined_tv['fc1.weight'] == 0).float().mean().item()\n",
    "print(f\"\\nTIES sparsity: {ties_sparsity:.2%}\")\n",
    "print(f\"Simple average sparsity: {simple_sparsity:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dare_merging(\n",
    "    task_vectors: List[OrderedDict],\n",
    "    drop_rate: float = 0.9,\n",
    "    scaling_factor: float = 1.0\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    DARE (Drop And REscale) Merging\n",
    "    \n",
    "    另一種減少干擾的方法：\n",
    "    1. 隨機 drop 一部分參數\n",
    "    2. 重新縮放保留的參數\n",
    "    3. 合併\n",
    "    \"\"\"\n",
    "    merged = OrderedDict()\n",
    "    rescale = 1.0 / (1.0 - drop_rate)\n",
    "    \n",
    "    for key in task_vectors[0]:\n",
    "        values = torch.stack([tv[key] for tv in task_vectors])\n",
    "        \n",
    "        # 隨機 drop 並重新縮放\n",
    "        dropped_values = []\n",
    "        for tv in values:\n",
    "            mask = torch.bernoulli(torch.ones_like(tv) * (1 - drop_rate))\n",
    "            dropped = tv * mask * rescale\n",
    "            dropped_values.append(dropped)\n",
    "        \n",
    "        dropped_values = torch.stack(dropped_values)\n",
    "        merged[key] = scaling_factor * dropped_values.mean(dim=0)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "# 測試 DARE\n",
    "print(\"\\nDARE Merging 示範\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dare_merged = dare_merging(\n",
    "    [task_vector_a, task_vector_b],\n",
    "    drop_rate=0.9,\n",
    "    scaling_factor=1.0\n",
    ")\n",
    "\n",
    "print(f\"DARE merged fc1.weight norm: {dare_merged['fc1.weight'].norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 使用 mergekit\n",
    "\n",
    "### 5.1 mergekit 簡介\n",
    "\n",
    "mergekit 是一個實用的模型合併工具，支援多種合併方法。\n",
    "\n",
    "```yaml\n",
    "# mergekit 配置文件範例\n",
    "merge_method: ties\n",
    "slices:\n",
    "  - sources:\n",
    "      - model: base_model\n",
    "        layer_range: [0, 32]\n",
    "      - model: math_lora\n",
    "        layer_range: [0, 32]\n",
    "      - model: code_lora\n",
    "        layer_range: [0, 32]\n",
    "base_model: base_model\n",
    "parameters:\n",
    "  density: 0.5     # TIES 保留比例\n",
    "  weight: 1.0      # 縮放係數\n",
    "dtype: float16\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬 mergekit 風格的 API\n",
    "class ModelMerger:\n",
    "    \"\"\"\n",
    "    模型合併器（模擬 mergekit 功能）\n",
    "    \"\"\"\n",
    "    METHODS = ['linear', 'slerp', 'ties', 'dare', 'task_arithmetic']\n",
    "    \n",
    "    def __init__(self, base_model: nn.Module):\n",
    "        self.base_model = base_model\n",
    "        self.base_state = deepcopy(base_model.state_dict())\n",
    "    \n",
    "    def merge(\n",
    "        self,\n",
    "        models: List[nn.Module],\n",
    "        method: str = 'linear',\n",
    "        weights: Optional[List[float]] = None,\n",
    "        **kwargs\n",
    "    ) -> nn.Module:\n",
    "        \"\"\"\n",
    "        合併多個模型\n",
    "        \n",
    "        Args:\n",
    "            models: 要合併的模型列表\n",
    "            method: 合併方法\n",
    "            weights: 各模型的權重\n",
    "            **kwargs: 方法特定的參數\n",
    "        \"\"\"\n",
    "        if method not in self.METHODS:\n",
    "            raise ValueError(f\"Unknown method: {method}. Available: {self.METHODS}\")\n",
    "        \n",
    "        print(f\"Merging {len(models)} models using {method} method...\")\n",
    "        \n",
    "        if method == 'linear':\n",
    "            if weights is None:\n",
    "                merged_state = uniform_averaging(models)\n",
    "            else:\n",
    "                merged_state = weighted_averaging(models, weights)\n",
    "        \n",
    "        elif method == 'task_arithmetic':\n",
    "            task_vectors = [\n",
    "                compute_task_vector(self.base_state, m.state_dict())\n",
    "                for m in models\n",
    "            ]\n",
    "            combined_tv = add_task_vectors(task_vectors, weights)\n",
    "            scaling = kwargs.get('scaling_factor', 1.0)\n",
    "            merged_state = apply_task_vector(self.base_state, combined_tv, scaling)\n",
    "        \n",
    "        elif method == 'ties':\n",
    "            task_vectors = [\n",
    "                compute_task_vector(self.base_state, m.state_dict())\n",
    "                for m in models\n",
    "            ]\n",
    "            trim_ratio = kwargs.get('trim_ratio', 0.2)\n",
    "            scaling = kwargs.get('scaling_factor', 1.0)\n",
    "            merged_tv = ties_merging(task_vectors, trim_ratio, scaling)\n",
    "            merged_state = apply_task_vector(self.base_state, merged_tv, 1.0)\n",
    "        \n",
    "        elif method == 'dare':\n",
    "            task_vectors = [\n",
    "                compute_task_vector(self.base_state, m.state_dict())\n",
    "                for m in models\n",
    "            ]\n",
    "            drop_rate = kwargs.get('drop_rate', 0.9)\n",
    "            scaling = kwargs.get('scaling_factor', 1.0)\n",
    "            merged_tv = dare_merging(task_vectors, drop_rate, scaling)\n",
    "            merged_state = apply_task_vector(self.base_state, merged_tv, 1.0)\n",
    "        \n",
    "        elif method == 'slerp':\n",
    "            # 球面線性插值（用於兩個模型）\n",
    "            if len(models) != 2:\n",
    "                raise ValueError(\"SLERP requires exactly 2 models\")\n",
    "            t = kwargs.get('t', 0.5)\n",
    "            merged_state = self._slerp(models[0].state_dict(), models[1].state_dict(), t)\n",
    "        \n",
    "        # 創建合併後的模型\n",
    "        merged_model = deepcopy(self.base_model)\n",
    "        merged_model.load_state_dict(merged_state)\n",
    "        \n",
    "        print(\"Merge complete!\")\n",
    "        return merged_model\n",
    "    \n",
    "    def _slerp(self, state_a: OrderedDict, state_b: OrderedDict, t: float) -> OrderedDict:\n",
    "        \"\"\"\n",
    "        球面線性插值 (Spherical Linear Interpolation)\n",
    "        \n",
    "        對於單位向量 v0, v1 和插值參數 t:\n",
    "        slerp(v0, v1, t) = sin((1-t)Ω)/sin(Ω) * v0 + sin(tΩ)/sin(Ω) * v1\n",
    "        其中 Ω = arccos(v0·v1)\n",
    "        \"\"\"\n",
    "        result = OrderedDict()\n",
    "        \n",
    "        for key in state_a:\n",
    "            a = state_a[key].flatten().float()\n",
    "            b = state_b[key].flatten().float()\n",
    "            \n",
    "            # 正規化\n",
    "            a_norm = a / (a.norm() + 1e-8)\n",
    "            b_norm = b / (b.norm() + 1e-8)\n",
    "            \n",
    "            # 計算角度\n",
    "            dot = torch.clamp((a_norm * b_norm).sum(), -1, 1)\n",
    "            omega = torch.acos(dot)\n",
    "            \n",
    "            if omega.abs() < 1e-6:\n",
    "                # 角度很小，用線性插值\n",
    "                result[key] = ((1 - t) * state_a[key] + t * state_b[key])\n",
    "            else:\n",
    "                # SLERP\n",
    "                sin_omega = torch.sin(omega)\n",
    "                coef_a = torch.sin((1 - t) * omega) / sin_omega\n",
    "                coef_b = torch.sin(t * omega) / sin_omega\n",
    "                result[key] = (coef_a * state_a[key] + coef_b * state_b[key])\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# 使用範例\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ModelMerger 使用範例\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "merger = ModelMerger(pretrained)\n",
    "\n",
    "# 測試不同方法\n",
    "for method in ['linear', 'task_arithmetic', 'ties']:\n",
    "    print(f\"\\n--- {method.upper()} ---\")\n",
    "    merged = merger.merge(\n",
    "        [finetuned_a, finetuned_b],\n",
    "        method=method,\n",
    "        weights=[0.5, 0.5],\n",
    "        scaling_factor=1.0,\n",
    "        trim_ratio=0.2\n",
    "    )\n",
    "    print(f\"  Merged model fc1.weight mean: {merged.fc1.weight.data.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LoRA 模型合併\n",
    "\n",
    "### 6.1 合併多個 LoRA Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRALinear(nn.Module):\n",
    "    \"\"\"簡化的 LoRA Linear 層\"\"\"\n",
    "    def __init__(self, in_features, out_features, rank=8, alpha=16):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.lora_A = nn.Parameter(torch.randn(rank, in_features) * 0.01)\n",
    "        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))\n",
    "        self.scaling = alpha / rank\n",
    "    \n",
    "    def forward(self, x):\n",
    "        base_out = self.linear(x)\n",
    "        lora_out = (x @ self.lora_A.T @ self.lora_B.T) * self.scaling\n",
    "        return base_out + lora_out\n",
    "    \n",
    "    def get_merged_weight(self):\n",
    "        \"\"\"將 LoRA 權重合併到基礎權重\"\"\"\n",
    "        delta_w = (self.lora_B @ self.lora_A) * self.scaling\n",
    "        return self.linear.weight.data + delta_w\n",
    "    \n",
    "    def get_lora_weight(self):\n",
    "        \"\"\"取得 LoRA delta 權重\"\"\"\n",
    "        return (self.lora_B @ self.lora_A) * self.scaling\n",
    "\n",
    "\n",
    "def merge_lora_adapters(\n",
    "    base_linear: nn.Linear,\n",
    "    lora_adapters: List[Tuple[torch.Tensor, torch.Tensor, float]],\n",
    "    weights: Optional[List[float]] = None,\n",
    "    method: str = 'linear'\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    合併多個 LoRA adapters\n",
    "    \n",
    "    Args:\n",
    "        base_linear: 基礎 Linear 層\n",
    "        lora_adapters: [(lora_A, lora_B, scaling), ...]\n",
    "        weights: 各 adapter 的權重\n",
    "        method: 合併方法\n",
    "    \n",
    "    Returns:\n",
    "        合併後的權重\n",
    "    \"\"\"\n",
    "    if weights is None:\n",
    "        weights = [1.0 / len(lora_adapters)] * len(lora_adapters)\n",
    "    \n",
    "    # 計算所有 LoRA delta\n",
    "    deltas = []\n",
    "    for lora_A, lora_B, scaling in lora_adapters:\n",
    "        delta = (lora_B @ lora_A) * scaling\n",
    "        deltas.append(delta)\n",
    "    \n",
    "    if method == 'linear':\n",
    "        # 加權平均\n",
    "        merged_delta = sum(w * d for w, d in zip(weights, deltas))\n",
    "    \n",
    "    elif method == 'cat':\n",
    "        # 串接（需要特殊處理）\n",
    "        # 這只是概念展示，實際上串接會改變維度\n",
    "        merged_delta = sum(deltas) / len(deltas)\n",
    "    \n",
    "    return base_linear.weight.data + merged_delta\n",
    "\n",
    "\n",
    "# 示範 LoRA 合併\n",
    "print(\"LoRA Adapter 合併示範\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 創建基礎層和多個 LoRA adapters\n",
    "in_dim, out_dim, rank = 64, 32, 8\n",
    "base_linear = nn.Linear(in_dim, out_dim, bias=False)\n",
    "\n",
    "# 模擬不同任務的 LoRA adapters\n",
    "lora_adapters = []\n",
    "for i in range(3):\n",
    "    torch.manual_seed(i + 100)\n",
    "    lora_A = torch.randn(rank, in_dim) * 0.01\n",
    "    lora_B = torch.randn(out_dim, rank) * 0.01\n",
    "    scaling = 16 / rank\n",
    "    lora_adapters.append((lora_A, lora_B, scaling))\n",
    "\n",
    "# 合併\n",
    "merged_weight = merge_lora_adapters(\n",
    "    base_linear,\n",
    "    lora_adapters,\n",
    "    weights=[0.4, 0.3, 0.3],\n",
    "    method='linear'\n",
    ")\n",
    "\n",
    "print(f\"Base weight shape: {base_linear.weight.shape}\")\n",
    "print(f\"Merged weight shape: {merged_weight.shape}\")\n",
    "print(f\"Weight change norm: {(merged_weight - base_linear.weight.data).norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 練習題\n",
    "\n",
    "### 練習 1：實作自適應權重選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1：實作基於驗證集表現的自適應權重\n",
    "def adaptive_weight_search(\n",
    "    models: List[nn.Module],\n",
    "    val_data: Tuple[torch.Tensor, torch.Tensor],\n",
    "    base_model: nn.Module,\n",
    "    num_samples: int = 50\n",
    ") -> Tuple[List[float], nn.Module]:\n",
    "    \"\"\"\n",
    "    TODO: 搜尋最佳的合併權重\n",
    "    \n",
    "    方法：\n",
    "    1. 隨機採樣多組權重（使用 Dirichlet 分布）\n",
    "    2. 對每組權重，合併模型並在驗證集評估\n",
    "    3. 選擇最佳權重\n",
    "    \n",
    "    Args:\n",
    "        models: 要合併的模型\n",
    "        val_data: (X_val, y_val)\n",
    "        base_model: 用於創建合併模型的模板\n",
    "        num_samples: 要嘗試的權重組合數量\n",
    "    \n",
    "    Returns:\n",
    "        (best_weights, best_model)\n",
    "    \"\"\"\n",
    "    # 提示：\n",
    "    # 1. 使用 np.random.dirichlet 生成權重\n",
    "    # 2. 使用 weighted_averaging 合併\n",
    "    # 3. 評估合併模型\n",
    "    pass\n",
    "\n",
    "print(\"練習 1：實作 adaptive_weight_search 函數\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2：實作 Layer-wise 合併"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 2：對不同層使用不同的合併策略\n",
    "def layerwise_merge(\n",
    "    models: List[nn.Module],\n",
    "    layer_configs: Dict[str, Dict]\n",
    ") -> OrderedDict:\n",
    "    \"\"\"\n",
    "    TODO: 對不同層使用不同的合併配置\n",
    "    \n",
    "    想法：\n",
    "    - 底層（embedding）可能需要更保守的合併\n",
    "    - 頂層可能可以更激進地合併\n",
    "    \n",
    "    Args:\n",
    "        models: 要合併的模型\n",
    "        layer_configs: {\n",
    "            \"fc1\": {\"method\": \"ties\", \"trim_ratio\": 0.3},\n",
    "            \"fc2\": {\"method\": \"linear\", \"weights\": [0.5, 0.5]},\n",
    "            \"fc3\": {\"method\": \"slerp\", \"t\": 0.5}\n",
    "        }\n",
    "    \n",
    "    Returns:\n",
    "        合併後的 state_dict\n",
    "    \"\"\"\n",
    "    # 提示：\n",
    "    # 1. 遍歷每個參數\n",
    "    # 2. 根據層名稱查找對應的配置\n",
    "    # 3. 應用對應的合併方法\n",
    "    pass\n",
    "\n",
    "print(\"練習 2：實作 layerwise_merge 函數\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3：分析合併效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 3：分析不同合併方法的效果\n",
    "def analyze_merge_quality(\n",
    "    original_models: List[nn.Module],\n",
    "    merged_model: nn.Module,\n",
    "    test_datasets: Dict[str, Tuple[torch.Tensor, torch.Tensor]]\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    TODO: 分析合併模型的品質\n",
    "    \n",
    "    分析項目：\n",
    "    1. 各任務的性能保持程度\n",
    "    2. 權重干擾程度\n",
    "    3. 與原始模型的距離\n",
    "    \n",
    "    Args:\n",
    "        original_models: 原始的專門模型\n",
    "        merged_model: 合併後的模型\n",
    "        test_datasets: {\"task_a\": (X, y), \"task_b\": (X, y), ...}\n",
    "    \n",
    "    Returns:\n",
    "        分析結果字典\n",
    "    \"\"\"\n",
    "    # 提示：\n",
    "    # 1. 評估每個任務的準確率\n",
    "    # 2. 計算權重變化的統計量\n",
    "    # 3. 繪製比較圖表\n",
    "    pass\n",
    "\n",
    "print(\"練習 3：實作 analyze_merge_quality 函數\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 總結\n",
    "\n",
    "### 8.1 合併方法比較\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                      模型合併方法比較                                     │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│  方法               │ 優點                    │ 缺點                    │\n",
    "│  ───────────────────────────────────────────────────────────────────── │\n",
    "│  Linear Average    │ 簡單、快速              │ 可能有嚴重干擾          │\n",
    "│                    │ 不需要額外計算          │ 不同任務可能衝突        │\n",
    "│  ───────────────────────────────────────────────────────────────────── │\n",
    "│  Task Arithmetic   │ 概念清晰               │ 需要調整 scaling        │\n",
    "│                    │ 可以做加減法            │ 干擾問題仍存在          │\n",
    "│  ───────────────────────────────────────────────────────────────────── │\n",
    "│  TIES              │ 減少干擾               │ 計算較複雜              │\n",
    "│                    │ 符號一致性             │ 可能丟失有用資訊        │\n",
    "│  ───────────────────────────────────────────────────────────────────── │\n",
    "│  DARE              │ 簡單有效               │ 隨機性                  │\n",
    "│                    │ 減少冗餘               │ 需要多次嘗試            │\n",
    "│  ───────────────────────────────────────────────────────────────────── │\n",
    "│  SLERP             │ 平滑插值               │ 只適用於兩個模型        │\n",
    "│                    │ 保持範數               │                         │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 8.2 實際應用建議\n",
    "\n",
    "1. **相似任務**：Linear Average 或 Model Soups\n",
    "2. **不同任務**：TIES 或 Task Arithmetic\n",
    "3. **多個 LoRA**：先評估各自性能，再選擇合併策略\n",
    "4. **生產環境**：務必在驗證集上評估合併效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"模型合併 - 學習完成！\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n你已經學會：\")\n",
    "print(\"✓ 理解模型合併的動機與挑戰\")\n",
    "print(\"✓ Weight Averaging 和 Model Soups\")\n",
    "print(\"✓ Task Arithmetic（任務向量加法）\")\n",
    "print(\"✓ TIES-Merging 減少干擾\")\n",
    "print(\"✓ LoRA Adapter 合併\")\n",
    "print(\"\\n下一步學習建議：\")\n",
    "print(\"1. 使用 mergekit 合併真實的 LLM\")\n",
    "print(\"2. 探索 frankenmerge（混合不同層）\")\n",
    "print(\"3. 研究 Layer-wise 合併策略\")\n",
    "print(\"4. 了解合併與 continual learning 的關係\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
