{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM 微調技術 (LLM Fine-tuning Techniques)\n",
    "\n",
    "**對應課程**: 李宏毅 2025 Spring ML HW5, 2025 Fall GenAI-ML HW7\n",
    "\n",
    "本 notebook 涵蓋大型語言模型的微調技術，包括 Full Fine-tuning、LoRA、QLoRA 等高效微調方法。\n",
    "\n",
    "## 學習目標\n",
    "1. 理解 Full Fine-tuning vs PEFT 的差異\n",
    "2. 掌握 LoRA 的原理與實作\n",
    "3. 學會 QLoRA（4-bit 量化 + LoRA）\n",
    "4. 了解訓練資料格式與準備\n",
    "5. 實作使用 PEFT 庫微調小型 LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: 為什麼需要微調？\n",
    "\n",
    "### 1.1 預訓練 vs 微調\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     LLM 訓練階段                                 │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  ┌──────────────────────────────────────────────────────────┐  │\n",
    "│  │                    Pre-training                           │  │\n",
    "│  │  • 海量無標註資料（TB 級別）                               │  │\n",
    "│  │  • 自監督學習（Next Token Prediction）                    │  │\n",
    "│  │  • 學習語言的通用表示                                     │  │\n",
    "│  │  • 需要大量 GPU 資源（數千 GPU-days）                     │  │\n",
    "│  └──────────────────────────────────────────────────────────┘  │\n",
    "│                            ↓                                    │\n",
    "│  ┌──────────────────────────────────────────────────────────┐  │\n",
    "│  │                    Fine-tuning                            │  │\n",
    "│  │  • 小量標註資料（數千到數萬筆）                            │  │\n",
    "│  │  • 監督學習（特定任務）                                   │  │\n",
    "│  │  • 適應特定領域或任務                                     │  │\n",
    "│  │  • 較少 GPU 資源（單卡或數卡）                            │  │\n",
    "│  └──────────────────────────────────────────────────────────┘  │\n",
    "│                            ↓                                    │\n",
    "│  ┌──────────────────────────────────────────────────────────┐  │\n",
    "│  │                    Alignment (RLHF/DPO)                   │  │\n",
    "│  │  • 人類偏好資料                                           │  │\n",
    "│  │  • 讓模型輸出符合人類期望                                  │  │\n",
    "│  └──────────────────────────────────────────────────────────┘  │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 微調的應用場景\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                   微調的主要用途                                │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│  1. 領域適應 (Domain Adaptation)                               │\n",
    "│     • 醫療、法律、金融等專業領域                               │\n",
    "│     • 學習領域專有術語和知識                                   │\n",
    "│                                                                │\n",
    "│  2. 任務特化 (Task Specialization)                             │\n",
    "│     • 程式碼生成、摘要、翻譯                                   │\n",
    "│     • 提高特定任務的效能                                       │\n",
    "│                                                                │\n",
    "│  3. 風格調整 (Style Adaptation)                                │\n",
    "│     • 品牌語調、正式/非正式                                    │\n",
    "│     • 特定角色或人格                                           │\n",
    "│                                                                │\n",
    "│  4. 指令遵循 (Instruction Following)                           │\n",
    "│     • 讓模型更好地遵循指令                                     │\n",
    "│     • 提高對話能力                                             │\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設置\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "\n",
    "print(\"\\n建議安裝的套件:\")\n",
    "print(\"  pip install transformers peft bitsandbytes accelerate datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Full Fine-tuning vs PEFT\n",
    "\n",
    "### 2.1 Full Fine-tuning 的挑戰\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                 Full Fine-tuning 的問題                        │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│  記憶體需求 (以 7B 模型為例):                                   │\n",
    "│  ┌──────────────────────────────────────────────────────────┐ │\n",
    "│  │ 模型參數 (FP16):     7B × 2 bytes = 14 GB                │ │\n",
    "│  │ 梯度 (FP16):         7B × 2 bytes = 14 GB                │ │\n",
    "│  │ 優化器狀態 (Adam):   7B × 8 bytes = 56 GB                │ │\n",
    "│  │ 激活值:              視 batch size 而定                   │ │\n",
    "│  │ ─────────────────────────────────────────────            │ │\n",
    "│  │ 總計:                約 84 GB + 激活值                    │ │\n",
    "│  └──────────────────────────────────────────────────────────┘ │\n",
    "│                                                                │\n",
    "│  其他問題:                                                     │\n",
    "│  • 災難性遺忘 (Catastrophic Forgetting)                       │\n",
    "│  • 每個任務需要儲存完整模型副本                                │\n",
    "│  • 訓練時間長                                                 │\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化不同模型規模的記憶體需求\n",
    "def visualize_memory_requirements():\n",
    "    \"\"\"視覺化 Full Fine-tuning 的記憶體需求\"\"\"\n",
    "    \n",
    "    model_sizes = ['1B', '3B', '7B', '13B', '70B']\n",
    "    param_counts = [1, 3, 7, 13, 70]  # 十億\n",
    "    \n",
    "    # 計算各項記憶體需求 (GB)\n",
    "    model_memory = [p * 2 for p in param_counts]  # FP16\n",
    "    gradient_memory = [p * 2 for p in param_counts]  # FP16\n",
    "    optimizer_memory = [p * 8 for p in param_counts]  # Adam (2 states × 4 bytes each)\n",
    "    \n",
    "    x = np.arange(len(model_sizes))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars1 = ax.bar(x - width, model_memory, width, label='Model Parameters', color='steelblue')\n",
    "    bars2 = ax.bar(x, gradient_memory, width, label='Gradients', color='coral')\n",
    "    bars3 = ax.bar(x + width, optimizer_memory, width, label='Optimizer States (Adam)', color='seagreen')\n",
    "    \n",
    "    ax.set_xlabel('Model Size')\n",
    "    ax.set_ylabel('Memory (GB)')\n",
    "    ax.set_title('Full Fine-tuning Memory Requirements (FP16)')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_sizes)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 標註總計\n",
    "    totals = [m + g + o for m, g, o in zip(model_memory, gradient_memory, optimizer_memory)]\n",
    "    for i, total in enumerate(totals):\n",
    "        ax.annotate(f'Total: {total} GB', \n",
    "                   xy=(i, optimizer_memory[i]), \n",
    "                   xytext=(i, max(totals) * 0.9),\n",
    "                   ha='center', fontsize=9,\n",
    "                   arrowprops=dict(arrowstyle='->', color='gray', alpha=0.5))\n",
    "    \n",
    "    # 標註常見 GPU VRAM\n",
    "    gpu_vrams = [('RTX 4090', 24), ('A100-40GB', 40), ('A100-80GB', 80)]\n",
    "    for name, vram in gpu_vrams:\n",
    "        ax.axhline(y=vram, color='red', linestyle='--', alpha=0.3)\n",
    "        ax.text(len(model_sizes) - 0.5, vram + 2, f'{name} ({vram}GB)', fontsize=8, color='red')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_memory_requirements()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PEFT (Parameter-Efficient Fine-Tuning)\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                     PEFT 方法概覽                               │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│  1. Adapter Methods                                            │\n",
    "│     • 在 Transformer 層間插入小型網路                          │\n",
    "│     • 只訓練 adapter 參數                                      │\n",
    "│                                                                │\n",
    "│  2. LoRA (Low-Rank Adaptation)                                 │\n",
    "│     • 用低秩矩陣近似權重更新                                   │\n",
    "│     • 最流行的 PEFT 方法                                       │\n",
    "│                                                                │\n",
    "│  3. Prefix Tuning / Prompt Tuning                              │\n",
    "│     • 訓練可學習的 prefix tokens                               │\n",
    "│     • 不修改模型參數                                           │\n",
    "│                                                                │\n",
    "│  4. IA3 (Infused Adapter by Inhibiting and Amplifying)         │\n",
    "│     • 學習縮放向量                                             │\n",
    "│     • 參數量更少                                               │\n",
    "│                                                                │\n",
    "│  比較:                                                         │\n",
    "│  ┌────────────┬─────────────┬──────────────┬─────────────┐    │\n",
    "│  │ 方法        │ 可訓練參數   │ 推理開銷      │ 效果        │    │\n",
    "│  ├────────────┼─────────────┼──────────────┼─────────────┤    │\n",
    "│  │ Full FT    │ 100%        │ 無           │ 最佳        │    │\n",
    "│  │ LoRA       │ 0.1-1%      │ 可合併(無)   │ 接近 Full   │    │\n",
    "│  │ Adapter    │ 1-5%        │ 有           │ 良好        │    │\n",
    "│  │ Prefix     │ <0.1%       │ 有           │ 中等        │    │\n",
    "│  └────────────┴─────────────┴──────────────┴─────────────┘    │\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: LoRA 深入解析\n",
    "\n",
    "### 3.1 LoRA 原理\n",
    "\n",
    "LoRA 的核心想法：權重更新 $\\Delta W$ 具有低秩結構。\n",
    "\n",
    "$$W' = W + \\Delta W = W + BA$$\n",
    "\n",
    "其中：\n",
    "- $W \\in \\mathbb{R}^{d \\times k}$: 原始權重（凍結）\n",
    "- $B \\in \\mathbb{R}^{d \\times r}$: 低秩矩陣\n",
    "- $A \\in \\mathbb{R}^{r \\times k}$: 低秩矩陣\n",
    "- $r \\ll \\min(d, k)$: rank（通常 4-64）\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                      LoRA 結構示意                              │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│                        Input x                                 │\n",
    "│                           │                                    │\n",
    "│              ┌────────────┼────────────┐                       │\n",
    "│              │            │            │                       │\n",
    "│              ▼            │            ▼                       │\n",
    "│         ┌────────┐       │       ┌────────┐                   │\n",
    "│         │   W    │       │       │   A    │ r×k               │\n",
    "│         │ (凍結) │       │       │ (可訓練)│                   │\n",
    "│         │ d×k    │       │       └────┬───┘                   │\n",
    "│         └────┬───┘       │            │                       │\n",
    "│              │           │            ▼                       │\n",
    "│              │           │       ┌────────┐                   │\n",
    "│              │           │       │   B    │ d×r               │\n",
    "│              │           │       │ (可訓練)│                   │\n",
    "│              │           │       └────┬───┘                   │\n",
    "│              │           │            │ × (α/r)               │\n",
    "│              │           │            │                       │\n",
    "│              └─────────+ │ +──────────┘                       │\n",
    "│                          │                                    │\n",
    "│                          ▼                                    │\n",
    "│                       Output                                   │\n",
    "│                                                                │\n",
    "│  參數量: d×k (凍結) + r×k + d×r (可訓練)                       │\n",
    "│  例如: d=4096, k=4096, r=8                                     │\n",
    "│       原始: 16M, LoRA: 64K (0.4%)                              │\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 層的實作\n",
    "class LoRALayer(nn.Module):\n",
    "    \"\"\"LoRA (Low-Rank Adaptation) 層\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_features: int, \n",
    "                 out_features: int, \n",
    "                 rank: int = 8, \n",
    "                 alpha: float = 16.0,\n",
    "                 dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.rank = rank\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / rank  # LoRA 縮放因子\n",
    "        \n",
    "        # 原始線性層（凍結）\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=False)\n",
    "        self.linear.weight.requires_grad = False\n",
    "        \n",
    "        # LoRA 矩陣\n",
    "        self.lora_A = nn.Linear(in_features, rank, bias=False)\n",
    "        self.lora_B = nn.Linear(rank, out_features, bias=False)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
    "        \n",
    "        # 初始化\n",
    "        nn.init.kaiming_uniform_(self.lora_A.weight, a=np.sqrt(5))\n",
    "        nn.init.zeros_(self.lora_B.weight)  # 初始化為 0，確保開始時 LoRA 不改變輸出\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 原始輸出\n",
    "        original_output = self.linear(x)\n",
    "        \n",
    "        # LoRA 增量\n",
    "        lora_output = self.lora_B(self.lora_A(self.dropout(x))) * self.scaling\n",
    "        \n",
    "        return original_output + lora_output\n",
    "    \n",
    "    def merge_weights(self):\n",
    "        \"\"\"將 LoRA 權重合併到原始權重（用於推理加速）\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # W' = W + BA * scaling\n",
    "            delta_w = (self.lora_B.weight @ self.lora_A.weight) * self.scaling\n",
    "            self.linear.weight.add_(delta_w)\n",
    "    \n",
    "    @property\n",
    "    def trainable_params(self):\n",
    "        return sum(p.numel() for p in [self.lora_A.weight, self.lora_B.weight])\n",
    "    \n",
    "    @property\n",
    "    def total_params(self):\n",
    "        return self.linear.weight.numel() + self.trainable_params\n",
    "\n",
    "# 測試 LoRA 層\n",
    "in_features, out_features = 4096, 4096\n",
    "rank = 8\n",
    "\n",
    "lora_layer = LoRALayer(in_features, out_features, rank=rank, alpha=16.0)\n",
    "\n",
    "print(f\"輸入維度: {in_features}, 輸出維度: {out_features}, Rank: {rank}\")\n",
    "print(f\"原始參數量: {in_features * out_features:,}\")\n",
    "print(f\"LoRA 參數量: {lora_layer.trainable_params:,}\")\n",
    "print(f\"參數比例: {lora_layer.trainable_params / (in_features * out_features) * 100:.2f}%\")\n",
    "\n",
    "# 測試前向傳播\n",
    "x = torch.randn(2, 128, in_features)\n",
    "output = lora_layer(x)\n",
    "print(f\"\\n輸入形狀: {x.shape}\")\n",
    "print(f\"輸出形狀: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 LoRA 參數效率\n",
    "def visualize_lora_efficiency():\n",
    "    \"\"\"視覺化不同 rank 下的 LoRA 參數效率\"\"\"\n",
    "    \n",
    "    hidden_size = 4096  # 典型的 LLM hidden size\n",
    "    ranks = [1, 2, 4, 8, 16, 32, 64, 128, 256]\n",
    "    \n",
    "    # 計算參數量\n",
    "    original_params = hidden_size * hidden_size\n",
    "    lora_params = [(hidden_size * r + r * hidden_size) for r in ranks]\n",
    "    param_ratios = [lp / original_params * 100 for lp in lora_params]\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 左圖：參數量\n",
    "    ax1.bar(range(len(ranks)), [original_params] * len(ranks), \n",
    "           alpha=0.3, label='Original', color='gray')\n",
    "    ax1.bar(range(len(ranks)), lora_params, \n",
    "           alpha=0.8, label='LoRA Trainable', color='steelblue')\n",
    "    ax1.set_xlabel('LoRA Rank')\n",
    "    ax1.set_ylabel('Number of Parameters')\n",
    "    ax1.set_title('LoRA vs Original Parameters')\n",
    "    ax1.set_xticks(range(len(ranks)))\n",
    "    ax1.set_xticklabels(ranks)\n",
    "    ax1.legend()\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 右圖：參數比例\n",
    "    bars = ax2.bar(range(len(ranks)), param_ratios, color='coral')\n",
    "    ax2.set_xlabel('LoRA Rank')\n",
    "    ax2.set_ylabel('Trainable Parameter Ratio (%)')\n",
    "    ax2.set_title('LoRA Parameter Efficiency')\n",
    "    ax2.set_xticks(range(len(ranks)))\n",
    "    ax2.set_xticklabels(ranks)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 標註常用 rank\n",
    "    for i, (r, ratio) in enumerate(zip(ranks, param_ratios)):\n",
    "        if r in [8, 16, 32]:\n",
    "            ax2.annotate(f'{ratio:.2f}%', xy=(i, ratio), \n",
    "                        xytext=(i, ratio + 0.5),\n",
    "                        ha='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n典型 rank 設定:\")\n",
    "    print(f\"  rank=8:  {param_ratios[3]:.3f}% of parameters\")\n",
    "    print(f\"  rank=16: {param_ratios[4]:.3f}% of parameters\")\n",
    "    print(f\"  rank=32: {param_ratios[5]:.3f}% of parameters\")\n",
    "\n",
    "visualize_lora_efficiency()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 LoRA 應用到 Transformer\n",
    "\n",
    "通常對以下層應用 LoRA：\n",
    "- Query (Q) 投影\n",
    "- Key (K) 投影\n",
    "- Value (V) 投影\n",
    "- Output (O) 投影\n",
    "- FFN 層（可選）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoRAAttention(nn.Module):\n",
    "    \"\"\"帶 LoRA 的 Multi-Head Attention\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 hidden_size: int = 768,\n",
    "                 num_heads: int = 12,\n",
    "                 lora_rank: int = 8,\n",
    "                 lora_alpha: float = 16.0,\n",
    "                 lora_dropout: float = 0.0,\n",
    "                 target_modules: List[str] = ['q', 'v']):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = hidden_size // num_heads\n",
    "        \n",
    "        # 原始投影層\n",
    "        self.q_proj = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.k_proj = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.v_proj = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        self.o_proj = nn.Linear(hidden_size, hidden_size, bias=False)\n",
    "        \n",
    "        # 凍結原始權重\n",
    "        for proj in [self.q_proj, self.k_proj, self.v_proj, self.o_proj]:\n",
    "            for param in proj.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # LoRA 層\n",
    "        self.lora_modules = {}\n",
    "        for name in target_modules:\n",
    "            self.lora_modules[name] = {\n",
    "                'A': nn.Linear(hidden_size, lora_rank, bias=False),\n",
    "                'B': nn.Linear(lora_rank, hidden_size, bias=False)\n",
    "            }\n",
    "            # 初始化\n",
    "            nn.init.kaiming_uniform_(self.lora_modules[name]['A'].weight)\n",
    "            nn.init.zeros_(self.lora_modules[name]['B'].weight)\n",
    "            \n",
    "            # 註冊為子模組\n",
    "            self.add_module(f'lora_{name}_A', self.lora_modules[name]['A'])\n",
    "            self.add_module(f'lora_{name}_B', self.lora_modules[name]['B'])\n",
    "        \n",
    "        self.scaling = lora_alpha / lora_rank\n",
    "        self.dropout = nn.Dropout(lora_dropout)\n",
    "    \n",
    "    def _apply_lora(self, x, proj, lora_name):\n",
    "        \"\"\"應用 LoRA 到投影層\"\"\"\n",
    "        output = proj(x)\n",
    "        \n",
    "        if lora_name in self.lora_modules:\n",
    "            lora_A = self.lora_modules[lora_name]['A']\n",
    "            lora_B = self.lora_modules[lora_name]['B']\n",
    "            lora_output = lora_B(lora_A(self.dropout(x))) * self.scaling\n",
    "            output = output + lora_output\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, hidden_states, attention_mask=None):\n",
    "        batch_size, seq_len, _ = hidden_states.shape\n",
    "        \n",
    "        # 投影（帶 LoRA）\n",
    "        q = self._apply_lora(hidden_states, self.q_proj, 'q')\n",
    "        k = self._apply_lora(hidden_states, self.k_proj, 'k')\n",
    "        v = self._apply_lora(hidden_states, self.v_proj, 'v')\n",
    "        \n",
    "        # 重塑為多頭\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # 注意力計算\n",
    "        attn_weights = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(self.head_dim)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights + attention_mask\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_output = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        # 合併頭\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)\n",
    "        \n",
    "        # 輸出投影\n",
    "        output = self._apply_lora(attn_output, self.o_proj, 'o')\n",
    "        \n",
    "        return output\n",
    "\n",
    "# 測試\n",
    "lora_attn = LoRAAttention(hidden_size=768, num_heads=12, lora_rank=8, target_modules=['q', 'v'])\n",
    "\n",
    "# 計算參數量\n",
    "total_params = sum(p.numel() for p in lora_attn.parameters())\n",
    "trainable_params = sum(p.numel() for p in lora_attn.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"總參數量: {total_params:,}\")\n",
    "print(f\"可訓練參數量: {trainable_params:,}\")\n",
    "print(f\"可訓練比例: {trainable_params / total_params * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: QLoRA（量化 + LoRA）\n",
    "\n",
    "### 4.1 QLoRA 原理\n",
    "\n",
    "QLoRA 結合 4-bit 量化和 LoRA，進一步降低記憶體需求。\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│                      QLoRA 技術棧                               │\n",
    "├────────────────────────────────────────────────────────────────┤\n",
    "│                                                                │\n",
    "│  1. 4-bit NormalFloat (NF4) 量化                              │\n",
    "│     • 專為正態分布權重設計的量化格式                           │\n",
    "│     • 比 INT4 有更好的精度                                     │\n",
    "│                                                                │\n",
    "│  2. Double Quantization                                        │\n",
    "│     • 量化「量化常數」以進一步節省記憶體                       │\n",
    "│     • 每 64 個參數的量化常數再量化為 FP8                       │\n",
    "│                                                                │\n",
    "│  3. Paged Optimizers                                          │\n",
    "│     • 使用 NVIDIA unified memory                              │\n",
    "│     • 自動處理記憶體溢出                                      │\n",
    "│                                                                │\n",
    "│  記憶體比較 (7B 模型):                                         │\n",
    "│  ┌───────────────────────────────────────────────────────┐   │\n",
    "│  │ Full FT (FP16):     ~84 GB                             │   │\n",
    "│  │ LoRA (FP16):        ~14 GB (模型) + 少量可訓練參數      │   │\n",
    "│  │ QLoRA (NF4):        ~4 GB (模型) + 少量可訓練參數       │   │\n",
    "│  └───────────────────────────────────────────────────────┘   │\n",
    "│                                                                │\n",
    "└────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 QLoRA 記憶體節省\n",
    "def visualize_qlora_memory():\n",
    "    \"\"\"視覺化 QLoRA 的記憶體節省效果\"\"\"\n",
    "    \n",
    "    model_sizes = ['1B', '3B', '7B', '13B', '30B']\n",
    "    param_counts = [1, 3, 7, 13, 30]  # 十億\n",
    "    \n",
    "    # 計算記憶體需求 (GB)\n",
    "    full_ft_memory = [p * 12 for p in param_counts]  # 模型 + 梯度 + 優化器\n",
    "    lora_fp16 = [p * 2 for p in param_counts]  # 只有凍結模型\n",
    "    qlora_nf4 = [p * 0.5 for p in param_counts]  # 4-bit 量化\n",
    "    \n",
    "    x = np.arange(len(model_sizes))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    bars1 = ax.bar(x - width, full_ft_memory, width, label='Full Fine-tuning (FP16)', color='coral')\n",
    "    bars2 = ax.bar(x, lora_fp16, width, label='LoRA (FP16 frozen)', color='steelblue')\n",
    "    bars3 = ax.bar(x + width, qlora_nf4, width, label='QLoRA (NF4)', color='seagreen')\n",
    "    \n",
    "    ax.set_xlabel('Model Size')\n",
    "    ax.set_ylabel('Memory (GB)')\n",
    "    ax.set_title('Memory Requirements: Full FT vs LoRA vs QLoRA')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(model_sizes)\n",
    "    ax.legend()\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 標註 GPU VRAM 線\n",
    "    ax.axhline(y=16, color='red', linestyle='--', alpha=0.5, label='RTX 5080 (16GB)')\n",
    "    ax.axhline(y=24, color='orange', linestyle='--', alpha=0.5, label='RTX 4090 (24GB)')\n",
    "    ax.text(4.2, 16, '16GB VRAM', fontsize=9, color='red')\n",
    "    ax.text(4.2, 24, '24GB VRAM', fontsize=9, color='orange')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nQLoRA 使得在 16GB VRAM 上微調 7B 模型成為可能！\")\n",
    "\n",
    "visualize_qlora_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: 訓練資料格式\n",
    "\n",
    "### 5.1 常見格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練資料格式範例\n",
    "\n",
    "# 格式 1: Alpaca 格式\n",
    "alpaca_example = {\n",
    "    \"instruction\": \"將以下句子翻譯成英文\",\n",
    "    \"input\": \"深度學習是人工智慧的一個重要分支。\",\n",
    "    \"output\": \"Deep learning is an important branch of artificial intelligence.\"\n",
    "}\n",
    "\n",
    "# 格式 2: ShareGPT 格式（對話）\n",
    "sharegpt_example = {\n",
    "    \"conversations\": [\n",
    "        {\"from\": \"human\", \"value\": \"什麼是機器學習？\"},\n",
    "        {\"from\": \"gpt\", \"value\": \"機器學習是人工智慧的一個分支...\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# 格式 3: Instruction 格式\n",
    "instruction_example = {\n",
    "    \"text\": \"\"\"### Instruction:\n",
    "將以下句子翻譯成英文\n",
    "\n",
    "### Input:\n",
    "深度學習是人工智慧的一個重要分支。\n",
    "\n",
    "### Response:\n",
    "Deep learning is an important branch of artificial intelligence.\"\"\"\n",
    "}\n",
    "\n",
    "print(\"=== Alpaca 格式 ===\")\n",
    "print(json.dumps(alpaca_example, ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\n=== ShareGPT 格式 ===\")\n",
    "print(json.dumps(sharegpt_example, ensure_ascii=False, indent=2))\n",
    "\n",
    "print(\"\\n=== Instruction 格式 ===\")\n",
    "print(instruction_example[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資料格式轉換器\n",
    "class DataFormatter:\n",
    "    \"\"\"訓練資料格式化器\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def alpaca_to_text(example: dict, \n",
    "                       instruction_template: str = \"### Instruction:\\n{instruction}\\n\\n\",\n",
    "                       input_template: str = \"### Input:\\n{input}\\n\\n\",\n",
    "                       response_template: str = \"### Response:\\n{output}\") -> str:\n",
    "        \"\"\"將 Alpaca 格式轉換為文本\"\"\"\n",
    "        text = instruction_template.format(instruction=example['instruction'])\n",
    "        \n",
    "        if example.get('input'):\n",
    "            text += input_template.format(input=example['input'])\n",
    "        \n",
    "        text += response_template.format(output=example['output'])\n",
    "        return text\n",
    "    \n",
    "    @staticmethod\n",
    "    def sharegpt_to_text(example: dict,\n",
    "                         human_template: str = \"User: {message}\\n\",\n",
    "                         assistant_template: str = \"Assistant: {message}\\n\") -> str:\n",
    "        \"\"\"將 ShareGPT 格式轉換為文本\"\"\"\n",
    "        text = \"\"\n",
    "        for turn in example['conversations']:\n",
    "            if turn['from'] == 'human':\n",
    "                text += human_template.format(message=turn['value'])\n",
    "            else:\n",
    "                text += assistant_template.format(message=turn['value'])\n",
    "        return text.strip()\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply_chat_template(messages: List[dict], tokenizer) -> str:\n",
    "        \"\"\"\n",
    "        使用 tokenizer 的 chat template（如果支援）\n",
    "        \n",
    "        messages 格式:\n",
    "        [{\"role\": \"user\", \"content\": \"...\"},\n",
    "         {\"role\": \"assistant\", \"content\": \"...\"}]\n",
    "        \"\"\"\n",
    "        if hasattr(tokenizer, 'apply_chat_template'):\n",
    "            return tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "        else:\n",
    "            # 後備方案\n",
    "            text = \"\"\n",
    "            for msg in messages:\n",
    "                role = msg['role'].capitalize()\n",
    "                text += f\"{role}: {msg['content']}\\n\"\n",
    "            return text\n",
    "\n",
    "# 測試格式化\n",
    "formatter = DataFormatter()\n",
    "\n",
    "print(\"=== Alpaca 轉換後 ===\")\n",
    "print(formatter.alpaca_to_text(alpaca_example))\n",
    "\n",
    "print(\"\\n=== ShareGPT 轉換後 ===\")\n",
    "print(formatter.sharegpt_to_text(sharegpt_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 使用 PEFT 庫微調\n",
    "\n",
    "### 6.1 完整微調流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的 LoRA 微調流程（使用 PEFT）\n",
    "def setup_lora_training():\n",
    "    \"\"\"設置 LoRA 微調\"\"\"\n",
    "    try:\n",
    "        from transformers import (\n",
    "            AutoModelForCausalLM, \n",
    "            AutoTokenizer,\n",
    "            TrainingArguments,\n",
    "            Trainer\n",
    "        )\n",
    "        from peft import (\n",
    "            LoraConfig, \n",
    "            get_peft_model, \n",
    "            TaskType,\n",
    "            prepare_model_for_kbit_training\n",
    "        )\n",
    "        \n",
    "        print(\"✓ PEFT 和 Transformers 已安裝\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        print(f\"✗ 缺少套件: {e}\")\n",
    "        print(\"請安裝: pip install transformers peft bitsandbytes\")\n",
    "        return False\n",
    "\n",
    "peft_available = setup_lora_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA 微調範例（使用小型模型 GPT-2）\n",
    "if peft_available:\n",
    "    from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "    from peft import LoraConfig, get_peft_model, TaskType\n",
    "    \n",
    "    # 載入基礎模型\n",
    "    model_name = \"gpt2\"  # 小型模型，適合示範\n",
    "    print(f\"載入模型: {model_name}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    # 設定 padding token\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    model.config.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    # LoRA 配置\n",
    "    lora_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        r=8,                      # LoRA rank\n",
    "        lora_alpha=16,            # Alpha 參數\n",
    "        lora_dropout=0.1,         # Dropout\n",
    "        target_modules=[\"c_attn\", \"c_proj\"],  # GPT-2 的注意力層\n",
    "        bias=\"none\"\n",
    "    )\n",
    "    \n",
    "    # 應用 LoRA\n",
    "    peft_model = get_peft_model(model, lora_config)\n",
    "    \n",
    "    # 打印可訓練參數\n",
    "    peft_model.print_trainable_parameters()\n",
    "    \n",
    "    print(f\"\\nLoRA 配置:\")\n",
    "    print(f\"  Rank: {lora_config.r}\")\n",
    "    print(f\"  Alpha: {lora_config.lora_alpha}\")\n",
    "    print(f\"  Target modules: {lora_config.target_modules}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備訓練資料\n",
    "if peft_available:\n",
    "    from torch.utils.data import Dataset\n",
    "    \n",
    "    class InstructionDataset(Dataset):\n",
    "        \"\"\"指令微調資料集\"\"\"\n",
    "        \n",
    "        def __init__(self, data: List[dict], tokenizer, max_length: int = 512):\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "            self.data = data\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            example = self.data[idx]\n",
    "            \n",
    "            # 格式化文本\n",
    "            text = DataFormatter.alpaca_to_text(example)\n",
    "            \n",
    "            # Tokenize\n",
    "            encodings = self.tokenizer(\n",
    "                text,\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            input_ids = encodings['input_ids'].squeeze()\n",
    "            attention_mask = encodings['attention_mask'].squeeze()\n",
    "            \n",
    "            # 對於 Causal LM，labels = input_ids\n",
    "            labels = input_ids.clone()\n",
    "            # 將 padding 位置的 label 設為 -100（不計算損失）\n",
    "            labels[attention_mask == 0] = -100\n",
    "            \n",
    "            return {\n",
    "                'input_ids': input_ids,\n",
    "                'attention_mask': attention_mask,\n",
    "                'labels': labels\n",
    "            }\n",
    "    \n",
    "    # 建立示範資料集\n",
    "    sample_data = [\n",
    "        {\"instruction\": \"Translate to English\", \"input\": \"你好\", \"output\": \"Hello\"},\n",
    "        {\"instruction\": \"Translate to English\", \"input\": \"謝謝\", \"output\": \"Thank you\"},\n",
    "        {\"instruction\": \"What is the capital of France?\", \"input\": \"\", \"output\": \"Paris\"},\n",
    "        {\"instruction\": \"Summarize this text\", \"input\": \"Machine learning is...\", \"output\": \"ML is AI that learns from data.\"},\n",
    "    ]\n",
    "    \n",
    "    dataset = InstructionDataset(sample_data, tokenizer, max_length=128)\n",
    "    \n",
    "    print(f\"資料集大小: {len(dataset)}\")\n",
    "    \n",
    "    # 查看一個樣本\n",
    "    sample = dataset[0]\n",
    "    print(f\"\\n樣本 input_ids 形狀: {sample['input_ids'].shape}\")\n",
    "    print(f\"解碼後: {tokenizer.decode(sample['input_ids'], skip_special_tokens=True)[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練配置（示範）\n",
    "training_config = {\n",
    "    \"output_dir\": \"./lora-output\",\n",
    "    \"num_train_epochs\": 3,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"warmup_steps\": 100,\n",
    "    \"logging_steps\": 10,\n",
    "    \"save_steps\": 500,\n",
    "    \"fp16\": True if torch.cuda.is_available() else False,\n",
    "    \"optim\": \"adamw_torch\",\n",
    "}\n",
    "\n",
    "print(\"訓練配置:\")\n",
    "for key, value in training_config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n注意: 實際訓練需要更多資料和計算資源\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: 練習題\n",
    "\n",
    "### Exercise 1: 實作不同 rank 的 LoRA 比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_lora_ranks(model_dim: int = 768):\n",
    "    \"\"\"\n",
    "    比較不同 LoRA rank 的效果\n",
    "    \n",
    "    測量:\n",
    "    1. 參數量\n",
    "    2. 前向傳播時間\n",
    "    3. 近似誤差（與 full rank 比較）\n",
    "    \"\"\"\n",
    "    ranks = [1, 2, 4, 8, 16, 32, 64]\n",
    "    results = []\n",
    "    \n",
    "    # 建立測試輸入\n",
    "    x = torch.randn(1, 128, model_dim)\n",
    "    \n",
    "    for rank in ranks:\n",
    "        # 建立 LoRA 層\n",
    "        lora = LoRALayer(model_dim, model_dim, rank=rank, alpha=rank*2)\n",
    "        \n",
    "        # 測量參數量\n",
    "        trainable_params = lora.trainable_params\n",
    "        \n",
    "        # 測量時間\n",
    "        import time\n",
    "        start = time.time()\n",
    "        for _ in range(100):\n",
    "            _ = lora(x)\n",
    "        elapsed = (time.time() - start) / 100 * 1000  # ms\n",
    "        \n",
    "        results.append({\n",
    "            'rank': rank,\n",
    "            'trainable_params': trainable_params,\n",
    "            'param_ratio': trainable_params / (model_dim * model_dim) * 100,\n",
    "            'forward_time_ms': elapsed\n",
    "        })\n",
    "    \n",
    "    # 視覺化\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # 參數比例\n",
    "    ax1.bar([str(r['rank']) for r in results], \n",
    "           [r['param_ratio'] for r in results],\n",
    "           color='steelblue')\n",
    "    ax1.set_xlabel('LoRA Rank')\n",
    "    ax1.set_ylabel('Trainable Parameter Ratio (%)')\n",
    "    ax1.set_title('LoRA Parameter Efficiency')\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 前向時間\n",
    "    ax2.plot([r['rank'] for r in results],\n",
    "            [r['forward_time_ms'] for r in results],\n",
    "            'o-', color='coral')\n",
    "    ax2.set_xlabel('LoRA Rank')\n",
    "    ax2.set_ylabel('Forward Time (ms)')\n",
    "    ax2.set_title('LoRA Forward Pass Time')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = compare_lora_ranks()\n",
    "\n",
    "print(\"\\n結果摘要:\")\n",
    "for r in results:\n",
    "    print(f\"  Rank {r['rank']:2d}: {r['param_ratio']:.2f}% params, {r['forward_time_ms']:.3f}ms forward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: 實作簡單的訓練循環"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_lora_training_loop():\n",
    "    \"\"\"\n",
    "    簡單的 LoRA 訓練循環示範\n",
    "    \"\"\"\n",
    "    if not peft_available:\n",
    "        print(\"需要安裝 PEFT\")\n",
    "        return\n",
    "    \n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # 設定\n",
    "    batch_size = 2\n",
    "    learning_rate = 1e-4\n",
    "    num_epochs = 2\n",
    "    \n",
    "    # 建立 DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # 只優化 LoRA 參數\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        filter(lambda p: p.requires_grad, peft_model.parameters()),\n",
    "        lr=learning_rate\n",
    "    )\n",
    "    \n",
    "    # 移到設備\n",
    "    peft_model.to(device)\n",
    "    peft_model.train()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    print(f\"開始訓練 (epochs={num_epochs}, batch_size={batch_size}, lr={learning_rate})\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            # 移到設備\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # 前向傳播\n",
    "            outputs = peft_model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            # 反向傳播\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # 視覺化損失\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(losses, 'b-', alpha=0.7)\n",
    "    plt.xlabel('Step')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    return losses\n",
    "\n",
    "if peft_available:\n",
    "    losses = simple_lora_training_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                   LLM 微調技術總結                           │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  1. 微調動機                                                │\n",
    "│     • 領域適應、任務特化、風格調整                           │\n",
    "│     • Full FT 記憶體需求過高                                │\n",
    "│                                                             │\n",
    "│  2. PEFT 方法                                               │\n",
    "│     • LoRA: 低秩分解權重更新                                │\n",
    "│     • QLoRA: 4-bit 量化 + LoRA                              │\n",
    "│     • Adapter, Prefix Tuning 等                             │\n",
    "│                                                             │\n",
    "│  3. LoRA 關鍵參數                                           │\n",
    "│     • rank (r): 控制可訓練參數量                            │\n",
    "│     • alpha: 縮放因子                                       │\n",
    "│     • target_modules: 應用 LoRA 的層                        │\n",
    "│                                                             │\n",
    "│  4. 訓練資料                                                │\n",
    "│     • Alpaca 格式                                           │\n",
    "│     • ShareGPT 格式                                         │\n",
    "│     • Chat template                                         │\n",
    "│                                                             │\n",
    "│  5. 實用建議                                                │\n",
    "│     • rank=8-32 通常足夠                                    │\n",
    "│     • 優先對 Q, V 投影應用 LoRA                             │\n",
    "│     • 使用 QLoRA 在消費級 GPU 上訓練                        │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 下一步學習\n",
    "\n",
    "- **災難性遺忘**: `transfer_adaptation/catastrophic_forgetting.ipynb`\n",
    "- **RLHF**: `reinforcement_learning/rlhf_alignment.ipynb`\n",
    "- **模型合併**: `llm_advanced/model_merging.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考資源\n",
    "\n",
    "### 課程\n",
    "- [李宏毅 2025 Spring ML HW5](https://speech.ee.ntu.edu.tw/~hylee/ml/2025-spring.php)\n",
    "- [李宏毅 2025 Fall GenAI-ML HW7](https://speech.ee.ntu.edu.tw/~hylee/GenAI-ML/2025-fall.php)\n",
    "\n",
    "### 論文\n",
    "- [LoRA: Low-Rank Adaptation of Large Language Models](https://arxiv.org/abs/2106.09685)\n",
    "- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)\n",
    "\n",
    "### 工具\n",
    "- [PEFT (Hugging Face)](https://github.com/huggingface/peft)\n",
    "- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
