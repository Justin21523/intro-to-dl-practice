{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 進階技術 (Advanced RAG Fundamentals)\n",
    "\n",
    "**對應課程**: 李宏毅 2025 Spring ML HW1 進階部分\n",
    "\n",
    "本 notebook 涵蓋 RAG 系統的進階技術，包括 Reranking、HyDE、Query Transformation 等。\n",
    "\n",
    "## 學習目標\n",
    "1. 理解 RAG 系統的瓶頸與優化方向\n",
    "2. 實作 Reranking（Cross-encoder）\n",
    "3. 實作 HyDE（Hypothetical Document Embeddings）\n",
    "4. 學習 Query Transformation 技術\n",
    "5. 掌握 RAG 系統的完整評估方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: RAG 系統的瓶頸分析\n",
    "\n",
    "### 1.1 基礎 RAG 的問題\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                  基礎 RAG 的常見問題                         │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  1. 檢索品質問題                                             │\n",
    "│     • Bi-encoder 語義匹配不夠精確                            │\n",
    "│     • 查詢與文件的表達方式不同（詞彙差異）                    │\n",
    "│     • Top-K 可能遺漏重要文件                                 │\n",
    "│                                                             │\n",
    "│  2. 上下文品質問題                                           │\n",
    "│     • 檢索到的文件可能不相關                                 │\n",
    "│     • 文件順序影響 LLM 理解                                  │\n",
    "│     • Context window 限制                                   │\n",
    "│                                                             │\n",
    "│  3. 生成品質問題                                             │\n",
    "│     • LLM 可能忽略檢索內容                                   │\n",
    "│     • 無法正確整合多個來源                                   │\n",
    "│     • 仍可能產生幻覺                                         │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 進階 RAG 架構\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────┐\n",
    "│                      進階 RAG Pipeline                               │\n",
    "├─────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                     │\n",
    "│  ┌─────────────────── Pre-Retrieval 優化 ─────────────────┐        │\n",
    "│  │                                                         │        │\n",
    "│  │   原始查詢         查詢改寫          多查詢生成          │        │\n",
    "│  │  ┌─────────┐     ┌─────────┐     ┌─────────────┐       │        │\n",
    "│  │  │  Query  │ →   │Rewrite/ │ →   │Multi-Query  │       │        │\n",
    "│  │  │         │     │ Expand  │     │(HyDE/Step)  │       │        │\n",
    "│  │  └─────────┘     └─────────┘     └──────┬──────┘       │        │\n",
    "│  │                                         │               │        │\n",
    "│  └─────────────────────────────────────────┼───────────────┘        │\n",
    "│                                            ↓                        │\n",
    "│  ┌─────────────────── Retrieval 階段 ──────┼───────────────┐        │\n",
    "│  │                                         │               │        │\n",
    "│  │                                    ┌────┴────┐          │        │\n",
    "│  │                                    │ Initial │          │        │\n",
    "│  │                                    │Retrieval│          │        │\n",
    "│  │                                    │ (Top-K) │          │        │\n",
    "│  │                                    └────┬────┘          │        │\n",
    "│  │                                         │               │        │\n",
    "│  └─────────────────────────────────────────┼───────────────┘        │\n",
    "│                                            ↓                        │\n",
    "│  ┌─────────────────── Post-Retrieval 優化 ─┼───────────────┐        │\n",
    "│  │                                         │               │        │\n",
    "│  │   Reranking        過濾/壓縮        上下文整合           │        │\n",
    "│  │  ┌─────────┐     ┌─────────┐     ┌─────────────┐       │        │\n",
    "│  │  │ Cross-  │ →   │ Filter/ │ →   │  Context    │       │        │\n",
    "│  │  │ Encoder │     │Compress │     │ Formatting  │       │        │\n",
    "│  │  └─────────┘     └─────────┘     └──────┬──────┘       │        │\n",
    "│  │                                         │               │        │\n",
    "│  └─────────────────────────────────────────┼───────────────┘        │\n",
    "│                                            ↓                        │\n",
    "│                                       ┌──────────┐                  │\n",
    "│                                       │   LLM    │                  │\n",
    "│                                       │ Generate │                  │\n",
    "│                                       └──────────┘                  │\n",
    "│                                                                     │\n",
    "└─────────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 環境設置\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from dataclasses import dataclass\n",
    "import re\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "# 資料結構\n",
    "@dataclass\n",
    "class Document:\n",
    "    content: str\n",
    "    metadata: Dict = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        if self.metadata is None:\n",
    "            self.metadata = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Reranking（重排序）\n",
    "\n",
    "### 2.1 Bi-encoder vs Cross-encoder\n",
    "\n",
    "```\n",
    "┌────────────────────────────────────────────────────────────────┐\n",
    "│            Bi-encoder vs Cross-encoder 比較                    │\n",
    "├────────────────────────────┬───────────────────────────────────┤\n",
    "│        Bi-encoder          │         Cross-encoder            │\n",
    "├────────────────────────────┼───────────────────────────────────┤\n",
    "│                            │                                   │\n",
    "│   Query    Document        │      Query + Document             │\n",
    "│     │         │            │            │                      │\n",
    "│     ▼         ▼            │            ▼                      │\n",
    "│  ┌─────┐  ┌─────┐         │      ┌───────────┐                │\n",
    "│  │Enc 1│  │Enc 2│         │      │ Encoder   │                │\n",
    "│  └──┬──┘  └──┬──┘         │      │ (Joint)   │                │\n",
    "│     │        │            │      └─────┬─────┘                │\n",
    "│     ▼        ▼            │            │                      │\n",
    "│   [Vec]    [Vec]          │            ▼                      │\n",
    "│     └───┬────┘            │        Relevance                  │\n",
    "│         │                 │         Score                     │\n",
    "│     Similarity            │                                   │\n",
    "├────────────────────────────┼───────────────────────────────────┤\n",
    "│ + 可預先計算文件向量       │ + 更精確的相關性判斷              │\n",
    "│ + 快速（O(1) 比較）       │ + 考慮 query-doc 交互             │\n",
    "│ - 較不精確                │ - 需要 O(N) 計算                  │\n",
    "│                           │ - 較慢                            │\n",
    "├────────────────────────────┼───────────────────────────────────┤\n",
    "│ 用途: 初始檢索（召回）     │ 用途: 重排序（精排）              │\n",
    "└────────────────────────────┴───────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-encoder Reranker 實作\n",
    "class CrossEncoderReranker:\n",
    "    \"\"\"使用 Cross-encoder 進行重排序\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'):\n",
    "        try:\n",
    "            from sentence_transformers import CrossEncoder\n",
    "            self.model = CrossEncoder(model_name)\n",
    "            self.available = True\n",
    "        except ImportError:\n",
    "            print(\"警告: sentence-transformers 未安裝，使用簡化實作\")\n",
    "            self.model = None\n",
    "            self.available = False\n",
    "    \n",
    "    def rerank(self, query: str, documents: List[Document], \n",
    "               top_k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        重排序文件\n",
    "        \n",
    "        Args:\n",
    "            query: 查詢文本\n",
    "            documents: 候選文件列表\n",
    "            top_k: 返回的文件數量\n",
    "        \n",
    "        Returns:\n",
    "            排序後的 (document, score) 列表\n",
    "        \"\"\"\n",
    "        if not self.available or not documents:\n",
    "            # 簡化實作：使用字詞重疊率\n",
    "            results = []\n",
    "            query_words = set(query.lower().split())\n",
    "            for doc in documents:\n",
    "                doc_words = set(doc.content.lower().split())\n",
    "                overlap = len(query_words & doc_words) / len(query_words) if query_words else 0\n",
    "                results.append((doc, overlap))\n",
    "            results.sort(key=lambda x: x[1], reverse=True)\n",
    "            return results[:top_k]\n",
    "        \n",
    "        # 使用 Cross-encoder\n",
    "        pairs = [(query, doc.content) for doc in documents]\n",
    "        scores = self.model.predict(pairs)\n",
    "        \n",
    "        # 組合結果並排序\n",
    "        results = list(zip(documents, scores))\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return results[:top_k]\n",
    "\n",
    "# 測試 Reranker\n",
    "reranker = CrossEncoderReranker()\n",
    "\n",
    "# 準備測試文件\n",
    "test_docs = [\n",
    "    Document(content=\"Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data.\"),\n",
    "    Document(content=\"The weather forecast predicts sunny skies for the weekend.\"),\n",
    "    Document(content=\"Deep learning uses neural networks with multiple layers to process complex patterns in data.\"),\n",
    "    Document(content=\"Pizza is a popular Italian dish made with dough, tomato sauce, and cheese.\"),\n",
    "    Document(content=\"Natural language processing enables computers to understand human language.\"),\n",
    "]\n",
    "\n",
    "query = \"What is deep learning and how does it work?\"\n",
    "reranked = reranker.rerank(query, test_docs, top_k=3)\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"Reranked results:\")\n",
    "for i, (doc, score) in enumerate(reranked, 1):\n",
    "    print(f\"  [{i}] Score: {score:.4f}\")\n",
    "    print(f\"      {doc.content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Two-stage Retrieval Pipeline\n",
    "\n",
    "結合 Bi-encoder（召回）和 Cross-encoder（精排）的兩階段檢索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoStageRetriever:\n",
    "    \"\"\"兩階段檢索器：Bi-encoder 召回 + Cross-encoder 精排\"\"\"\n",
    "    \n",
    "    def __init__(self, bi_encoder_name: str = 'all-MiniLM-L6-v2',\n",
    "                 cross_encoder_name: str = 'cross-encoder/ms-marco-MiniLM-L-6-v2'):\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.bi_encoder = SentenceTransformer(bi_encoder_name)\n",
    "        except ImportError:\n",
    "            self.bi_encoder = None\n",
    "        \n",
    "        self.reranker = CrossEncoderReranker(cross_encoder_name)\n",
    "        self.documents: List[Document] = []\n",
    "        self.embeddings: np.ndarray = None\n",
    "    \n",
    "    def add_documents(self, documents: List[Document]):\n",
    "        \"\"\"建立索引\"\"\"\n",
    "        self.documents.extend(documents)\n",
    "        \n",
    "        if self.bi_encoder:\n",
    "            new_embeddings = self.bi_encoder.encode(\n",
    "                [doc.content for doc in documents],\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "            if self.embeddings is None:\n",
    "                self.embeddings = new_embeddings\n",
    "            else:\n",
    "                self.embeddings = np.vstack([self.embeddings, new_embeddings])\n",
    "    \n",
    "    def retrieve(self, query: str, \n",
    "                 initial_k: int = 20, \n",
    "                 final_k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        兩階段檢索\n",
    "        \n",
    "        Args:\n",
    "            query: 查詢\n",
    "            initial_k: 第一階段召回數量\n",
    "            final_k: 最終返回數量\n",
    "        \"\"\"\n",
    "        # Stage 1: Bi-encoder 召回\n",
    "        if self.bi_encoder and self.embeddings is not None:\n",
    "            query_embedding = self.bi_encoder.encode([query])[0]\n",
    "            \n",
    "            # 計算餘弦相似度\n",
    "            similarities = np.dot(self.embeddings, query_embedding) / (\n",
    "                np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "            )\n",
    "            \n",
    "            # 取 top-K\n",
    "            top_indices = np.argsort(similarities)[::-1][:initial_k]\n",
    "            candidates = [self.documents[i] for i in top_indices]\n",
    "        else:\n",
    "            candidates = self.documents[:initial_k]\n",
    "        \n",
    "        # Stage 2: Cross-encoder 精排\n",
    "        results = self.reranker.rerank(query, candidates, top_k=final_k)\n",
    "        \n",
    "        return results\n",
    "\n",
    "# 示範\n",
    "print(\"兩階段檢索器已定義\")\n",
    "print(\"Stage 1: Bi-encoder 快速召回大量候選\")\n",
    "print(\"Stage 2: Cross-encoder 精確重排序\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: HyDE (Hypothetical Document Embeddings)\n",
    "\n",
    "### 3.1 HyDE 概念\n",
    "\n",
    "HyDE 的核心想法：讓 LLM 先生成一個「假設性答案文件」，然後用這個文件去檢索。\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                         HyDE Pipeline                           │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│   原始查詢                                                      │\n",
    "│  \"What causes climate change?\"                                 │\n",
    "│           │                                                     │\n",
    "│           ▼                                                     │\n",
    "│   ┌───────────────┐                                            │\n",
    "│   │     LLM       │ ← \"Generate a passage that answers...\"     │\n",
    "│   │  (Zero-shot)  │                                            │\n",
    "│   └───────┬───────┘                                            │\n",
    "│           │                                                     │\n",
    "│           ▼                                                     │\n",
    "│   假設性文件 (Hypothetical Document)                            │\n",
    "│  \"Climate change is primarily caused by greenhouse gas         │\n",
    "│   emissions from human activities such as burning fossil       │\n",
    "│   fuels, deforestation...\"                                     │\n",
    "│           │                                                     │\n",
    "│           ▼                                                     │\n",
    "│   ┌───────────────┐                                            │\n",
    "│   │   Embedding   │                                            │\n",
    "│   └───────┬───────┘                                            │\n",
    "│           │                                                     │\n",
    "│           ▼                                                     │\n",
    "│   ┌───────────────┐    ┌───────────────────────┐               │\n",
    "│   │   Retrieval   │ ←  │  Document Embeddings  │               │\n",
    "│   └───────────────┘    └───────────────────────┘               │\n",
    "│                                                                 │\n",
    "│   優勢: 假設性文件與真實文件在向量空間中更接近                   │\n",
    "│                                                                 │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    \"\"\"HyDE: Hypothetical Document Embeddings\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model=None, llm_generator=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embedding_model: 用於嵌入的模型\n",
    "            llm_generator: 用於生成假設性文件的 LLM\n",
    "        \"\"\"\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedding_model = embedding_model or SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        except ImportError:\n",
    "            self.embedding_model = None\n",
    "        \n",
    "        self.llm_generator = llm_generator\n",
    "        self.documents: List[Document] = []\n",
    "        self.doc_embeddings: np.ndarray = None\n",
    "        \n",
    "        # HyDE prompt template\n",
    "        self.hyde_prompt = \"\"\"Please write a passage that answers the following question.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Passage:\"\"\"\n",
    "    \n",
    "    def add_documents(self, documents: List[Document]):\n",
    "        \"\"\"建立文件索引\"\"\"\n",
    "        self.documents.extend(documents)\n",
    "        \n",
    "        if self.embedding_model:\n",
    "            new_embeddings = self.embedding_model.encode(\n",
    "                [doc.content for doc in documents],\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "            if self.doc_embeddings is None:\n",
    "                self.doc_embeddings = new_embeddings\n",
    "            else:\n",
    "                self.doc_embeddings = np.vstack([self.doc_embeddings, new_embeddings])\n",
    "    \n",
    "    def generate_hypothetical_document(self, query: str) -> str:\n",
    "        \"\"\"生成假設性文件\"\"\"\n",
    "        if self.llm_generator:\n",
    "            prompt = self.hyde_prompt.format(query=query)\n",
    "            return self.llm_generator(prompt)\n",
    "        else:\n",
    "            # 簡化版：直接擴展查詢\n",
    "            return f\"This passage discusses {query}. It provides detailed information about the topic, including relevant facts, explanations, and examples.\"\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 5, \n",
    "                 use_hyde: bool = True) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        使用 HyDE 進行檢索\n",
    "        \n",
    "        Args:\n",
    "            query: 原始查詢\n",
    "            k: 返回文件數量\n",
    "            use_hyde: 是否使用 HyDE\n",
    "        \"\"\"\n",
    "        if not self.embedding_model or self.doc_embeddings is None:\n",
    "            return [(doc, 0.0) for doc in self.documents[:k]]\n",
    "        \n",
    "        if use_hyde:\n",
    "            # 生成假設性文件\n",
    "            hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "            query_text = hypothetical_doc\n",
    "        else:\n",
    "            query_text = query\n",
    "        \n",
    "        # 嵌入查詢\n",
    "        query_embedding = self.embedding_model.encode([query_text])[0]\n",
    "        \n",
    "        # 計算相似度\n",
    "        similarities = np.dot(self.doc_embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.doc_embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "        )\n",
    "        \n",
    "        # 取 top-K\n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        results = [(self.documents[i], float(similarities[i])) for i in top_indices]\n",
    "        \n",
    "        return results\n",
    "\n",
    "# 示範\n",
    "print(\"HyDE Retriever 已定義\")\n",
    "print(\"\\nHyDE 的優勢:\")\n",
    "print(\"1. 查詢通常很短，文件通常很長\")\n",
    "print(\"2. 假設性文件橋接了這個差距\")\n",
    "print(\"3. 特別適合問答型查詢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化 HyDE 效果\n",
    "def visualize_hyde_effect():\n",
    "    \"\"\"展示 HyDE 如何改善查詢與文件的語義匹配\"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # 模擬的向量空間（2D 簡化）\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 文件向量（聚集在某區域）\n",
    "    doc_vectors = np.random.randn(10, 2) * 0.3 + np.array([2, 2])\n",
    "    \n",
    "    # 原始查詢向量（離文件較遠）\n",
    "    query_vector = np.array([0.5, 0.5])\n",
    "    \n",
    "    # HyDE 假設性文件向量（更接近文件）\n",
    "    hyde_vector = np.array([1.8, 1.9])\n",
    "    \n",
    "    # 左圖：標準檢索\n",
    "    ax1 = axes[0]\n",
    "    ax1.scatter(doc_vectors[:, 0], doc_vectors[:, 1], c='blue', s=100, alpha=0.6, label='Documents')\n",
    "    ax1.scatter(query_vector[0], query_vector[1], c='red', s=200, marker='*', label='Query')\n",
    "    \n",
    "    # 畫出到最近文件的線\n",
    "    distances_standard = np.linalg.norm(doc_vectors - query_vector, axis=1)\n",
    "    nearest_idx = np.argmin(distances_standard)\n",
    "    ax1.plot([query_vector[0], doc_vectors[nearest_idx, 0]], \n",
    "             [query_vector[1], doc_vectors[nearest_idx, 1]], 'r--', alpha=0.5)\n",
    "    \n",
    "    ax1.set_title('Standard Retrieval\\n(Query far from documents)', fontsize=12)\n",
    "    ax1.set_xlabel('Dimension 1')\n",
    "    ax1.set_ylabel('Dimension 2')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim(-0.5, 3.5)\n",
    "    ax1.set_ylim(-0.5, 3.5)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.text(0.5, 0.2, f'Distance: {distances_standard[nearest_idx]:.2f}', fontsize=10)\n",
    "    \n",
    "    # 右圖：HyDE 檢索\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(doc_vectors[:, 0], doc_vectors[:, 1], c='blue', s=100, alpha=0.6, label='Documents')\n",
    "    ax2.scatter(query_vector[0], query_vector[1], c='red', s=100, marker='*', alpha=0.3, label='Original Query')\n",
    "    ax2.scatter(hyde_vector[0], hyde_vector[1], c='green', s=200, marker='*', label='HyDE Document')\n",
    "    \n",
    "    # 畫出轉換箭頭\n",
    "    ax2.annotate('', xy=hyde_vector, xytext=query_vector,\n",
    "                arrowprops=dict(arrowstyle='->', color='purple', lw=2))\n",
    "    ax2.text(1.0, 1.0, 'LLM\\nGeneration', fontsize=9, color='purple')\n",
    "    \n",
    "    # 畫出到最近文件的線\n",
    "    distances_hyde = np.linalg.norm(doc_vectors - hyde_vector, axis=1)\n",
    "    nearest_idx_hyde = np.argmin(distances_hyde)\n",
    "    ax2.plot([hyde_vector[0], doc_vectors[nearest_idx_hyde, 0]], \n",
    "             [hyde_vector[1], doc_vectors[nearest_idx_hyde, 1]], 'g--', alpha=0.5)\n",
    "    \n",
    "    ax2.set_title('HyDE Retrieval\\n(Hypothetical doc closer to documents)', fontsize=12)\n",
    "    ax2.set_xlabel('Dimension 1')\n",
    "    ax2.set_ylabel('Dimension 2')\n",
    "    ax2.legend(loc='upper left')\n",
    "    ax2.set_xlim(-0.5, 3.5)\n",
    "    ax2.set_ylim(-0.5, 3.5)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.text(1.8, 1.6, f'Distance: {distances_hyde[nearest_idx_hyde]:.2f}', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_hyde_effect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Query Transformation（查詢轉換）\n",
    "\n",
    "### 4.1 Multi-Query（多查詢）\n",
    "\n",
    "生成多個不同角度的查詢，增加召回率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiQueryRetriever:\n",
    "    \"\"\"多查詢檢索器\"\"\"\n",
    "    \n",
    "    def __init__(self, base_retriever, query_generator=None):\n",
    "        self.base_retriever = base_retriever\n",
    "        self.query_generator = query_generator\n",
    "        \n",
    "        # 查詢生成 prompt\n",
    "        self.multi_query_prompt = \"\"\"Your task is to generate 3 different versions of the given user question \n",
    "to retrieve relevant documents from a vector database. By generating multiple perspectives on the user question, \n",
    "your goal is to help the user overcome some of the limitations of distance-based similarity search.\n",
    "\n",
    "Provide these alternative questions separated by newlines.\n",
    "\n",
    "Original question: {query}\n",
    "\n",
    "Alternative questions:\"\"\"\n",
    "    \n",
    "    def generate_queries(self, query: str, num_queries: int = 3) -> List[str]:\n",
    "        \"\"\"生成多個查詢變體\"\"\"\n",
    "        if self.query_generator:\n",
    "            prompt = self.multi_query_prompt.format(query=query)\n",
    "            response = self.query_generator(prompt)\n",
    "            queries = [q.strip() for q in response.split('\\n') if q.strip()]\n",
    "            return [query] + queries[:num_queries-1]\n",
    "        else:\n",
    "            # 簡化版：規則式變體\n",
    "            variants = [query]\n",
    "            \n",
    "            # 變體 1: 重新措辭\n",
    "            if '?' in query:\n",
    "                variants.append(query.replace('?', '').strip() + \" explanation\")\n",
    "            \n",
    "            # 變體 2: 加入同義詞提示\n",
    "            variants.append(f\"detailed information about {query}\")\n",
    "            \n",
    "            # 變體 3: 更具體\n",
    "            variants.append(f\"examples and use cases of {query}\")\n",
    "            \n",
    "            return variants[:num_queries]\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"使用多查詢進行檢索\"\"\"\n",
    "        # 生成多個查詢\n",
    "        queries = self.generate_queries(query)\n",
    "        \n",
    "        # 對每個查詢進行檢索\n",
    "        all_results = {}\n",
    "        for q in queries:\n",
    "            results = self.base_retriever.retrieve(q, k=k)\n",
    "            for doc, score in results:\n",
    "                doc_id = id(doc)\n",
    "                if doc_id not in all_results:\n",
    "                    all_results[doc_id] = (doc, score)\n",
    "                else:\n",
    "                    # 取最高分數\n",
    "                    _, existing_score = all_results[doc_id]\n",
    "                    all_results[doc_id] = (doc, max(score, existing_score))\n",
    "        \n",
    "        # 排序並返回\n",
    "        results = list(all_results.values())\n",
    "        results.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return results[:k]\n",
    "\n",
    "# 測試多查詢生成\n",
    "class DummyRetriever:\n",
    "    def retrieve(self, query, k=5):\n",
    "        return [(Document(content=f\"Result for: {query}\"), 0.5)]\n",
    "\n",
    "multi_query = MultiQueryRetriever(DummyRetriever())\n",
    "test_query = \"How does attention mechanism work in transformers?\"\n",
    "generated = multi_query.generate_queries(test_query)\n",
    "\n",
    "print(f\"原始查詢: {test_query}\\n\")\n",
    "print(\"生成的查詢變體:\")\n",
    "for i, q in enumerate(generated, 1):\n",
    "    print(f\"  {i}. {q}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Step-back Prompting\n",
    "\n",
    "將具體問題抽象化，檢索更通用的背景知識。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepBackRetriever:\n",
    "    \"\"\"Step-back Prompting 檢索器\"\"\"\n",
    "    \n",
    "    def __init__(self, base_retriever, abstractor=None):\n",
    "        self.base_retriever = base_retriever\n",
    "        self.abstractor = abstractor\n",
    "        \n",
    "        self.stepback_prompt = \"\"\"Given a specific question, generate a more abstract, higher-level question \n",
    "that would help provide background knowledge for answering the original question.\n",
    "\n",
    "Original question: {query}\n",
    "\n",
    "Abstract question:\"\"\"\n",
    "    \n",
    "    def generate_stepback_query(self, query: str) -> str:\n",
    "        \"\"\"生成抽象化查詢\"\"\"\n",
    "        if self.abstractor:\n",
    "            prompt = self.stepback_prompt.format(query=query)\n",
    "            return self.abstractor(prompt)\n",
    "        else:\n",
    "            # 簡化版：提取核心概念\n",
    "            # 移除具體細節，保留核心主題\n",
    "            abstract = query\n",
    "            \n",
    "            # 規則式抽象化\n",
    "            specific_patterns = [\n",
    "                (r'in (PyTorch|TensorFlow|Keras)', 'in deep learning frameworks'),\n",
    "                (r'for (GPT-\\d|BERT|LLaMA)', 'for language models'),\n",
    "                (r'(\\d+) layer', 'multi-layer'),\n",
    "                (r'how to implement', 'what is'),\n",
    "            ]\n",
    "            \n",
    "            for pattern, replacement in specific_patterns:\n",
    "                abstract = re.sub(pattern, replacement, abstract, flags=re.IGNORECASE)\n",
    "            \n",
    "            return f\"What are the fundamental concepts of {abstract.split()[-1]}?\" if len(abstract.split()) > 0 else query\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 5, include_stepback: bool = True) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"使用 step-back 進行檢索\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        # 原始查詢檢索\n",
    "        original_results = self.base_retriever.retrieve(query, k=k)\n",
    "        for doc, score in original_results:\n",
    "            results[id(doc)] = (doc, score, 'original')\n",
    "        \n",
    "        # Step-back 查詢檢索\n",
    "        if include_stepback:\n",
    "            stepback_query = self.generate_stepback_query(query)\n",
    "            stepback_results = self.base_retriever.retrieve(stepback_query, k=k//2)\n",
    "            for doc, score in stepback_results:\n",
    "                doc_id = id(doc)\n",
    "                if doc_id not in results:\n",
    "                    results[doc_id] = (doc, score * 0.8, 'stepback')  # 稍微降低權重\n",
    "        \n",
    "        # 排序\n",
    "        final_results = [(doc, score) for doc, score, _ in results.values()]\n",
    "        final_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return final_results[:k]\n",
    "\n",
    "# 測試\n",
    "stepback = StepBackRetriever(DummyRetriever())\n",
    "specific_query = \"How to implement multi-head attention in PyTorch for GPT-2?\"\n",
    "abstract_query = stepback.generate_stepback_query(specific_query)\n",
    "\n",
    "print(f\"具體查詢: {specific_query}\")\n",
    "print(f\"抽象查詢: {abstract_query}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: RAG 評估框架\n",
    "\n",
    "### 5.1 評估維度\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    RAG 評估維度                              │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  1. 檢索品質 (Retrieval Quality)                            │\n",
    "│     • Precision@K: 前 K 個結果中相關的比例                   │\n",
    "│     • Recall@K: 找到的相關文件佔全部相關文件的比例           │\n",
    "│     • MRR: 第一個相關結果的排名倒數                         │\n",
    "│     • NDCG: 考慮排名位置的相關性評分                        │\n",
    "│                                                             │\n",
    "│  2. 生成品質 (Generation Quality)                           │\n",
    "│     • Faithfulness: 生成內容是否忠於檢索結果                 │\n",
    "│     • Answer Relevance: 答案是否回答了問題                   │\n",
    "│     • Fluency: 語言流暢度                                   │\n",
    "│                                                             │\n",
    "│  3. 端到端評估 (End-to-End)                                 │\n",
    "│     • Accuracy: 答案正確率                                  │\n",
    "│     • F1 Score: 與參考答案的詞彙重疊                        │\n",
    "│     • Human Evaluation: 人工評估                            │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEvaluator:\n",
    "    \"\"\"RAG 系統評估器\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    # === 檢索品質指標 ===\n",
    "    \n",
    "    @staticmethod\n",
    "    def precision_at_k(retrieved: List[Document], relevant: List[Document], k: int) -> float:\n",
    "        \"\"\"Precision@K\"\"\"\n",
    "        retrieved_ids = {id(doc) for doc in retrieved[:k]}\n",
    "        relevant_ids = {id(doc) for doc in relevant}\n",
    "        \n",
    "        relevant_retrieved = len(retrieved_ids & relevant_ids)\n",
    "        return relevant_retrieved / k if k > 0 else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def recall_at_k(retrieved: List[Document], relevant: List[Document], k: int) -> float:\n",
    "        \"\"\"Recall@K\"\"\"\n",
    "        retrieved_ids = {id(doc) for doc in retrieved[:k]}\n",
    "        relevant_ids = {id(doc) for doc in relevant}\n",
    "        \n",
    "        relevant_retrieved = len(retrieved_ids & relevant_ids)\n",
    "        return relevant_retrieved / len(relevant_ids) if relevant_ids else 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def mrr(retrieved: List[Document], relevant: List[Document]) -> float:\n",
    "        \"\"\"Mean Reciprocal Rank\"\"\"\n",
    "        relevant_ids = {id(doc) for doc in relevant}\n",
    "        \n",
    "        for i, doc in enumerate(retrieved, 1):\n",
    "            if id(doc) in relevant_ids:\n",
    "                return 1.0 / i\n",
    "        return 0.0\n",
    "    \n",
    "    @staticmethod\n",
    "    def ndcg_at_k(retrieved: List[Document], relevance_scores: List[float], k: int) -> float:\n",
    "        \"\"\"NDCG@K\"\"\"\n",
    "        def dcg(scores, k):\n",
    "            return sum(score / np.log2(i + 2) for i, score in enumerate(scores[:k]))\n",
    "        \n",
    "        dcg_score = dcg(relevance_scores, k)\n",
    "        ideal_scores = sorted(relevance_scores, reverse=True)\n",
    "        idcg_score = dcg(ideal_scores, k)\n",
    "        \n",
    "        return dcg_score / idcg_score if idcg_score > 0 else 0.0\n",
    "    \n",
    "    # === 生成品質指標 ===\n",
    "    \n",
    "    @staticmethod\n",
    "    def faithfulness(answer: str, context: str) -> float:\n",
    "        \"\"\"\n",
    "        忠實度：答案中的資訊是否來自於 context\n",
    "        簡化實作：計算答案詞彙在 context 中出現的比例\n",
    "        \"\"\"\n",
    "        answer_words = set(answer.lower().split())\n",
    "        context_words = set(context.lower().split())\n",
    "        \n",
    "        # 移除停用詞\n",
    "        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', \n",
    "                    'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n",
    "                    'would', 'could', 'should', 'may', 'might', 'must', 'shall',\n",
    "                    'to', 'of', 'in', 'for', 'on', 'with', 'at', 'by', 'from',\n",
    "                    'as', 'into', 'through', 'during', 'before', 'after',\n",
    "                    'above', 'below', 'between', 'under', 'again', 'further',\n",
    "                    'then', 'once', 'here', 'there', 'when', 'where', 'why',\n",
    "                    'how', 'all', 'each', 'few', 'more', 'most', 'other',\n",
    "                    'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n",
    "                    'so', 'than', 'too', 'very', 'can', 'just', 'and', 'but',\n",
    "                    'or', 'if', 'because', 'until', 'while', 'this', 'that'}\n",
    "        \n",
    "        answer_words = answer_words - stopwords\n",
    "        \n",
    "        if not answer_words:\n",
    "            return 1.0\n",
    "        \n",
    "        overlap = len(answer_words & context_words)\n",
    "        return overlap / len(answer_words)\n",
    "    \n",
    "    @staticmethod\n",
    "    def answer_relevance(answer: str, question: str) -> float:\n",
    "        \"\"\"\n",
    "        答案相關性：答案是否回答了問題\n",
    "        簡化實作：問題關鍵詞在答案中出現的比例\n",
    "        \"\"\"\n",
    "        # 提取問題中的關鍵詞\n",
    "        question_words = set(re.findall(r'\\w+', question.lower()))\n",
    "        answer_words = set(re.findall(r'\\w+', answer.lower()))\n",
    "        \n",
    "        # 移除疑問詞和常見詞\n",
    "        question_words -= {'what', 'how', 'why', 'when', 'where', 'who', 'which',\n",
    "                          'is', 'are', 'the', 'a', 'an', 'do', 'does', 'can'}\n",
    "        \n",
    "        if not question_words:\n",
    "            return 1.0\n",
    "        \n",
    "        overlap = len(question_words & answer_words)\n",
    "        return overlap / len(question_words)\n",
    "\n",
    "# 測試評估器\n",
    "evaluator = RAGEvaluator()\n",
    "\n",
    "# 模擬檢索結果\n",
    "retrieved_docs = [\n",
    "    Document(content=\"Relevant doc 1\"),\n",
    "    Document(content=\"Irrelevant doc\"),\n",
    "    Document(content=\"Relevant doc 2\"),\n",
    "    Document(content=\"Irrelevant doc 2\"),\n",
    "    Document(content=\"Relevant doc 3\"),\n",
    "]\n",
    "\n",
    "relevant_docs = [retrieved_docs[0], retrieved_docs[2], retrieved_docs[4]]\n",
    "\n",
    "print(\"檢索品質評估:\")\n",
    "print(f\"  Precision@3: {evaluator.precision_at_k(retrieved_docs, relevant_docs, 3):.3f}\")\n",
    "print(f\"  Recall@3: {evaluator.recall_at_k(retrieved_docs, relevant_docs, 3):.3f}\")\n",
    "print(f\"  MRR: {evaluator.mrr(retrieved_docs, relevant_docs):.3f}\")\n",
    "\n",
    "# 模擬生成評估\n",
    "context = \"Deep learning is a subset of machine learning that uses neural networks with multiple layers.\"\n",
    "answer = \"Deep learning uses neural networks with many layers to learn complex patterns.\"\n",
    "question = \"What is deep learning?\"\n",
    "\n",
    "print(\"\\n生成品質評估:\")\n",
    "print(f\"  Faithfulness: {evaluator.faithfulness(answer, context):.3f}\")\n",
    "print(f\"  Answer Relevance: {evaluator.answer_relevance(answer, question):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 綜合 RAG 系統\n",
    "\n",
    "整合所有進階技術。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedRAG:\n",
    "    \"\"\"進階 RAG 系統：整合 HyDE、Multi-Query、Reranking\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 embedding_model_name: str = 'all-MiniLM-L6-v2',\n",
    "                 use_hyde: bool = True,\n",
    "                 use_multi_query: bool = True,\n",
    "                 use_reranking: bool = True):\n",
    "        \n",
    "        self.use_hyde = use_hyde\n",
    "        self.use_multi_query = use_multi_query\n",
    "        self.use_reranking = use_reranking\n",
    "        \n",
    "        # 初始化組件\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedding_model = SentenceTransformer(embedding_model_name)\n",
    "        except ImportError:\n",
    "            self.embedding_model = None\n",
    "        \n",
    "        self.reranker = CrossEncoderReranker() if use_reranking else None\n",
    "        self.documents: List[Document] = []\n",
    "        self.embeddings: np.ndarray = None\n",
    "    \n",
    "    def add_documents(self, documents: List[Document]):\n",
    "        \"\"\"建立索引\"\"\"\n",
    "        self.documents.extend(documents)\n",
    "        \n",
    "        if self.embedding_model:\n",
    "            new_embeddings = self.embedding_model.encode(\n",
    "                [doc.content for doc in documents],\n",
    "                show_progress_bar=False\n",
    "            )\n",
    "            if self.embeddings is None:\n",
    "                self.embeddings = new_embeddings\n",
    "            else:\n",
    "                self.embeddings = np.vstack([self.embeddings, new_embeddings])\n",
    "    \n",
    "    def _generate_queries(self, query: str) -> List[str]:\n",
    "        \"\"\"生成多個查詢\"\"\"\n",
    "        queries = [query]\n",
    "        \n",
    "        if self.use_multi_query:\n",
    "            # 簡化版多查詢\n",
    "            queries.append(f\"explain {query}\")\n",
    "            queries.append(f\"details about {query}\")\n",
    "        \n",
    "        if self.use_hyde:\n",
    "            # 簡化版 HyDE\n",
    "            hyde_query = f\"This document provides comprehensive information about {query}. It covers key concepts, methodologies, and applications.\"\n",
    "            queries.append(hyde_query)\n",
    "        \n",
    "        return queries\n",
    "    \n",
    "    def _initial_retrieval(self, query: str, k: int) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"初始檢索\"\"\"\n",
    "        if not self.embedding_model or self.embeddings is None:\n",
    "            return [(doc, 0.5) for doc in self.documents[:k]]\n",
    "        \n",
    "        query_embedding = self.embedding_model.encode([query])[0]\n",
    "        \n",
    "        # 餘弦相似度\n",
    "        similarities = np.dot(self.embeddings, query_embedding) / (\n",
    "            np.linalg.norm(self.embeddings, axis=1) * np.linalg.norm(query_embedding)\n",
    "        )\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[::-1][:k]\n",
    "        return [(self.documents[i], float(similarities[i])) for i in top_indices]\n",
    "    \n",
    "    def retrieve(self, query: str, \n",
    "                 initial_k: int = 20,\n",
    "                 final_k: int = 5) -> List[Tuple[Document, float]]:\n",
    "        \"\"\"\n",
    "        進階檢索流程\n",
    "        \n",
    "        1. Query Transformation (Multi-Query / HyDE)\n",
    "        2. Initial Retrieval (Bi-encoder)\n",
    "        3. Reranking (Cross-encoder)\n",
    "        \"\"\"\n",
    "        # Step 1: Query Transformation\n",
    "        queries = self._generate_queries(query)\n",
    "        \n",
    "        # Step 2: Initial Retrieval (對所有查詢)\n",
    "        all_candidates = {}\n",
    "        for q in queries:\n",
    "            results = self._initial_retrieval(q, initial_k)\n",
    "            for doc, score in results:\n",
    "                doc_id = id(doc)\n",
    "                if doc_id not in all_candidates:\n",
    "                    all_candidates[doc_id] = (doc, score)\n",
    "                else:\n",
    "                    # 融合分數（取最大）\n",
    "                    _, existing_score = all_candidates[doc_id]\n",
    "                    all_candidates[doc_id] = (doc, max(score, existing_score))\n",
    "        \n",
    "        # 轉換為列表\n",
    "        candidates = list(all_candidates.values())\n",
    "        \n",
    "        # Step 3: Reranking\n",
    "        if self.use_reranking and self.reranker:\n",
    "            candidate_docs = [doc for doc, _ in candidates]\n",
    "            results = self.reranker.rerank(query, candidate_docs, top_k=final_k)\n",
    "        else:\n",
    "            candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "            results = candidates[:final_k]\n",
    "        \n",
    "        return results\n",
    "\n",
    "print(\"AdvancedRAG 系統已定義\")\n",
    "print(\"\\n支援的功能:\")\n",
    "print(\"  - HyDE (Hypothetical Document Embeddings)\")\n",
    "print(\"  - Multi-Query Retrieval\")\n",
    "print(\"  - Cross-encoder Reranking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: 練習題\n",
    "\n",
    "### Exercise 1: 實作 Contextual Compression\n",
    "\n",
    "在將文件送入 LLM 前，壓縮/過濾掉不相關的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualCompressor:\n",
    "    \"\"\"\n",
    "    上下文壓縮器：過濾掉文件中與查詢不相關的部分\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_model=None, similarity_threshold: float = 0.3):\n",
    "        try:\n",
    "            from sentence_transformers import SentenceTransformer\n",
    "            self.embedding_model = embedding_model or SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        except ImportError:\n",
    "            self.embedding_model = None\n",
    "        \n",
    "        self.similarity_threshold = similarity_threshold\n",
    "    \n",
    "    def compress(self, query: str, document: Document) -> Document:\n",
    "        \"\"\"\n",
    "        壓縮文件，只保留與查詢相關的句子\n",
    "        \"\"\"\n",
    "        # TODO: 實作壓縮邏輯\n",
    "        # 1. 將文件分成句子\n",
    "        # 2. 計算每個句子與查詢的相似度\n",
    "        # 3. 只保留相似度高於閾值的句子\n",
    "        \n",
    "        sentences = re.split(r'(?<=[.!?])\\s+', document.content)\n",
    "        \n",
    "        if not self.embedding_model:\n",
    "            # 簡化版：使用詞彙重疊\n",
    "            query_words = set(query.lower().split())\n",
    "            relevant_sentences = []\n",
    "            for sent in sentences:\n",
    "                sent_words = set(sent.lower().split())\n",
    "                overlap = len(query_words & sent_words) / len(query_words) if query_words else 0\n",
    "                if overlap > self.similarity_threshold:\n",
    "                    relevant_sentences.append(sent)\n",
    "        else:\n",
    "            # 使用 embedding 相似度\n",
    "            query_emb = self.embedding_model.encode([query])[0]\n",
    "            sent_embs = self.embedding_model.encode(sentences)\n",
    "            \n",
    "            relevant_sentences = []\n",
    "            for sent, sent_emb in zip(sentences, sent_embs):\n",
    "                sim = np.dot(query_emb, sent_emb) / (\n",
    "                    np.linalg.norm(query_emb) * np.linalg.norm(sent_emb)\n",
    "                )\n",
    "                if sim > self.similarity_threshold:\n",
    "                    relevant_sentences.append(sent)\n",
    "        \n",
    "        # 如果沒有相關句子，返回原文件的開頭部分\n",
    "        if not relevant_sentences:\n",
    "            compressed_content = ' '.join(sentences[:2]) if len(sentences) > 2 else document.content\n",
    "        else:\n",
    "            compressed_content = ' '.join(relevant_sentences)\n",
    "        \n",
    "        return Document(\n",
    "            content=compressed_content,\n",
    "            metadata={**document.metadata, 'compressed': True, 'original_length': len(document.content)}\n",
    "        )\n",
    "\n",
    "# 測試壓縮器\n",
    "compressor = ContextualCompressor(similarity_threshold=0.2)\n",
    "\n",
    "test_doc = Document(content=\"\"\"\n",
    "Machine learning is a field of artificial intelligence. It allows computers to learn from data.\n",
    "The weather today is sunny with a high of 25 degrees. Perfect for outdoor activities.\n",
    "Deep learning is a subset of machine learning using neural networks. It has revolutionized many fields.\n",
    "Pizza is a popular Italian dish. It comes with various toppings like cheese and pepperoni.\n",
    "Neural networks are inspired by the human brain. They consist of layers of interconnected nodes.\n",
    "\"\"\")\n",
    "\n",
    "query = \"How does machine learning use neural networks?\"\n",
    "compressed = compressor.compress(query, test_doc)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"\\nOriginal length: {len(test_doc.content)} chars\")\n",
    "print(f\"Compressed length: {len(compressed.content)} chars\")\n",
    "print(f\"\\nCompressed content:\\n{compressed.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: 實作 Self-RAG\n",
    "\n",
    "讓模型自己決定何時需要檢索。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfRAG:\n",
    "    \"\"\"\n",
    "    Self-RAG: 模型自主決定是否需要檢索\n",
    "    \n",
    "    流程:\n",
    "    1. 判斷是否需要檢索\n",
    "    2. 如果需要，執行檢索\n",
    "    3. 判斷檢索結果是否有用\n",
    "    4. 生成最終答案\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, retriever, generator=None):\n",
    "        self.retriever = retriever\n",
    "        self.generator = generator\n",
    "        \n",
    "        # 判斷是否需要檢索的關鍵詞\n",
    "        self.retrieval_triggers = [\n",
    "            'what is', 'how does', 'explain', 'define', 'describe',\n",
    "            'who is', 'when did', 'where is', 'why does',\n",
    "            'tell me about', 'information about'\n",
    "        ]\n",
    "    \n",
    "    def needs_retrieval(self, query: str) -> bool:\n",
    "        \"\"\"\n",
    "        判斷查詢是否需要檢索\n",
    "        \n",
    "        簡化實作：基於規則判斷\n",
    "        實際應該用 LLM 判斷\n",
    "        \"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        # 檢查觸發詞\n",
    "        for trigger in self.retrieval_triggers:\n",
    "            if trigger in query_lower:\n",
    "                return True\n",
    "        \n",
    "        # 檢查問號\n",
    "        if '?' in query:\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def is_relevant(self, query: str, document: Document, threshold: float = 0.3) -> bool:\n",
    "        \"\"\"\n",
    "        判斷檢索結果是否相關\n",
    "        \"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        doc_words = set(document.content.lower().split())\n",
    "        \n",
    "        # 移除停用詞\n",
    "        stopwords = {'the', 'a', 'an', 'is', 'are', 'what', 'how', 'why', 'when', 'where', 'who'}\n",
    "        query_words -= stopwords\n",
    "        \n",
    "        if not query_words:\n",
    "            return True\n",
    "        \n",
    "        overlap = len(query_words & doc_words) / len(query_words)\n",
    "        return overlap >= threshold\n",
    "    \n",
    "    def query(self, query: str, k: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        執行 Self-RAG 查詢\n",
    "        \"\"\"\n",
    "        result = {\n",
    "            'query': query,\n",
    "            'retrieval_needed': False,\n",
    "            'retrieved_docs': [],\n",
    "            'relevant_docs': [],\n",
    "            'answer': None\n",
    "        }\n",
    "        \n",
    "        # Step 1: 判斷是否需要檢索\n",
    "        if self.needs_retrieval(query):\n",
    "            result['retrieval_needed'] = True\n",
    "            \n",
    "            # Step 2: 執行檢索\n",
    "            retrieved = self.retriever.retrieve(query, k=k)\n",
    "            result['retrieved_docs'] = retrieved\n",
    "            \n",
    "            # Step 3: 過濾相關結果\n",
    "            for doc, score in retrieved:\n",
    "                if self.is_relevant(query, doc):\n",
    "                    result['relevant_docs'].append((doc, score))\n",
    "        \n",
    "        # Step 4: 生成答案（這裡簡化處理）\n",
    "        if result['relevant_docs']:\n",
    "            context = ' '.join([doc.content for doc, _ in result['relevant_docs']])\n",
    "            result['answer'] = f\"Based on retrieved information: {context[:200]}...\"\n",
    "        else:\n",
    "            result['answer'] = \"I can answer this based on my knowledge.\"\n",
    "        \n",
    "        return result\n",
    "\n",
    "# 測試\n",
    "print(\"Self-RAG 系統已定義\")\n",
    "print(\"\\n特點:\")\n",
    "print(\"1. 自動判斷是否需要檢索\")\n",
    "print(\"2. 過濾不相關的檢索結果\")\n",
    "print(\"3. 根據結果品質決定是否使用\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                   RAG 進階技術總結                           │\n",
    "├─────────────────────────────────────────────────────────────┤\n",
    "│                                                             │\n",
    "│  Pre-Retrieval 優化                                         │\n",
    "│  ├─ Multi-Query: 多角度查詢增加召回                         │\n",
    "│  ├─ HyDE: 假設性文件縮小查詢-文件差距                       │\n",
    "│  └─ Step-back: 抽象化查詢獲取背景知識                       │\n",
    "│                                                             │\n",
    "│  Retrieval 優化                                             │\n",
    "│  ├─ Two-stage: Bi-encoder 召回 + Cross-encoder 精排        │\n",
    "│  └─ Hybrid: 向量搜尋 + BM25                                 │\n",
    "│                                                             │\n",
    "│  Post-Retrieval 優化                                        │\n",
    "│  ├─ Reranking: Cross-encoder 重排序                        │\n",
    "│  ├─ Compression: 過濾不相關內容                             │\n",
    "│  └─ Self-RAG: 自主決定檢索需求                              │\n",
    "│                                                             │\n",
    "│  評估維度                                                   │\n",
    "│  ├─ Retrieval: P@K, R@K, MRR, NDCG                         │\n",
    "│  ├─ Generation: Faithfulness, Relevance                    │\n",
    "│  └─ End-to-End: Accuracy, F1                               │\n",
    "│                                                             │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### 下一步學習\n",
    "\n",
    "- **AI Agent**: `ai_agents/agent_tools.ipynb`\n",
    "- **LLM 微調**: `language_models/llm_finetuning.ipynb`\n",
    "- **RLHF**: `reinforcement_learning/rlhf_alignment.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 參考資源\n",
    "\n",
    "### 論文\n",
    "- [Precise Zero-Shot Dense Retrieval without Relevance Labels](https://arxiv.org/abs/2212.10496) - HyDE\n",
    "- [Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection](https://arxiv.org/abs/2310.11511)\n",
    "- [Take a Step Back: Evoking Reasoning via Abstraction](https://arxiv.org/abs/2310.06117)\n",
    "\n",
    "### 工具\n",
    "- [LangChain](https://python.langchain.com/)\n",
    "- [LlamaIndex](https://www.llamaindex.ai/)\n",
    "- [RAGAS](https://github.com/explodinggradients/ragas) - RAG 評估框架"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
