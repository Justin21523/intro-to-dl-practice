{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åˆ†é¡ä»»å‹™ (Classification)\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£åˆ†é¡å•é¡Œèˆ‡è¿´æ­¸å•é¡Œçš„å·®ç•°\n",
    "- æŒæ¡å¤šé¡åˆ¥åˆ†é¡çš„å¯¦ç¾\n",
    "- å­¸ç¿’éŸ³æ¡†åˆ†é¡ä»»å‹™ï¼ˆæå®æ¯… HW2ï¼‰\n",
    "- è™•ç†é¡åˆ¥ä¸å¹³è¡¡å•é¡Œ\n",
    "\n",
    "## å°æ‡‰èª²ç¨‹\n",
    "- [æå®æ¯… ML 2021 - Lecture 2: Classification](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php)\n",
    "- [HW2: Phoneme Classification](https://github.com/ga642381/ML2021-Spring/tree/main/HW02)\n",
    "\n",
    "## åˆ†é¡å•é¡Œæ¦‚è¿°\n",
    "\n",
    "```\n",
    "åˆ†é¡ä»»å‹™é¡å‹\n",
    "â”œâ”€â”€ äºŒå…ƒåˆ†é¡ (Binary): åƒåœ¾éƒµä»¶æª¢æ¸¬\n",
    "â”œâ”€â”€ å¤šé¡åˆ¥åˆ†é¡ (Multi-class): æ‰‹å¯«æ•¸å­—è­˜åˆ¥ï¼ˆ0-9ï¼‰\n",
    "â””â”€â”€ å¤šæ¨™ç±¤åˆ†é¡ (Multi-label): æ–‡ç« æ¨™ç±¤ï¼ˆå¯æœ‰å¤šå€‹æ¨™ç±¤ï¼‰\n",
    "\n",
    "HW2: Phoneme Classification\n",
    "â”œâ”€â”€ è¼¸å…¥: èªéŸ³ç‰¹å¾µ (MFCC)\n",
    "â”œâ”€â”€ è¼¸å‡º: 39 å€‹éŸ³ç´ é¡åˆ¥ä¹‹ä¸€\n",
    "â””â”€â”€ æŒ‘æˆ°: ä¸Šä¸‹æ–‡ç›¸é—œæ€§ã€é¡åˆ¥ä¸å¹³è¡¡\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è¨­å‚™: {device}\")\n",
    "\n",
    "# å›ºå®šéš¨æ©Ÿç¨®å­\n",
    "def set_seed(seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: åˆ†é¡åŸºç¤\n",
    "\n",
    "### åˆ†é¡ vs è¿´æ­¸\n",
    "\n",
    "| | è¿´æ­¸ | åˆ†é¡ |\n",
    "|---|---|---|\n",
    "| **è¼¸å‡º** | é€£çºŒå€¼ | é›¢æ•£é¡åˆ¥ |\n",
    "| **æå¤±å‡½æ•¸** | MSE, MAE | Cross-Entropy |\n",
    "| **è¼¸å‡ºå±¤** | 1 å€‹ç¥ç¶“å…ƒ | N å€‹ç¥ç¶“å…ƒ (N é¡) |\n",
    "| **æ¿€æ´»å‡½æ•¸** | ç„¡ / Linear | Softmax |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Softmax èˆ‡ Cross-Entropy ==========\n",
    "\n",
    "# Softmax: å°‡ logits è½‰ç‚ºæ¦‚ç‡åˆ†å¸ƒ\n",
    "logits = torch.tensor([2.0, 1.0, 0.1])\n",
    "probs = F.softmax(logits, dim=0)\n",
    "\n",
    "print(\"Softmax ç¤ºä¾‹:\")\n",
    "print(f\"  Logits: {logits}\")\n",
    "print(f\"  Probabilities: {probs}\")\n",
    "print(f\"  Sum: {probs.sum():.4f}\")\n",
    "\n",
    "# Cross-Entropy Loss\n",
    "# PyTorch çš„ CrossEntropyLoss åŒ…å« Softmaxï¼Œè¼¸å…¥æ‡‰ç‚º logits\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# æ¨¡æ“¬æ‰¹æ¬¡è³‡æ–™\n",
    "batch_logits = torch.randn(4, 3)  # 4 å€‹æ¨£æœ¬ï¼Œ3 å€‹é¡åˆ¥\n",
    "targets = torch.tensor([0, 1, 2, 0])  # çœŸå¯¦æ¨™ç±¤\n",
    "\n",
    "loss = criterion(batch_logits, targets)\n",
    "print(f\"\\nCross-Entropy Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== åˆ†é¡æ¨¡å‹åŸºæœ¬çµæ§‹ ==========\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    åŸºæœ¬åˆ†é¡å™¨\n",
    "    \n",
    "    æ³¨æ„ï¼šè¼¸å‡ºå±¤ä¸åŠ  Softmaxï¼Œå› ç‚º CrossEntropyLoss æœƒè™•ç†\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dims, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # è¼¸å‡ºå±¤ï¼šnum_classes å€‹é¡åˆ¥\n",
    "        layers.append(nn.Linear(prev_dim, num_classes))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # è¼¸å‡º logits\n",
    "\n",
    "# æ¸¬è©¦\n",
    "model = Classifier(input_dim=39, hidden_dims=[256, 128, 64], num_classes=39)\n",
    "print(model)\n",
    "\n",
    "x = torch.randn(4, 39)\n",
    "out = model(x)\n",
    "print(f\"\\nè¼¸å…¥: {x.shape}\")\n",
    "print(f\"è¼¸å‡º (logits): {out.shape}\")\n",
    "print(f\"é æ¸¬é¡åˆ¥: {out.argmax(dim=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Phoneme Classificationï¼ˆæå®æ¯… HW2ï¼‰\n",
    "\n",
    "### ä»»å‹™èªªæ˜\n",
    "\n",
    "**ç›®æ¨™**ï¼šæ ¹æ“šèªéŸ³ç‰¹å¾µ (MFCC) é æ¸¬éŸ³ç´ é¡åˆ¥\n",
    "\n",
    "**ç‰¹å¾µ**ï¼š\n",
    "- MFCC (Mel-Frequency Cepstral Coefficients): 39 ç¶­\n",
    "- å¯è€ƒæ…®å‰å¾Œå¹¾å€‹ frame çš„ä¸Šä¸‹æ–‡\n",
    "\n",
    "**è¼¸å‡º**ï¼š39 å€‹éŸ³ç´ é¡åˆ¥ä¹‹ä¸€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æ¨¡æ“¬ Phoneme è³‡æ–™é›† ==========\n",
    "\n",
    "def generate_phoneme_data(n_samples=10000, feat_dim=39, n_classes=39, context=5):\n",
    "    \"\"\"\n",
    "    ç”Ÿæˆé¡ä¼¼ HW2 çš„ Phoneme è³‡æ–™\n",
    "    \n",
    "    å¯¦éš› HW2:\n",
    "    - æ¯å€‹ frame æœ‰ 39 ç¶­ MFCC ç‰¹å¾µ\n",
    "    - å¯ä»¥ä¸²æ¥å‰å¾Œ n å€‹ frame ä½œç‚ºä¸Šä¸‹æ–‡\n",
    "    - ç›®æ¨™æ˜¯ 39 é¡éŸ³ç´ \n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # ç‰¹å¾µç¶­åº¦ = MFCC * (context * 2 + 1)\n",
    "    total_feat_dim = feat_dim * (context * 2 + 1)\n",
    "    \n",
    "    # ç”Ÿæˆç‰¹å¾µï¼ˆæ¨¡æ“¬ MFCCï¼‰\n",
    "    X = np.random.randn(n_samples, total_feat_dim).astype(np.float32)\n",
    "    \n",
    "    # ç”Ÿæˆæ¨™ç±¤ï¼ˆæ¨¡æ“¬ä¸å¹³è¡¡åˆ†å¸ƒï¼‰\n",
    "    # æŸäº›éŸ³ç´ å‡ºç¾é »ç‡è¼ƒé«˜\n",
    "    class_probs = np.random.dirichlet(np.ones(n_classes) * 0.5)\n",
    "    y = np.random.choice(n_classes, n_samples, p=class_probs).astype(np.int64)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# ç”Ÿæˆè³‡æ–™\n",
    "CONTEXT = 5  # è€ƒæ…®å‰å¾Œå„ 5 å€‹ frame\n",
    "X, y = generate_phoneme_data(n_samples=10000, context=CONTEXT)\n",
    "\n",
    "print(f\"ç‰¹å¾µç¶­åº¦: {X.shape}\")\n",
    "print(f\"  MFCC: 39 ç¶­\")\n",
    "print(f\"  ä¸Šä¸‹æ–‡: å‰å¾Œå„ {CONTEXT} å€‹ frame\")\n",
    "print(f\"  ç¸½ç¶­åº¦: 39 Ã— {CONTEXT*2+1} = {39*(CONTEXT*2+1)}\")\n",
    "print(f\"\\næ¨™ç±¤åˆ†å¸ƒ:\")\n",
    "label_counts = Counter(y)\n",
    "print(f\"  é¡åˆ¥æ•¸: {len(label_counts)}\")\n",
    "print(f\"  æœ€å¤š: {max(label_counts.values())}\")\n",
    "print(f\"  æœ€å°‘: {min(label_counts.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Dataset é¡åˆ¥ ==========\n",
    "\n",
    "class PhonemeDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Phoneme åˆ†é¡è³‡æ–™é›†\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.LongTensor(y) if y is not None else None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]\n",
    "\n",
    "# åˆ†å‰²è³‡æ–™\n",
    "train_ratio = 0.8\n",
    "n_train = int(len(X) * train_ratio)\n",
    "\n",
    "# æ¨™æº–åŒ–\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X[:n_train])\n",
    "X_val = scaler.transform(X[n_train:])\n",
    "y_train, y_val = y[:n_train], y[n_train:]\n",
    "\n",
    "print(f\"è¨“ç·´é›†: {X_train.shape[0]}\")\n",
    "print(f\"é©—è­‰é›†: {X_val.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== é€²éšåˆ†é¡å™¨ï¼ˆHW2 Strong Baselineï¼‰==========\n",
    "\n",
    "class PhonemeClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Phoneme åˆ†é¡å™¨\n",
    "    \n",
    "    HW2 Strong Baseline æŠ€å·§:\n",
    "    - è¼ƒæ·±çš„ç¶²è·¯ (5-6 å±¤)\n",
    "    - BatchNorm + Dropout\n",
    "    - é©ç•¶çš„ hidden size\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=512, num_classes=39, num_layers=5, dropout=0.25):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_layer = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        \n",
    "        # ä¸­é–“å±¤\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.hidden_layers.append(nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.BatchNorm1d(hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "            ))\n",
    "        \n",
    "        # è¼¸å‡ºå±¤\n",
    "        self.output_layer = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_layer(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# å»ºç«‹æ¨¡å‹\n",
    "model = PhonemeClassifier(\n",
    "    input_dim=X_train.shape[1],\n",
    "    hidden_dim=512,\n",
    "    num_classes=39,\n",
    "    num_layers=5,\n",
    "    dropout=0.25\n",
    ")\n",
    "\n",
    "# è¨ˆç®—åƒæ•¸é‡\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"æ¨¡å‹åƒæ•¸é‡: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== è¨“ç·´é…ç½® ==========\n",
    "\n",
    "config = {\n",
    "    'batch_size': 512,\n",
    "    'epochs': 50,\n",
    "    'lr': 1e-3,\n",
    "    'weight_decay': 1e-5,\n",
    "}\n",
    "\n",
    "# å»ºç«‹ DataLoader\n",
    "train_dataset = PhonemeDataset(X_train, y_train)\n",
    "val_dataset = PhonemeDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== è¨“ç·´å‡½æ•¸ ==========\n",
    "\n",
    "def train_classifier(model, train_loader, val_loader, config):\n",
    "    \"\"\"\n",
    "    è¨“ç·´åˆ†é¡æ¨¡å‹\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=config['lr'],\n",
    "        weight_decay=config['weight_decay']\n",
    "    )\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=config['epochs']\n",
    "    )\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'val_acc': []}\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # ========== è¨“ç·´ ==========\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * len(X_batch)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        \n",
    "        # ========== é©—è­‰ ==========\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                X_batch = X_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                \n",
    "                logits = model(X_batch)\n",
    "                loss = criterion(logits, y_batch)\n",
    "                \n",
    "                val_loss += loss.item() * len(X_batch)\n",
    "                pred = logits.argmax(dim=1)\n",
    "                correct += (pred == y_batch).sum().item()\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_acc = correct / len(val_loader.dataset)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{config['epochs']}\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    model.load_state_dict(best_model_state)\n",
    "    print(f\"\\næœ€ä½³é©—è­‰æº–ç¢ºç‡: {best_acc:.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "# è¨“ç·´\n",
    "model, history = train_classifier(model, train_loader, val_loader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== çµæœå¯è¦–åŒ– ==========\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# æå¤±æ›²ç·š\n",
    "axes[0].plot(history['train_loss'], label='Train')\n",
    "axes[0].plot(history['val_loss'], label='Val')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Loss Curve')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# æº–ç¢ºç‡æ›²ç·š\n",
    "axes[1].plot(history['val_acc'])\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# æ··æ·†çŸ©é™£\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "    y_pred = model(X_val_tensor).argmax(dim=1).cpu().numpy()\n",
    "\n",
    "# åªé¡¯ç¤ºéƒ¨åˆ†é¡åˆ¥çš„æ··æ·†çŸ©é™£\n",
    "cm = confusion_matrix(y_val[:1000], y_pred[:1000])\n",
    "sns.heatmap(cm[:10, :10], annot=True, fmt='d', cmap='Blues', ax=axes[2])\n",
    "axes[2].set_xlabel('Predicted')\n",
    "axes[2].set_ylabel('Actual')\n",
    "axes[2].set_title('Confusion Matrix (Top 10 Classes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# åˆ†é¡å ±å‘Š\n",
    "print(\"\\nåˆ†é¡å ±å‘Š (å‰ 10 é¡):\")\n",
    "print(classification_report(y_val, y_pred, labels=range(10), digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: è™•ç†é¡åˆ¥ä¸å¹³è¡¡\n",
    "\n",
    "å¯¦éš›è³‡æ–™ä¸­ï¼Œå„é¡åˆ¥æ¨£æœ¬æ•¸å¾€å¾€ä¸å¹³è¡¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æ–¹æ³• 1: Weighted Loss ==========\n",
    "\n",
    "def compute_class_weights(labels, num_classes):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—é¡åˆ¥æ¬Šé‡\n",
    "    \n",
    "    å°‘æ•¸é¡åˆ¥ç²å¾—æ›´é«˜æ¬Šé‡\n",
    "    \"\"\"\n",
    "    counts = np.bincount(labels, minlength=num_classes)\n",
    "    weights = 1.0 / (counts + 1e-6)\n",
    "    weights = weights / weights.sum() * num_classes\n",
    "    return torch.FloatTensor(weights)\n",
    "\n",
    "# è¨ˆç®—æ¬Šé‡\n",
    "class_weights = compute_class_weights(y_train, 39)\n",
    "print(f\"é¡åˆ¥æ¬Šé‡ç¯„åœ: [{class_weights.min():.2f}, {class_weights.max():.2f}]\")\n",
    "\n",
    "# ä½¿ç”¨åŠ æ¬Šæå¤±\n",
    "weighted_criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æ–¹æ³• 2: Weighted Sampler ==========\n",
    "\n",
    "def get_weighted_sampler(labels):\n",
    "    \"\"\"\n",
    "    å»ºç«‹åŠ æ¬Šæ¡æ¨£å™¨\n",
    "    \n",
    "    ä½¿å°‘æ•¸é¡åˆ¥è¢«æ¡æ¨£çš„æ©Ÿç‡å¢åŠ \n",
    "    \"\"\"\n",
    "    counts = np.bincount(labels)\n",
    "    weights = 1.0 / counts[labels]\n",
    "    weights = torch.DoubleTensor(weights)\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=weights,\n",
    "        num_samples=len(weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return sampler\n",
    "\n",
    "# ä½¿ç”¨åŠ æ¬Šæ¡æ¨£å™¨\n",
    "sampler = get_weighted_sampler(y_train)\n",
    "balanced_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    sampler=sampler  # ä¸èƒ½åŒæ™‚ä½¿ç”¨ shuffle å’Œ sampler\n",
    ")\n",
    "\n",
    "# é©—è­‰æ¡æ¨£æ•ˆæœ\n",
    "batch_labels = []\n",
    "for _, y_batch in balanced_loader:\n",
    "    batch_labels.extend(y_batch.tolist())\n",
    "    if len(batch_labels) > 2000:\n",
    "        break\n",
    "\n",
    "print(\"åŠ æ¬Šæ¡æ¨£å¾Œçš„é¡åˆ¥åˆ†å¸ƒæ›´å‡å‹»\")\n",
    "print(f\"åŸå§‹æœ€å¤§/æœ€å°æ¯”: {max(Counter(y_train).values()) / min(Counter(y_train).values()):.2f}\")\n",
    "print(f\"æ¡æ¨£å¾Œæœ€å¤§/æœ€å°æ¯”: {max(Counter(batch_labels).values()) / min(Counter(batch_labels).values()):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æ–¹æ³• 3: Focal Loss ==========\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss: é™ä½ç°¡å–®æ¨£æœ¬çš„æ¬Šé‡ï¼Œå°ˆæ³¨æ–¼å›°é›£æ¨£æœ¬\n",
    "    \n",
    "    FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)\n",
    "    \n",
    "    - Î³ (gamma): èšç„¦åƒæ•¸ï¼ŒÎ³=0 æ™‚ç­‰åŒæ–¼ CE Loss\n",
    "    - Î± (alpha): é¡åˆ¥å¹³è¡¡å› å­\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        p_t = torch.exp(-ce_loss)\n",
    "        focal_weight = (1 - p_t) ** self.gamma\n",
    "        \n",
    "        if self.alpha is not None:\n",
    "            alpha_t = self.alpha[targets]\n",
    "            focal_weight = alpha_t * focal_weight\n",
    "        \n",
    "        loss = focal_weight * ce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        return loss\n",
    "\n",
    "# æ¸¬è©¦ Focal Loss\n",
    "focal_criterion = FocalLoss(gamma=2.0)\n",
    "ce_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# æ¯”è¼ƒå…©ç¨®æå¤±\n",
    "logits = torch.randn(100, 39)\n",
    "targets = torch.randint(0, 39, (100,))\n",
    "\n",
    "print(f\"Cross-Entropy Loss: {ce_criterion(logits, targets):.4f}\")\n",
    "print(f\"Focal Loss: {focal_criterion(logits, targets):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Label Smoothing\n",
    "\n",
    "é˜²æ­¢æ¨¡å‹éåº¦è‡ªä¿¡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Label Smoothing ==========\n",
    "\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    \"\"\"\n",
    "    Label Smoothing Cross Entropy\n",
    "    \n",
    "    å°‡ one-hot æ¨™ç±¤è»ŸåŒ–ï¼š\n",
    "    - åŸæœ¬: [0, 0, 1, 0, 0]\n",
    "    - è»ŸåŒ–: [0.02, 0.02, 0.92, 0.02, 0.02] (smoothing=0.1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing=0.1):\n",
    "        super().__init__()\n",
    "        self.smoothing = smoothing\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        n_classes = inputs.size(-1)\n",
    "        log_preds = F.log_softmax(inputs, dim=-1)\n",
    "        \n",
    "        # è¨ˆç®— smooth label çš„æå¤±\n",
    "        loss = -log_preds.sum(dim=-1) / n_classes\n",
    "        \n",
    "        # è¨ˆç®— hard label çš„æå¤±\n",
    "        nll_loss = F.nll_loss(log_preds, targets, reduction='none')\n",
    "        \n",
    "        # çµ„åˆ\n",
    "        loss = (1 - self.smoothing) * nll_loss + self.smoothing * loss\n",
    "        return loss.mean()\n",
    "\n",
    "# PyTorch å…§å»ºç‰ˆæœ¬ï¼ˆ1.10+ï¼‰\n",
    "smooth_criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "print(\"Label Smoothing æ•ˆæœ:\")\n",
    "print(f\"  CE Loss: {ce_criterion(logits, targets):.4f}\")\n",
    "print(f\"  Smooth CE Loss: {smooth_criterion(logits, targets):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¯ ç¸½çµ\n",
    "\n",
    "### åˆ†é¡ä»»å‹™é‡é»\n",
    "\n",
    "| æŠ€å·§ | èªªæ˜ |\n",
    "|------|------|\n",
    "| **Cross-Entropy Loss** | åˆ†é¡æ¨™æº–æå¤±å‡½æ•¸ |\n",
    "| **Softmax** | è¼¸å‡ºè½‰ç‚ºæ¦‚ç‡ï¼ˆPyTorch CE å…§å»ºï¼‰|\n",
    "| **BatchNorm + Dropout** | æ­£å‰‡åŒ– |\n",
    "| **Weighted Loss** | è™•ç†é¡åˆ¥ä¸å¹³è¡¡ |\n",
    "| **Label Smoothing** | é˜²æ­¢éåº¦è‡ªä¿¡ |\n",
    "\n",
    "### è©•ä¼°æŒ‡æ¨™\n",
    "\n",
    "| æŒ‡æ¨™ | èªªæ˜ |\n",
    "|------|------|\n",
    "| **Accuracy** | æ•´é«”æº–ç¢ºç‡ |\n",
    "| **Precision** | é æ¸¬ç‚ºæ­£çš„æ­£ç¢ºæ¯”ä¾‹ |\n",
    "| **Recall** | å¯¦éš›ç‚ºæ­£çš„æª¢å‡ºæ¯”ä¾‹ |\n",
    "| **F1-Score** | Precision å’Œ Recall çš„èª¿å’Œå¹³å‡ |\n",
    "| **Confusion Matrix** | è©³ç´°é¡åˆ¥é æ¸¬æƒ…æ³ |\n",
    "\n",
    "### æå®æ¯… HW2 æŠ€å·§\n",
    "\n",
    "```\n",
    "Strong Baseline é”æˆæ–¹æ³•:\n",
    "1. ä¸²æ¥ä¸Šä¸‹æ–‡ frameï¼ˆå‰å¾Œå„ 5-11 å€‹ï¼‰\n",
    "2. è¼ƒæ·±çš„ç¶²è·¯ï¼ˆ5-6 å±¤ï¼‰\n",
    "3. è¼ƒå¤§çš„ hidden sizeï¼ˆ512-1024ï¼‰\n",
    "4. BatchNorm + Dropout\n",
    "5. å­¸ç¿’ç‡èª¿åº¦ï¼ˆCosine Annealingï¼‰\n",
    "```\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "å‰å¾€ `computer_vision/cnn_fundamentals.ipynb` å­¸ç¿’å·ç©ç¥ç¶“ç¶²è·¯ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ç·´ç¿’é¡Œ\n\n### ç·´ç¿’ 1: æ¯”è¼ƒä¸åŒä¸Šä¸‹æ–‡é•·åº¦çš„æ•ˆæœ\n\n**ç›®æ¨™**: å¯¦é©—ä¸åŒ context å¤§å°å°éŸ³æ¡†åˆ†é¡çš„å½±éŸ¿",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ç·´ç¿’ 1: æ¯”è¼ƒä¸åŒä¸Šä¸‹æ–‡é•·åº¦\n\ndef experiment_context_size(context_sizes=[0, 2, 5, 8, 11]):\n    \"\"\"æ¯”è¼ƒä¸åŒä¸Šä¸‹æ–‡é•·åº¦çš„æ•ˆæœ\"\"\"\n    results = []\n    \n    for ctx in context_sizes:\n        print(f\"\\n=== Context = {ctx} ===\")\n        \n        # ç”Ÿæˆè³‡æ–™\n        X_ctx, y_ctx = generate_phoneme_data(n_samples=5000, context=ctx)\n        \n        # åˆ†å‰²\n        n_train = int(len(X_ctx) * 0.8)\n        X_tr, X_vl = X_ctx[:n_train], X_ctx[n_train:]\n        y_tr, y_vl = y_ctx[:n_train], y_ctx[n_train:]\n        \n        # æ¨™æº–åŒ–\n        scaler = StandardScaler()\n        X_tr = scaler.fit_transform(X_tr)\n        X_vl = scaler.transform(X_vl)\n        \n        # å»ºç«‹ DataLoader\n        train_ds = PhonemeDataset(X_tr, y_tr)\n        val_ds = PhonemeDataset(X_vl, y_vl)\n        train_dl = DataLoader(train_ds, batch_size=256, shuffle=True)\n        val_dl = DataLoader(val_ds, batch_size=256)\n        \n        # è¨“ç·´æ¨¡å‹ï¼ˆç°¡åŒ–ç‰ˆï¼‰\n        model = PhonemeClassifier(input_dim=X_tr.shape[1], hidden_dim=256, num_layers=3).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n        criterion = nn.CrossEntropyLoss()\n        \n        for epoch in range(20):\n            model.train()\n            for X_batch, y_batch in train_dl:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                optimizer.zero_grad()\n                loss = criterion(model(X_batch), y_batch)\n                loss.backward()\n                optimizer.step()\n        \n        # è©•ä¼°\n        model.eval()\n        correct = 0\n        with torch.no_grad():\n            for X_batch, y_batch in val_dl:\n                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n                pred = model(X_batch).argmax(dim=1)\n                correct += (pred == y_batch).sum().item()\n        \n        acc = correct / len(val_ds)\n        results.append({'context': ctx, 'accuracy': acc, 'feature_dim': X_tr.shape[1]})\n        print(f\"  Feature dim: {X_tr.shape[1]}, Accuracy: {acc:.4f}\")\n    \n    return results\n\n# åŸ·è¡Œå¯¦é©—\nctx_results = experiment_context_size()\n\n# è¦–è¦ºåŒ–\nfig, ax = plt.subplots(figsize=(8, 5))\ncontexts = [r['context'] for r in ctx_results]\naccs = [r['accuracy'] for r in ctx_results]\nax.plot(contexts, accs, 'bo-', linewidth=2, markersize=10)\nax.set_xlabel('Context Size')\nax.set_ylabel('Validation Accuracy')\nax.set_title('Effect of Context Size on Phoneme Classification')\nax.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"\\næœ€ä½³ context: {ctx_results[np.argmax(accs)]['context']}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ç·´ç¿’ 2: æ¯”è¼ƒä¸åŒè™•ç†é¡åˆ¥ä¸å¹³è¡¡çš„æ–¹æ³•\n\n**ç›®æ¨™**: æ¯”è¼ƒ Weighted Lossã€Focal Lossã€Weighted Sampler çš„æ•ˆæœ",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ç·´ç¿’ 2: æ¯”è¼ƒè™•ç†é¡åˆ¥ä¸å¹³è¡¡çš„æ–¹æ³•\n\n# ç”Ÿæˆé«˜åº¦ä¸å¹³è¡¡çš„è³‡æ–™\nnp.random.seed(42)\nn_samples = 3000\nn_classes = 10\n\n# æ¥µåº¦ä¸å¹³è¡¡ï¼šé¡åˆ¥ 0 æœ‰ 50% æ¨£æœ¬ï¼Œå…¶ä»–å‡åˆ†\nclass_probs = np.array([0.5] + [0.5 / (n_classes - 1)] * (n_classes - 1))\nX_imb = np.random.randn(n_samples, 20).astype(np.float32)\ny_imb = np.random.choice(n_classes, n_samples, p=class_probs).astype(np.int64)\n\nprint(\"é¡åˆ¥åˆ†å¸ƒ:\")\nfor i, cnt in enumerate(np.bincount(y_imb)):\n    print(f\"  Class {i}: {cnt} ({cnt/n_samples*100:.1f}%)\")\n\n# åˆ†å‰²\nn_tr = int(n_samples * 0.8)\nX_tr, X_vl = X_imb[:n_tr], X_imb[n_tr:]\ny_tr, y_vl = y_imb[:n_tr], y_imb[n_tr:]\n\ndef train_with_method(method_name, train_loader, criterion, epochs=30):\n    \"\"\"ä½¿ç”¨æŒ‡å®šæ–¹æ³•è¨“ç·´\"\"\"\n    model = nn.Sequential(\n        nn.Linear(20, 64), nn.ReLU(), nn.Dropout(0.2),\n        nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.2),\n        nn.Linear(32, n_classes)\n    ).to(device)\n    \n    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n    \n    for _ in range(epochs):\n        model.train()\n        for X_batch, y_batch in train_loader:\n            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n            optimizer.zero_grad()\n            loss = criterion(model(X_batch), y_batch)\n            loss.backward()\n            optimizer.step()\n    \n    # è©•ä¼°\n    model.eval()\n    with torch.no_grad():\n        X_vl_t = torch.FloatTensor(X_vl).to(device)\n        pred = model(X_vl_t).argmax(dim=1).cpu().numpy()\n    \n    # è¨ˆç®—å„é¡åˆ¥çš„æº–ç¢ºç‡\n    acc_per_class = []\n    for c in range(n_classes):\n        mask = y_vl == c\n        if mask.sum() > 0:\n            acc_per_class.append((pred[mask] == c).mean())\n        else:\n            acc_per_class.append(0)\n    \n    return {\n        'overall_acc': (pred == y_vl).mean(),\n        'macro_acc': np.mean(acc_per_class),\n        'per_class': acc_per_class\n    }\n\n# æº–å‚™è³‡æ–™é›†\ntrain_ds = PhonemeDataset(X_tr, y_tr)\nval_ds = PhonemeDataset(X_vl, y_vl)\n\n# æ–¹æ³• 1: åŸºæº–ï¼ˆç„¡è™•ç†ï¼‰\nbaseline_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\nbaseline_result = train_with_method(\"Baseline\", baseline_loader, nn.CrossEntropyLoss())\n\n# æ–¹æ³• 2: Weighted Loss\nclass_weights = compute_class_weights(y_tr, n_classes).to(device)\nweighted_result = train_with_method(\"Weighted Loss\", baseline_loader, \n                                     nn.CrossEntropyLoss(weight=class_weights))\n\n# æ–¹æ³• 3: Focal Loss\nfocal_result = train_with_method(\"Focal Loss\", baseline_loader, FocalLoss(gamma=2.0))\n\n# æ–¹æ³• 4: Weighted Sampler\nsampler = get_weighted_sampler(y_tr)\nsampler_loader = DataLoader(train_ds, batch_size=64, sampler=sampler)\nsampler_result = train_with_method(\"Weighted Sampler\", sampler_loader, nn.CrossEntropyLoss())\n\n# æ¯”è¼ƒçµæœ\nprint(\"\\n=== çµæœæ¯”è¼ƒ ===\")\nprint(f\"{'æ–¹æ³•':<20} {'Overall Acc':<12} {'Macro Acc':<12}\")\nprint(\"-\" * 44)\nfor name, res in [(\"Baseline\", baseline_result), (\"Weighted Loss\", weighted_result),\n                   (\"Focal Loss\", focal_result), (\"Weighted Sampler\", sampler_result)]:\n    print(f\"{name:<20} {res['overall_acc']:.4f}       {res['macro_acc']:.4f}\")\n\n# è¦–è¦ºåŒ–å„é¡åˆ¥æº–ç¢ºç‡\nfig, ax = plt.subplots(figsize=(12, 5))\nx = np.arange(n_classes)\nwidth = 0.2\n\nax.bar(x - 1.5*width, baseline_result['per_class'], width, label='Baseline')\nax.bar(x - 0.5*width, weighted_result['per_class'], width, label='Weighted Loss')\nax.bar(x + 0.5*width, focal_result['per_class'], width, label='Focal Loss')\nax.bar(x + 1.5*width, sampler_result['per_class'], width, label='Weighted Sampler')\n\nax.set_xlabel('Class')\nax.set_ylabel('Accuracy')\nax.set_title('Per-Class Accuracy Comparison')\nax.set_xticks(x)\nax.legend()\nax.grid(True, alpha=0.3, axis='y')\nplt.show()\n\nprint(\"\\nçµè«–: è™•ç†é¡åˆ¥ä¸å¹³è¡¡å¯ä»¥é¡¯è‘—æå‡å°‘æ•¸é¡åˆ¥çš„æº–ç¢ºç‡\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}