{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 10: 性能優化與部署\n",
    "\n",
    "## 學習目標\n",
    "- 掌握 DataLoader 優化技巧\n",
    "- 學會混合精度訓練加速\n",
    "- 理解梯度累積處理大批次\n",
    "- 模型保存、載入與部署\n",
    "\n",
    "## 為什麼需要優化？\n",
    "\n",
    "在實際應用中，訓練效率和部署品質直接影響：\n",
    "- 訓練成本（時間和 GPU 費用）\n",
    "- 產品迭代速度\n",
    "- 線上服務的延遲和吞吐量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, Any\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: DataLoader 優化\n",
    "\n",
    "### 資料載入瓶頸\n",
    "\n",
    "訓練過程中，GPU 可能在等待 CPU 準備資料：\n",
    "\n",
    "```\n",
    "未優化：\n",
    "CPU: [載入資料] ──► [等待] ──► [載入資料] ──► [等待]\n",
    "GPU: [等待] ──► [訓練] ──► [等待] ──► [訓練]\n",
    "\n",
    "優化後：\n",
    "CPU: [載入批次 1] [載入批次 2] [載入批次 3] ...\n",
    "GPU: ──────────► [訓練 1] [訓練 2] [訓練 3] ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 準備資料\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "\n",
    "def benchmark_dataloader(dataset, **kwargs):\n",
    "    \"\"\"\n",
    "    測試 DataLoader 的載入速度\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, **kwargs)\n",
    "    \n",
    "    start = time.time()\n",
    "    n_batches = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        n_batches += 1\n",
    "        if n_batches >= 100:  # 測試 100 個批次\n",
    "            break\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    batches_per_sec = n_batches / elapsed\n",
    "    \n",
    "    return batches_per_sec, elapsed\n",
    "\n",
    "# 測試不同配置\n",
    "configs = [\n",
    "    {'batch_size': 64, 'num_workers': 0, 'pin_memory': False},\n",
    "    {'batch_size': 64, 'num_workers': 2, 'pin_memory': False},\n",
    "    {'batch_size': 64, 'num_workers': 4, 'pin_memory': False},\n",
    "    {'batch_size': 64, 'num_workers': 4, 'pin_memory': True},\n",
    "]\n",
    "\n",
    "print(\"DataLoader 配置比較：\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "for config in configs:\n",
    "    bps, elapsed = benchmark_dataloader(train_dataset, **config)\n",
    "    results.append(bps)\n",
    "    print(f\"workers={config['num_workers']}, pin_memory={config['pin_memory']}\")\n",
    "    print(f\"  速度: {bps:.1f} batches/sec\")\n",
    "    \n",
    "print(f\"\\n最快配置比最慢快 {max(results)/min(results):.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 最佳實踐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_dataloader(\n",
    "    dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    "    num_workers=None,\n",
    "    pin_memory=True,\n",
    "    prefetch_factor=2,\n",
    "    persistent_workers=True\n",
    "):\n",
    "    \"\"\"\n",
    "    建立優化的 DataLoader\n",
    "    \n",
    "    參數說明：\n",
    "    - num_workers: 並行資料載入的進程數\n",
    "      建議設為 CPU 核心數的一半或 4-8\n",
    "      \n",
    "    - pin_memory: 將資料固定在 CPU 記憶體\n",
    "      加速 CPU→GPU 傳輸，建議開啟\n",
    "      \n",
    "    - prefetch_factor: 每個 worker 預取的批次數\n",
    "      增加可以減少等待，但佔用更多記憶體\n",
    "      \n",
    "    - persistent_workers: 保持 workers 存活\n",
    "      避免每個 epoch 重新啟動進程的開銷\n",
    "    \"\"\"\n",
    "    \n",
    "    # 自動決定 num_workers\n",
    "    if num_workers is None:\n",
    "        num_workers = min(4, os.cpu_count() or 1)\n",
    "    \n",
    "    # 如果 num_workers=0，某些參數需要調整\n",
    "    if num_workers == 0:\n",
    "        prefetch_factor = None\n",
    "        persistent_workers = False\n",
    "    \n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory and torch.cuda.is_available(),\n",
    "        prefetch_factor=prefetch_factor,\n",
    "        persistent_workers=persistent_workers and num_workers > 0,\n",
    "        drop_last=True,  # 避免最後一個小批次影響 BatchNorm\n",
    "    )\n",
    "    \n",
    "    return loader\n",
    "\n",
    "# 建立優化的 DataLoader\n",
    "train_loader = create_optimized_dataloader(train_dataset, batch_size=128)\n",
    "print(f\"優化的 DataLoader 已建立\")\n",
    "print(f\"  batch_size: 128\")\n",
    "print(f\"  num_workers: {train_loader.num_workers}\")\n",
    "print(f\"  pin_memory: {train_loader.pin_memory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自訂 Dataset 優化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDataset(Dataset):\n",
    "    \"\"\"\n",
    "    優化的自訂 Dataset\n",
    "    \n",
    "    優化技巧：\n",
    "    1. 預載入小資料集到記憶體\n",
    "    2. 使用記憶體映射處理大檔案\n",
    "    3. 在 __getitem__ 中避免重複計算\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data, labels, transform=None, preload=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: 資料（numpy array 或檔案路徑列表）\n",
    "            labels: 標籤\n",
    "            transform: 資料轉換\n",
    "            preload: 是否預載入到記憶體\n",
    "        \"\"\"\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "        if preload:\n",
    "            # 預載入到記憶體\n",
    "            if isinstance(data, str):\n",
    "                self.data = np.load(data)\n",
    "            else:\n",
    "                self.data = np.array(data)\n",
    "        else:\n",
    "            # 使用記憶體映射（適合大檔案）\n",
    "            self.data = np.load(data, mmap_mode='r')\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 避免在這裡做複雜計算\n",
    "        x = self.data[idx]\n",
    "        y = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        \n",
    "        return x, y\n",
    "\n",
    "print(\"OptimizedDataset 類別已定義\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: 混合精度訓練 (AMP)\n",
    "\n",
    "### 什麼是混合精度？\n",
    "\n",
    "```\n",
    "精度類型：\n",
    "FP32 (32 位)：標準精度，4 bytes/參數\n",
    "FP16 (16 位)：半精度，2 bytes/參數\n",
    "BF16 (16 位)：Brain Float，2 bytes/參數（更好的數值範圍）\n",
    "\n",
    "混合精度策略：\n",
    "- 前向傳播：使用 FP16/BF16（速度快）\n",
    "- 權重更新：使用 FP32（精度高）\n",
    "- 損失縮放：防止梯度下溢\n",
    "\n",
    "好處：\n",
    "- 訓練速度提升 2-3x\n",
    "- 記憶體使用減半\n",
    "- 可以訓練更大的模型/批次\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "class AMPTrainer:\n",
    "    \"\"\"\n",
    "    自動混合精度訓練器\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, optimizer, criterion, use_amp=True, amp_dtype=torch.float16):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.use_amp = use_amp and torch.cuda.is_available()\n",
    "        self.amp_dtype = amp_dtype\n",
    "        \n",
    "        # 梯度縮放器（防止 FP16 梯度下溢）\n",
    "        self.scaler = GradScaler() if self.use_amp else None\n",
    "        \n",
    "    def train_step(self, x, y):\n",
    "        \"\"\"\n",
    "        單步訓練\n",
    "        \"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        if self.use_amp:\n",
    "            # 混合精度前向傳播\n",
    "            with autocast(dtype=self.amp_dtype):\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "            \n",
    "            # 縮放損失並反向傳播\n",
    "            self.scaler.scale(loss).backward()\n",
    "            \n",
    "            # 更新權重（自動處理縮放）\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            # 標準訓練\n",
    "            output = self.model(x)\n",
    "            loss = self.criterion(output, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "# 比較 AMP 和標準訓練\n",
    "def compare_training_speed():\n",
    "    \"\"\"\n",
    "    比較有無 AMP 的訓練速度\n",
    "    \"\"\"\n",
    "    # 建立一個較大的模型\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, 3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 128, 3, padding=1),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(),\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(128, 10)\n",
    "    ).to(device)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for use_amp in [False, True]:\n",
    "        # 重置模型\n",
    "        model_copy = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 10)\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model_copy.parameters(), lr=1e-3)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        trainer = AMPTrainer(model_copy, optimizer, criterion, use_amp=use_amp)\n",
    "        \n",
    "        # 預熱\n",
    "        x = torch.randn(64, 1, 28, 28).to(device)\n",
    "        y = torch.randint(0, 10, (64,)).to(device)\n",
    "        for _ in range(10):\n",
    "            trainer.train_step(x, y)\n",
    "        \n",
    "        # 計時\n",
    "        torch.cuda.synchronize()\n",
    "        start = time.time()\n",
    "        \n",
    "        for _ in range(100):\n",
    "            trainer.train_step(x, y)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        mode = \"AMP\" if use_amp else \"FP32\"\n",
    "        results[mode] = elapsed\n",
    "        print(f\"{mode}: {elapsed:.3f}s for 100 steps\")\n",
    "    \n",
    "    speedup = results['FP32'] / results['AMP']\n",
    "    print(f\"\\nAMP 加速: {speedup:.2f}x\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    compare_training_speed()\n",
    "else:\n",
    "    print(\"需要 CUDA 來比較 AMP 性能\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: 梯度累積\n",
    "\n",
    "當 VRAM 不足以容納大批次時，使用梯度累積模擬。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientAccumulationTrainer:\n",
    "    \"\"\"\n",
    "    支援梯度累積的訓練器\n",
    "    \n",
    "    有效批次大小 = micro_batch_size × accumulation_steps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        optimizer, \n",
    "        criterion,\n",
    "        accumulation_steps=4,\n",
    "        use_amp=True,\n",
    "        max_grad_norm=1.0  # 梯度裁剪\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.accumulation_steps = accumulation_steps\n",
    "        self.use_amp = use_amp and torch.cuda.is_available()\n",
    "        self.max_grad_norm = max_grad_norm\n",
    "        \n",
    "        self.scaler = GradScaler() if self.use_amp else None\n",
    "        self.current_step = 0\n",
    "        \n",
    "    def train_step(self, x, y):\n",
    "        \"\"\"\n",
    "        單步訓練（可能不會立即更新權重）\n",
    "        \"\"\"\n",
    "        # 計算損失\n",
    "        if self.use_amp:\n",
    "            with autocast(dtype=torch.float16):\n",
    "                output = self.model(x)\n",
    "                # 重要：除以累積步數！\n",
    "                loss = self.criterion(output, y) / self.accumulation_steps\n",
    "            self.scaler.scale(loss).backward()\n",
    "        else:\n",
    "            output = self.model(x)\n",
    "            loss = self.criterion(output, y) / self.accumulation_steps\n",
    "            loss.backward()\n",
    "        \n",
    "        self.current_step += 1\n",
    "        \n",
    "        # 每 accumulation_steps 步更新一次\n",
    "        if self.current_step % self.accumulation_steps == 0:\n",
    "            if self.use_amp:\n",
    "                # 解除縮放梯度\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                \n",
    "                # 梯度裁剪\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "                \n",
    "                # 更新\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.max_grad_norm)\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            return True, loss.item() * self.accumulation_steps\n",
    "        \n",
    "        return False, loss.item() * self.accumulation_steps\n",
    "\n",
    "# 示範\n",
    "print(\"梯度累積示範：\")\n",
    "print(\"假設 GPU 只能處理 batch_size=8，但想要有效 batch_size=32\")\n",
    "print(\"設定 accumulation_steps=4\")\n",
    "print(\"\\n每 4 個微批次後更新一次權重\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: 模型保存與載入\n",
    "\n",
    "### 保存選項"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSaver:\n",
    "    \"\"\"\n",
    "    模型保存工具\n",
    "    \n",
    "    支援：\n",
    "    - 保存權重\n",
    "    - 保存完整模型\n",
    "    - 保存訓練檢查點（包含優化器狀態）\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_weights(model, path):\n",
    "        \"\"\"\n",
    "        只保存權重（推薦，檔案小）\n",
    "        \"\"\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"權重已保存至: {path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_weights(model, path, strict=True):\n",
    "        \"\"\"\n",
    "        載入權重\n",
    "        \n",
    "        Args:\n",
    "            strict: 是否要求所有鍵都匹配\n",
    "        \"\"\"\n",
    "        model.load_state_dict(torch.load(path), strict=strict)\n",
    "        print(f\"權重已從 {path} 載入\")\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_checkpoint(\n",
    "        model, \n",
    "        optimizer, \n",
    "        epoch, \n",
    "        loss, \n",
    "        path,\n",
    "        scheduler=None,\n",
    "        extra_info=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        保存完整訓練檢查點（用於恢復訓練）\n",
    "        \"\"\"\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            checkpoint['scheduler_state_dict'] = scheduler.state_dict()\n",
    "        \n",
    "        if extra_info is not None:\n",
    "            checkpoint['extra_info'] = extra_info\n",
    "        \n",
    "        torch.save(checkpoint, path)\n",
    "        print(f\"檢查點已保存至: {path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_checkpoint(path, model, optimizer=None, scheduler=None):\n",
    "        \"\"\"\n",
    "        載入訓練檢查點\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(path)\n",
    "        \n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        if optimizer is not None and 'optimizer_state_dict' in checkpoint:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        if scheduler is not None and 'scheduler_state_dict' in checkpoint:\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        \n",
    "        print(f\"檢查點已從 {path} 載入\")\n",
    "        print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "        print(f\"  Loss: {checkpoint['loss']:.4f}\")\n",
    "        \n",
    "        return checkpoint\n",
    "\n",
    "# 示範\n",
    "demo_model = nn.Linear(10, 2)\n",
    "demo_optimizer = torch.optim.Adam(demo_model.parameters())\n",
    "\n",
    "# 保存\n",
    "ModelSaver.save_weights(demo_model, './demo_weights.pt')\n",
    "ModelSaver.save_checkpoint(demo_model, demo_optimizer, epoch=10, loss=0.5, path='./demo_checkpoint.pt')\n",
    "\n",
    "# 清理\n",
    "import os\n",
    "os.remove('./demo_weights.pt')\n",
    "os.remove('./demo_checkpoint.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型導出（用於部署）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelExporter:\n",
    "    \"\"\"\n",
    "    模型導出工具\n",
    "    \n",
    "    支援格式：\n",
    "    - TorchScript (推薦，PyTorch 原生)\n",
    "    - ONNX (跨平台)\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_torchscript(model, example_input, path, method='trace'):\n",
    "        \"\"\"\n",
    "        導出為 TorchScript\n",
    "        \n",
    "        Args:\n",
    "            method: 'trace' 或 'script'\n",
    "            - trace: 追蹤一次前向傳播，適合固定結構\n",
    "            - script: 編譯程式碼，支援控制流\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        if method == 'trace':\n",
    "            scripted = torch.jit.trace(model, example_input)\n",
    "        else:\n",
    "            scripted = torch.jit.script(model)\n",
    "        \n",
    "        scripted.save(path)\n",
    "        print(f\"TorchScript 模型已保存至: {path}\")\n",
    "        \n",
    "        return scripted\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_onnx(\n",
    "        model, \n",
    "        example_input, \n",
    "        path,\n",
    "        input_names=['input'],\n",
    "        output_names=['output'],\n",
    "        dynamic_axes=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        導出為 ONNX 格式\n",
    "        \n",
    "        ONNX 可以在多種推理引擎上運行：\n",
    "        - ONNX Runtime\n",
    "        - TensorRT\n",
    "        - OpenVINO\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        if dynamic_axes is None:\n",
    "            # 預設：batch size 動態\n",
    "            dynamic_axes = {\n",
    "                'input': {0: 'batch_size'},\n",
    "                'output': {0: 'batch_size'}\n",
    "            }\n",
    "        \n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            example_input,\n",
    "            path,\n",
    "            input_names=input_names,\n",
    "            output_names=output_names,\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            opset_version=14,\n",
    "        )\n",
    "        \n",
    "        print(f\"ONNX 模型已保存至: {path}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_torchscript(path):\n",
    "        \"\"\"\n",
    "        載入 TorchScript 模型\n",
    "        \"\"\"\n",
    "        model = torch.jit.load(path)\n",
    "        print(f\"TorchScript 模型已從 {path} 載入\")\n",
    "        return model\n",
    "\n",
    "# 示範 TorchScript 導出\n",
    "demo_model = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "example_input = torch.randn(1, 784)\n",
    "scripted = ModelExporter.to_torchscript(demo_model, example_input, './demo_model.pt')\n",
    "\n",
    "# 驗證輸出一致\n",
    "with torch.no_grad():\n",
    "    original_out = demo_model(example_input)\n",
    "    scripted_out = scripted(example_input)\n",
    "    diff = (original_out - scripted_out).abs().max().item()\n",
    "    print(f\"原始 vs TorchScript 輸出差異: {diff:.10f}\")\n",
    "\n",
    "# 清理\n",
    "os.remove('./demo_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: 推理優化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceOptimizer:\n",
    "    \"\"\"\n",
    "    推理優化工具\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def optimize_model_for_inference(model):\n",
    "        \"\"\"\n",
    "        為推理優化模型\n",
    "        \"\"\"\n",
    "        model.eval()  # 評估模式\n",
    "        \n",
    "        # 凍結 BatchNorm（如果有）\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.BatchNorm2d) or isinstance(module, nn.BatchNorm1d):\n",
    "                module.eval()\n",
    "                module.track_running_stats = False\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def fuse_conv_bn(model):\n",
    "        \"\"\"\n",
    "        融合 Conv + BatchNorm 層（加速推理）\n",
    "        \n",
    "        數學原理：\n",
    "        BN(Conv(x)) = gamma * (Conv(x) - mean) / sqrt(var + eps) + beta\n",
    "        可以合併為一個等效的 Conv\n",
    "        \"\"\"\n",
    "        # PyTorch 提供的融合工具\n",
    "        try:\n",
    "            from torch.quantization import fuse_modules\n",
    "            # 需要知道具體的模組名稱來融合\n",
    "            print(\"使用 torch.quantization.fuse_modules 進行融合\")\n",
    "        except ImportError:\n",
    "            print(\"融合功能需要 PyTorch >= 1.3\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def benchmark_inference(model, input_shape, n_warmup=10, n_runs=100):\n",
    "        \"\"\"\n",
    "        測試推理速度\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        x = torch.randn(*input_shape).to(device)\n",
    "        \n",
    "        # 預熱\n",
    "        for _ in range(n_warmup):\n",
    "            _ = model(x)\n",
    "        \n",
    "        # 同步（確保 GPU 完成）\n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        # 計時\n",
    "        start = time.time()\n",
    "        for _ in range(n_runs):\n",
    "            _ = model(x)\n",
    "        \n",
    "        if device.type == 'cuda':\n",
    "            torch.cuda.synchronize()\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        avg_time = elapsed / n_runs * 1000  # ms\n",
    "        throughput = n_runs * input_shape[0] / elapsed  # samples/sec\n",
    "        \n",
    "        print(f\"推理性能:\")\n",
    "        print(f\"  平均延遲: {avg_time:.2f} ms\")\n",
    "        print(f\"  吞吐量: {throughput:.0f} samples/sec\")\n",
    "        \n",
    "        return {'latency_ms': avg_time, 'throughput': throughput}\n",
    "\n",
    "# 測試\n",
    "test_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64, 10)\n",
    ").to(device)\n",
    "\n",
    "InferenceOptimizer.benchmark_inference(test_model, (32, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: 簡單 API 部署\n",
    "\n",
    "使用 FastAPI 建立簡單的模型推理服務。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI 推理服務範例\n",
    "\n",
    "fastapi_server_code = '''\n",
    "# app.py - FastAPI 推理服務\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile\n",
    "from pydantic import BaseModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "app = FastAPI(title=\"MNIST 分類服務\")\n",
    "\n",
    "# 載入模型（啟動時載入一次）\n",
    "model = torch.jit.load(\"model.pt\")\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "class PredictionResponse(BaseModel):\n",
    "    predicted_class: int\n",
    "    confidence: float\n",
    "    probabilities: List[float]\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {\"message\": \"MNIST 分類 API\"}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health_check():\n",
    "    return {\"status\": \"healthy\", \"device\": str(device)}\n",
    "\n",
    "@app.post(\"/predict\", response_model=PredictionResponse)\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    接收圖像並返回預測結果\n",
    "    \"\"\"\n",
    "    # 讀取並預處理圖像\n",
    "    contents = await file.read()\n",
    "    image = Image.open(io.BytesIO(contents)).convert(\"L\")  # 轉灰階\n",
    "    image = image.resize((28, 28))\n",
    "    \n",
    "    # 轉為張量\n",
    "    img_array = np.array(image, dtype=np.float32) / 255.0\n",
    "    img_tensor = torch.from_numpy(img_array).unsqueeze(0).unsqueeze(0)  # [1, 1, 28, 28]\n",
    "    img_tensor = (img_tensor - 0.5) / 0.5  # 歸一化\n",
    "    img_tensor = img_tensor.to(device)\n",
    "    \n",
    "    # 推理\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        confidence, predicted = probs.max(dim=1)\n",
    "    \n",
    "    return PredictionResponse(\n",
    "        predicted_class=predicted.item(),\n",
    "        confidence=confidence.item(),\n",
    "        probabilities=probs[0].tolist()\n",
    "    )\n",
    "\n",
    "# 批次預測\n",
    "@app.post(\"/predict_batch\")\n",
    "async def predict_batch(files: List[UploadFile] = File(...)):\n",
    "    \"\"\"\n",
    "    批次預測（更高效）\n",
    "    \"\"\"\n",
    "    tensors = []\n",
    "    \n",
    "    for file in files:\n",
    "        contents = await file.read()\n",
    "        image = Image.open(io.BytesIO(contents)).convert(\"L\")\n",
    "        image = image.resize((28, 28))\n",
    "        img_array = np.array(image, dtype=np.float32) / 255.0\n",
    "        img_tensor = torch.from_numpy(img_array)\n",
    "        tensors.append(img_tensor)\n",
    "    \n",
    "    # 批次處理\n",
    "    batch = torch.stack(tensors).unsqueeze(1)  # [B, 1, 28, 28]\n",
    "    batch = (batch - 0.5) / 0.5\n",
    "    batch = batch.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(batch)\n",
    "        probs = F.softmax(outputs, dim=1)\n",
    "        confidences, predictions = probs.max(dim=1)\n",
    "    \n",
    "    return {\n",
    "        \"predictions\": predictions.tolist(),\n",
    "        \"confidences\": confidences.tolist()\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "'''\n",
    "\n",
    "print(\"FastAPI 推理服務範例：\")\n",
    "print(\"=\"*60)\n",
    "print(fastapi_server_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker 部署配置\n",
    "\n",
    "dockerfile_content = '''\n",
    "# Dockerfile\n",
    "FROM python:3.10-slim\n",
    "\n",
    "WORKDIR /app\n",
    "\n",
    "# 安裝依賴\n",
    "COPY requirements.txt .\n",
    "RUN pip install --no-cache-dir -r requirements.txt\n",
    "\n",
    "# 複製模型和程式碼\n",
    "COPY model.pt .\n",
    "COPY app.py .\n",
    "\n",
    "# 暴露端口\n",
    "EXPOSE 8000\n",
    "\n",
    "# 啟動服務\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n",
    "'''\n",
    "\n",
    "requirements_content = '''\n",
    "# requirements.txt\n",
    "torch>=2.0.0\n",
    "fastapi>=0.100.0\n",
    "uvicorn>=0.23.0\n",
    "python-multipart>=0.0.6\n",
    "pillow>=10.0.0\n",
    "numpy>=1.24.0\n",
    "'''\n",
    "\n",
    "print(\"Dockerfile:\")\n",
    "print(dockerfile_content)\n",
    "print(\"\\nrequirements.txt:\")\n",
    "print(requirements_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 練習題\n",
    "\n",
    "### 練習 1: 完整訓練管線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1: 整合所有優化的訓練管線\n",
    "\n",
    "class OptimizedTrainingPipeline:\n",
    "    \"\"\"\n",
    "    整合所有優化技術的訓練管線\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        train_dataset,\n",
    "        val_dataset=None,\n",
    "        batch_size=64,\n",
    "        accumulation_steps=1,\n",
    "        use_amp=True,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        checkpoint_dir='./checkpoints',\n",
    "        save_every=5,\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.batch_size = batch_size\n",
    "        self.accumulation_steps = accumulation_steps\n",
    "        self.use_amp = use_amp and torch.cuda.is_available()\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.save_every = save_every\n",
    "        \n",
    "        # 建立優化的 DataLoader\n",
    "        self.train_loader = create_optimized_dataloader(\n",
    "            train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        \n",
    "        if val_dataset is not None:\n",
    "            self.val_loader = create_optimized_dataloader(\n",
    "                val_dataset, batch_size=batch_size * 2, shuffle=False\n",
    "            )\n",
    "        else:\n",
    "            self.val_loader = None\n",
    "        \n",
    "        # 優化器和調度器\n",
    "        self.optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=lr, weight_decay=weight_decay\n",
    "        )\n",
    "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer, T_max=100\n",
    "        )\n",
    "        \n",
    "        # 損失函數\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # AMP\n",
    "        self.scaler = GradScaler() if self.use_amp else None\n",
    "        \n",
    "        # 歷史記錄\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        \n",
    "        # 建立檢查點目錄\n",
    "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "        \n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            if self.use_amp:\n",
    "                with autocast(dtype=torch.float16):\n",
    "                    output = self.model(data)\n",
    "                    loss = self.criterion(output, target) / self.accumulation_steps\n",
    "                self.scaler.scale(loss).backward()\n",
    "            else:\n",
    "                output = self.model(data)\n",
    "                loss = self.criterion(output, target) / self.accumulation_steps\n",
    "                loss.backward()\n",
    "            \n",
    "            if (batch_idx + 1) % self.accumulation_steps == 0:\n",
    "                if self.use_amp:\n",
    "                    self.scaler.step(self.optimizer)\n",
    "                    self.scaler.update()\n",
    "                else:\n",
    "                    self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            \n",
    "            total_loss += loss.item() * self.accumulation_steps\n",
    "            n_batches += 1\n",
    "        \n",
    "        return total_loss / n_batches\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def validate(self):\n",
    "        if self.val_loader is None:\n",
    "            return None, None\n",
    "        \n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for data, target in self.val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "        \n",
    "        return total_loss / len(self.val_loader), correct / total\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        best_val_acc = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "            \n",
    "            # 訓練\n",
    "            train_loss = self.train_epoch()\n",
    "            \n",
    "            # 驗證\n",
    "            val_loss, val_acc = self.validate()\n",
    "            \n",
    "            # 更新學習率\n",
    "            self.scheduler.step()\n",
    "            current_lr = self.scheduler.get_last_lr()[0]\n",
    "            \n",
    "            # 記錄歷史\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['lr'].append(current_lr)\n",
    "            if val_loss is not None:\n",
    "                self.history['val_loss'].append(val_loss)\n",
    "                self.history['val_acc'].append(val_acc)\n",
    "            \n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            # 列印進度\n",
    "            print(f\"Epoch {epoch+1}/{epochs} ({elapsed:.1f}s)\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}\")\n",
    "            if val_loss is not None:\n",
    "                print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "            print(f\"  LR: {current_lr:.6f}\")\n",
    "            \n",
    "            # 保存檢查點\n",
    "            if (epoch + 1) % self.save_every == 0:\n",
    "                path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
    "                ModelSaver.save_checkpoint(\n",
    "                    self.model, self.optimizer, epoch+1, train_loss, path,\n",
    "                    scheduler=self.scheduler\n",
    "                )\n",
    "            \n",
    "            # 保存最佳模型\n",
    "            if val_acc is not None and val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                path = os.path.join(self.checkpoint_dir, 'best_model.pt')\n",
    "                ModelSaver.save_weights(self.model, path)\n",
    "                print(f\"  新最佳模型! Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        return self.history\n",
    "\n",
    "# 使用範例\n",
    "print(\"OptimizedTrainingPipeline 類別已定義\")\n",
    "print(\"\\n使用範例：\")\n",
    "print('''\n",
    "model = YourModel()\n",
    "pipeline = OptimizedTrainingPipeline(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    accumulation_steps=4,  # 有效 batch = 256\n",
    "    use_amp=True,\n",
    "    lr=1e-3,\n",
    ")\n",
    "history = pipeline.train(epochs=50)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 2: 模型效能分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 2: 模型效能分析工具\n",
    "\n",
    "class ModelProfiler:\n",
    "    \"\"\"\n",
    "    模型效能分析工具\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def count_parameters(model):\n",
    "        \"\"\"\n",
    "        計算模型參數量\n",
    "        \"\"\"\n",
    "        total = sum(p.numel() for p in model.parameters())\n",
    "        trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"參數統計：\")\n",
    "        print(f\"  總參數量: {total:,}\")\n",
    "        print(f\"  可訓練參數: {trainable:,}\")\n",
    "        print(f\"  凍結參數: {total - trainable:,}\")\n",
    "        print(f\"  模型大小: ~{total * 4 / 1024**2:.1f} MB (FP32)\")\n",
    "        \n",
    "        return total, trainable\n",
    "    \n",
    "    @staticmethod\n",
    "    def estimate_memory(model, input_shape, batch_size=1):\n",
    "        \"\"\"\n",
    "        估算模型記憶體使用\n",
    "        \"\"\"\n",
    "        # 參數記憶體\n",
    "        param_mem = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "        \n",
    "        # 估算激活值記憶體（粗略）\n",
    "        # 需要實際運行來獲得準確值\n",
    "        \n",
    "        print(f\"記憶體估算（batch_size={batch_size}）：\")\n",
    "        print(f\"  參數: {param_mem / 1024**2:.1f} MB\")\n",
    "        \n",
    "        return param_mem\n",
    "    \n",
    "    @staticmethod\n",
    "    def layer_summary(model, input_shape):\n",
    "        \"\"\"\n",
    "        打印每層的輸出形狀和參數量\n",
    "        \"\"\"\n",
    "        def hook_fn(module, input, output):\n",
    "            if hasattr(output, 'shape'):\n",
    "                summary.append({\n",
    "                    'name': module.__class__.__name__,\n",
    "                    'output_shape': list(output.shape),\n",
    "                    'params': sum(p.numel() for p in module.parameters())\n",
    "                })\n",
    "        \n",
    "        summary = []\n",
    "        hooks = []\n",
    "        \n",
    "        for module in model.modules():\n",
    "            if len(list(module.children())) == 0:  # 只對葉子節點\n",
    "                hooks.append(module.register_forward_hook(hook_fn))\n",
    "        \n",
    "        # 運行一次前向傳播\n",
    "        x = torch.randn(*input_shape).to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            model(x)\n",
    "        \n",
    "        # 移除 hooks\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        # 打印摘要\n",
    "        print(f\"{'Layer':<30} {'Output Shape':<20} {'Params':>10}\")\n",
    "        print(\"=\"*62)\n",
    "        \n",
    "        total_params = 0\n",
    "        for layer in summary:\n",
    "            print(f\"{layer['name']:<30} {str(layer['output_shape']):<20} {layer['params']:>10,}\")\n",
    "            total_params += layer['params']\n",
    "        \n",
    "        print(\"=\"*62)\n",
    "        print(f\"{'Total':<30} {'':<20} {total_params:>10,}\")\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# 測試\n",
    "test_model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(64 * 7 * 7, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "ModelProfiler.count_parameters(test_model)\n",
    "print()\n",
    "ModelProfiler.layer_summary(test_model, (1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 練習 3: 學習率尋找器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 3: 學習率尋找器\n",
    "\n",
    "class LRFinder:\n",
    "    \"\"\"\n",
    "    學習率尋找器\n",
    "    \n",
    "    通過逐漸增加學習率來找到最佳學習率範圍\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        \n",
    "        # 保存初始狀態\n",
    "        self.model_state = model.state_dict()\n",
    "        self.optimizer_state = optimizer.state_dict()\n",
    "        \n",
    "    def find(\n",
    "        self, \n",
    "        train_loader, \n",
    "        start_lr=1e-7, \n",
    "        end_lr=10, \n",
    "        num_iter=100,\n",
    "        smooth_factor=0.05\n",
    "    ):\n",
    "        \"\"\"\n",
    "        執行學習率搜索\n",
    "        \"\"\"\n",
    "        # 計算每步的學習率乘數\n",
    "        lr_mult = (end_lr / start_lr) ** (1 / num_iter)\n",
    "        lr = start_lr\n",
    "        \n",
    "        # 設置初始學習率\n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        # 記錄\n",
    "        lrs = []\n",
    "        losses = []\n",
    "        avg_loss = 0\n",
    "        best_loss = float('inf')\n",
    "        \n",
    "        self.model.train()\n",
    "        iterator = iter(train_loader)\n",
    "        \n",
    "        for i in range(num_iter):\n",
    "            try:\n",
    "                data, target = next(iterator)\n",
    "            except StopIteration:\n",
    "                iterator = iter(train_loader)\n",
    "                data, target = next(iterator)\n",
    "            \n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            # 前向傳播\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            # 平滑損失\n",
    "            avg_loss = smooth_factor * loss.item() + (1 - smooth_factor) * avg_loss\n",
    "            smoothed_loss = avg_loss / (1 - smooth_factor ** (i + 1))\n",
    "            \n",
    "            # 記錄\n",
    "            lrs.append(lr)\n",
    "            losses.append(smoothed_loss)\n",
    "            \n",
    "            # 如果損失爆炸，停止\n",
    "            if smoothed_loss > 4 * best_loss:\n",
    "                print(f\"損失爆炸，停止於 lr={lr:.2e}\")\n",
    "                break\n",
    "            \n",
    "            if smoothed_loss < best_loss:\n",
    "                best_loss = smoothed_loss\n",
    "            \n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # 更新學習率\n",
    "            lr *= lr_mult\n",
    "            for param_group in self.optimizer.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "        \n",
    "        # 恢復初始狀態\n",
    "        self.model.load_state_dict(self.model_state)\n",
    "        self.optimizer.load_state_dict(self.optimizer_state)\n",
    "        \n",
    "        return lrs, losses\n",
    "    \n",
    "    def plot(self, lrs, losses, suggest=True):\n",
    "        \"\"\"\n",
    "        繪製學習率 vs 損失曲線\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(lrs, losses)\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Finder')\n",
    "        \n",
    "        if suggest:\n",
    "            # 找到損失下降最快的點\n",
    "            gradients = np.gradient(losses)\n",
    "            min_grad_idx = np.argmin(gradients)\n",
    "            suggested_lr = lrs[min_grad_idx]\n",
    "            \n",
    "            plt.axvline(suggested_lr, color='r', linestyle='--', \n",
    "                       label=f'建議 LR: {suggested_lr:.2e}')\n",
    "            plt.legend()\n",
    "            \n",
    "            print(f\"建議學習率: {suggested_lr:.2e}\")\n",
    "        \n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# 使用範例\n",
    "print(\"LRFinder 使用範例：\")\n",
    "print('''\n",
    "model = YourModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device)\n",
    "lrs, losses = lr_finder.find(train_loader)\n",
    "lr_finder.plot(lrs, losses)\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Part 7: 進階優化技巧\n\n### 7.1 PyTorch 2.0 torch.compile()\n\nPyTorch 2.0 引入了 `torch.compile()`，可以自動優化模型的執行圖。",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========== PyTorch 2.0 torch.compile() ==========\n\ndef demonstrate_torch_compile():\n    \"\"\"\n    展示 torch.compile() 的使用和性能提升\n    \"\"\"\n    # 建立測試模型\n    class TestModel(nn.Module):\n        def __init__(self):\n            super().__init__()\n            self.conv1 = nn.Conv2d(3, 64, 3, padding=1)\n            self.bn1 = nn.BatchNorm2d(64)\n            self.conv2 = nn.Conv2d(64, 128, 3, padding=1)\n            self.bn2 = nn.BatchNorm2d(128)\n            self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n            self.bn3 = nn.BatchNorm2d(256)\n            self.pool = nn.AdaptiveAvgPool2d(1)\n            self.fc = nn.Linear(256, 10)\n        \n        def forward(self, x):\n            x = F.relu(self.bn1(self.conv1(x)))\n            x = F.relu(self.bn2(self.conv2(x)))\n            x = F.relu(self.bn3(self.conv3(x)))\n            x = self.pool(x).flatten(1)\n            return self.fc(x)\n    \n    model = TestModel().to(device)\n    x = torch.randn(32, 3, 64, 64).to(device)\n    \n    # 原始模型測試\n    model.eval()\n    \n    # 預熱\n    for _ in range(10):\n        _ = model(x)\n    \n    torch.cuda.synchronize() if torch.cuda.is_available() else None\n    start = time.time()\n    for _ in range(100):\n        _ = model(x)\n    torch.cuda.synchronize() if torch.cuda.is_available() else None\n    eager_time = time.time() - start\n    \n    # 編譯模型\n    try:\n        compiled_model = torch.compile(model, mode=\"reduce-overhead\")\n        \n        # 預熱（編譯發生在第一次前向傳播）\n        for _ in range(10):\n            _ = compiled_model(x)\n        \n        torch.cuda.synchronize() if torch.cuda.is_available() else None\n        start = time.time()\n        for _ in range(100):\n            _ = compiled_model(x)\n        torch.cuda.synchronize() if torch.cuda.is_available() else None\n        compiled_time = time.time() - start\n        \n        print(\"torch.compile() 性能比較：\")\n        print(f\"  原始模型: {eager_time*10:.2f} ms/100 batches\")\n        print(f\"  編譯模型: {compiled_time*10:.2f} ms/100 batches\")\n        print(f\"  加速比: {eager_time/compiled_time:.2f}x\")\n        \n    except Exception as e:\n        print(f\"torch.compile() 需要 PyTorch 2.0+\")\n        print(f\"當前版本: {torch.__version__}\")\n\n# 執行測試\nprint(\"PyTorch 版本:\", torch.__version__)\ndemonstrate_torch_compile()\n\nprint(\"\"\"\n💡 torch.compile() 模式說明：\n- 'default': 平衡編譯時間和加速\n- 'reduce-overhead': 最大化運行時加速（推薦 GPU）\n- 'max-autotune': 最大優化（編譯時間長）\n\"\"\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 7.2 模型量化 (Quantization)\n\n量化可以將模型從 FP32 壓縮到 INT8，減少模型大小和推理時間。\n\n```\n量化類型：\n1. 動態量化 (Dynamic Quantization)\n   - 權重量化為 INT8\n   - 激活在運行時量化\n   - 簡單易用，適合 CPU 部署\n\n2. 靜態量化 (Static Quantization)\n   - 權重和激活都量化\n   - 需要校準數據\n   - 更高的壓縮率\n\n3. 量化感知訓練 (QAT)\n   - 在訓練時模擬量化\n   - 精度損失最小\n   - 需要重新訓練\n```",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========== 模型量化 ==========\n\nclass ModelQuantizer:\n    \"\"\"\n    模型量化工具\n    \"\"\"\n    \n    @staticmethod\n    def dynamic_quantize(model):\n        \"\"\"\n        動態量化（最簡單）\n        適用於 Linear, LSTM, GRU 等層\n        \"\"\"\n        quantized_model = torch.quantization.quantize_dynamic(\n            model,\n            {nn.Linear, nn.LSTM, nn.GRU},  # 要量化的層類型\n            dtype=torch.qint8\n        )\n        return quantized_model\n    \n    @staticmethod\n    def compare_model_size(original_model, quantized_model):\n        \"\"\"\n        比較模型大小\n        \"\"\"\n        import tempfile\n        \n        # 保存原始模型\n        with tempfile.NamedTemporaryFile() as f:\n            torch.save(original_model.state_dict(), f.name)\n            original_size = os.path.getsize(f.name) / 1024 / 1024\n        \n        # 保存量化模型\n        with tempfile.NamedTemporaryFile() as f:\n            torch.save(quantized_model.state_dict(), f.name)\n            quantized_size = os.path.getsize(f.name) / 1024 / 1024\n        \n        print(f\"模型大小比較：\")\n        print(f\"  原始模型: {original_size:.2f} MB\")\n        print(f\"  量化模型: {quantized_size:.2f} MB\")\n        print(f\"  壓縮比: {original_size/quantized_size:.2f}x\")\n        \n        return original_size, quantized_size\n    \n    @staticmethod\n    def benchmark_quantized(original_model, quantized_model, input_shape, n_runs=100):\n        \"\"\"\n        比較原始和量化模型的推理速度\n        \"\"\"\n        x = torch.randn(*input_shape)\n        \n        # 原始模型（CPU）\n        original_model = original_model.cpu().eval()\n        for _ in range(10):\n            _ = original_model(x)\n        \n        start = time.time()\n        for _ in range(n_runs):\n            _ = original_model(x)\n        original_time = time.time() - start\n        \n        # 量化模型\n        for _ in range(10):\n            _ = quantized_model(x)\n        \n        start = time.time()\n        for _ in range(n_runs):\n            _ = quantized_model(x)\n        quantized_time = time.time() - start\n        \n        print(f\"推理速度比較 ({n_runs} 次)：\")\n        print(f\"  原始模型: {original_time*1000:.1f} ms\")\n        print(f\"  量化模型: {quantized_time*1000:.1f} ms\")\n        print(f\"  加速比: {original_time/quantized_time:.2f}x\")\n        \n        return original_time, quantized_time\n\n\n# 示範動態量化\nclass SimpleMLP(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(784, 512)\n        self.fc2 = nn.Linear(512, 256)\n        self.fc3 = nn.Linear(256, 10)\n    \n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        return self.fc3(x)\n\n# 建立和量化模型\noriginal_mlp = SimpleMLP()\nquantized_mlp = ModelQuantizer.dynamic_quantize(original_mlp)\n\nprint(\"動態量化示範：\")\nModelQuantizer.compare_model_size(original_mlp, quantized_mlp)\nprint()\nModelQuantizer.benchmark_quantized(original_mlp, quantized_mlp, (32, 784))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### 7.3 記憶體優化技巧\n\n當訓練大模型時，VRAM 往往是瓶頸。以下是一些記憶體優化技巧。",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "---\n## 🎯 總結：性能優化與部署完整知識框架\n\n### 📊 本模組重點回顧\n\n| 主題 | 核心技術 | 效果/使用場景 |\n|------|----------|---------------|\n| **DataLoader** | num_workers, pin_memory | 加速資料載入 2-5x |\n| **AMP** | autocast, GradScaler | 加速訓練 2-3x, 減少 VRAM |\n| **梯度累積** | 分步累積梯度 | 模擬大批次訓練 |\n| **torch.compile** | 圖優化編譯 | 加速推理 10-50% |\n| **量化** | INT8 量化 | 模型大小減少 4x |\n| **檢查點** | 梯度檢查點 | VRAM 減少 50-80% |\n| **TorchScript** | JIT 編譯 | 部署和加速 |\n| **ONNX** | 跨平台格式 | 多引擎部署 |\n\n### 🚀 性能優化決策流程\n\n```\n開始\n  │\n  ▼\n┌─────────────────────┐\n│ 1. 確認瓶頸是什麼？ │\n└─────────────────────┘\n  │\n  ├─► 資料載入慢？\n  │     └─► DataLoader 優化 (num_workers, pin_memory)\n  │\n  ├─► GPU 利用率低？\n  │     └─► 增加 batch_size 或使用 torch.compile()\n  │\n  ├─► VRAM 不足？\n  │     ├─► 混合精度訓練 (AMP)\n  │     ├─► 梯度累積\n  │     ├─► 梯度檢查點\n  │     └─► 減少 batch_size\n  │\n  ├─► 訓練太慢？\n  │     ├─► 混合精度訓練\n  │     ├─► torch.compile()\n  │     └─► 分散式訓練 (DDP)\n  │\n  └─► 推理太慢？\n        ├─► TorchScript 導出\n        ├─► 模型量化\n        ├─► 批次推理\n        └─► TensorRT 加速\n```\n\n### 🛠️ 優化技術速查表\n\n```\n┌─────────────────────────────────────────────────────────────┐\n│                    訓練優化                                 │\n├─────────────────────────────────────────────────────────────┤\n│ 技術             │ 命令/代碼                    │ 效果     │\n├─────────────────────────────────────────────────────────────┤\n│ 混合精度         │ with autocast():             │ 2-3x 加速│\n│ 梯度累積         │ loss = loss / accum_steps    │ 大批次   │\n│ 梯度裁剪         │ clip_grad_norm_(params, 1.0) │ 穩定訓練 │\n│ 學習率調度       │ CosineAnnealingLR           │ 更好收斂 │\n│ 權重衰減         │ weight_decay=1e-4           │ 正則化   │\n└─────────────────────────────────────────────────────────────┘\n\n┌─────────────────────────────────────────────────────────────┐\n│                    推理優化                                 │\n├─────────────────────────────────────────────────────────────┤\n│ 技術             │ 命令/代碼                    │ 效果     │\n├─────────────────────────────────────────────────────────────┤\n│ torch.compile    │ model = torch.compile(model) │ 10-50% ↑ │\n│ TorchScript      │ torch.jit.trace(model, x)   │ 部署用   │\n│ 動態量化         │ quantize_dynamic(model)      │ 4x 壓縮  │\n│ 批次推理         │ 多樣本同時推理              │ 吞吐量 ↑ │\n│ ONNX Runtime     │ onnxruntime.InferenceSession│ 跨平台   │\n└─────────────────────────────────────────────────────────────┘\n```\n\n### 📝 部署前 Checklist\n\n**模型準備**：\n- [ ] 模型已訓練完成並評估\n- [ ] 選擇最佳檢查點\n- [ ] 測試推理正確性\n\n**優化**：\n- [ ] 導出 TorchScript 或 ONNX\n- [ ] 考慮量化（如果需要）\n- [ ] 測試優化後的精度\n\n**部署**：\n- [ ] 建立推理服務（FastAPI / Flask）\n- [ ] 設定健康檢查端點\n- [ ] 實現批次推理\n- [ ] 建立 Docker 容器\n- [ ] 配置負載均衡（如果需要）\n\n**監控**：\n- [ ] 設定延遲監控\n- [ ] 設定錯誤追蹤\n- [ ] 設定模型版本管理\n\n### 🏆 課程總結\n\n恭喜完成整個深度學習課程！你已經掌握了：\n\n| 模組 | 主題 | 核心技能 |\n|------|------|----------|\n| **00** | 環境設置 | PyTorch, CUDA, Jupyter |\n| **01** | 數學基礎 | 線性代數, 微積分, 機率 |\n| **02** | MLP | 前向/反向傳播, 優化器 |\n| **03** | CNN | 卷積, 池化, 圖像分類 |\n| **04** | RNN/LSTM | 序列建模, 梯度問題 |\n| **05** | Transformer | 自注意力, 位置編碼 |\n| **06** | LLM | 推理, 微調, RAG |\n| **07** | VAE | 變分推理, 潛在空間 |\n| **08** | GAN/Diffusion | 對抗訓練, 去噪生成 |\n| **09** | GNN | 圖卷積, 訊息傳遞 |\n| **10** | 部署 | 優化, 量化, 服務化 |\n\n### 🔗 延伸學習資源\n\n| 資源 | 說明 |\n|------|------|\n| [PyTorch 官方教程](https://pytorch.org/tutorials/) | 官方最佳實踐 |\n| [Hugging Face Course](https://huggingface.co/course) | NLP/LLM 實務 |\n| [Fast.ai](https://www.fast.ai/) | 實用深度學習 |\n| [Papers With Code](https://paperswithcode.com/) | 論文 + 代碼 |\n| [Weights & Biases](https://wandb.ai/site) | 實驗追蹤 |\n| [MLOps Community](https://mlops.community/) | 部署最佳實踐 |\n\n### 🎓 下一步建議\n\n1. **選擇專精方向**\n   - 電腦視覺 → 深入 CNN, ViT, 目標檢測\n   - 自然語言處理 → 深入 Transformer, LLM 微調\n   - 生成模型 → 深入 Diffusion, 3D 生成\n   - 圖學習 → 深入 GNN, 知識圖譜\n\n2. **實戰項目**\n   - 參加 Kaggle 競賽\n   - 復現經典論文\n   - 建立端到端應用\n\n3. **保持更新**\n   - 關注 arXiv 最新論文\n   - 追蹤 AI 領域社群\n   - 參與開源項目\n\n**感謝你完成這個課程！祝你在深度學習的旅程中一切順利！** 🚀",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 總結\n",
    "\n",
    "### 本模組重點\n",
    "\n",
    "1. **DataLoader 優化**\n",
    "   - `num_workers`: 並行載入\n",
    "   - `pin_memory`: 加速 CPU→GPU 傳輸\n",
    "   - `prefetch_factor`: 預取批次\n",
    "\n",
    "2. **混合精度訓練**\n",
    "   - `autocast`: 自動選擇精度\n",
    "   - `GradScaler`: 防止梯度下溢\n",
    "   - 可提速 2-3x\n",
    "\n",
    "3. **梯度累積**\n",
    "   - 模擬大批次訓練\n",
    "   - 損失除以累積步數\n",
    "\n",
    "4. **模型保存與載入**\n",
    "   - `state_dict`: 只保存權重\n",
    "   - `checkpoint`: 完整訓練狀態\n",
    "   - `TorchScript`: 部署用\n",
    "\n",
    "5. **推理優化**\n",
    "   - 模型融合\n",
    "   - 批次處理\n",
    "\n",
    "### 性能優化清單\n",
    "\n",
    "```\n",
    "╔══════════════════════════════════════════════════════════╗\n",
    "║                    性能優化清單                          ║\n",
    "╠══════════════════════════════════════════════════════════╣\n",
    "║  資料載入                                                ║\n",
    "║  ☐ num_workers = 4-8                                    ║\n",
    "║  ☐ pin_memory = True                                    ║\n",
    "║  ☐ 預處理放到 Dataset 而非訓練循環                       ║\n",
    "║                                                          ║\n",
    "║  訓練優化                                                ║\n",
    "║  ☐ 使用混合精度 (AMP)                                   ║\n",
    "║  ☐ 梯度累積（如果需要大批次）                           ║\n",
    "║  ☐ 梯度裁剪（穩定訓練）                                 ║\n",
    "║  ☐ 學習率調度（Cosine, OneCycle）                       ║\n",
    "║                                                          ║\n",
    "║  記憶體優化                                              ║\n",
    "║  ☐ 梯度檢查點（大模型）                                 ║\n",
    "║  ☐ 定期清理 GPU 記憶體                                  ║\n",
    "║  ☐ 使用 8-bit 優化器（大模型）                          ║\n",
    "║                                                          ║\n",
    "║  部署優化                                                ║\n",
    "║  ☐ 導出 TorchScript/ONNX                                ║\n",
    "║  ☐ 批次推理                                             ║\n",
    "║  ☐ 模型量化（如果需要）                                 ║\n",
    "╚══════════════════════════════════════════════════════════╝\n",
    "```\n",
    "\n",
    "### 課程總結\n",
    "\n",
    "恭喜你完成了整個深度學習課程！你已經學習了：\n",
    "\n",
    "1. **Module 0-1**: 環境設置、數學基礎\n",
    "2. **Module 2-3**: MLP、CNN 圖像分類\n",
    "3. **Module 4-5**: RNN/LSTM、Transformer 序列建模\n",
    "4. **Module 6**: LLM 實務應用與微調\n",
    "5. **Module 7-8**: VAE、GAN、Diffusion 生成模型\n",
    "6. **Module 9**: GNN 圖結構學習\n",
    "7. **Module 10**: 性能優化與部署\n",
    "\n",
    "下一步建議：\n",
    "- 選擇一個感興趣的領域深入\n",
    "- 參與 Kaggle 競賽實踐\n",
    "- 閱讀最新論文保持更新"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}