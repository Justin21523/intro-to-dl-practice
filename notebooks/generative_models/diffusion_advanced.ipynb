{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion 進階技術 (Advanced Diffusion Models)\n",
    "\n",
    "本 notebook 對應李宏毅老師 2025 Spring ML HW10，探討 Diffusion 模型的進階技術。\n",
    "\n",
    "## 學習目標\n",
    "1. 理解 DDIM 採樣加速\n",
    "2. 學習 Classifier-Free Guidance (CFG)\n",
    "3. 了解 ControlNet 的條件控制\n",
    "4. 探索 Latent Diffusion (Stable Diffusion) 架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DDPM vs DDIM\n",
    "\n",
    "### 1.1 DDPM 採樣（原始方法）\n",
    "- 需要 1000 步的迭代\n",
    "- 每步都有隨機噪音\n",
    "\n",
    "### 1.2 DDIM 採樣（加速方法）\n",
    "- 可以用 50-100 步達到相似品質\n",
    "- 確定性採樣（無隨機噪音）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIMSampler:\n",
    "    \"\"\"\n",
    "    DDIM (Denoising Diffusion Implicit Models) 採樣器\n",
    "    \"\"\"\n",
    "    def __init__(self, num_train_timesteps=1000, beta_start=0.0001, beta_end=0.02):\n",
    "        self.num_train_timesteps = num_train_timesteps\n",
    "        \n",
    "        # Beta schedule\n",
    "        betas = torch.linspace(beta_start, beta_end, num_train_timesteps)\n",
    "        alphas = 1.0 - betas\n",
    "        self.alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    \n",
    "    def set_timesteps(self, num_inference_steps):\n",
    "        \"\"\"設定採樣步數（比訓練步數少很多）\"\"\"\n",
    "        self.num_inference_steps = num_inference_steps\n",
    "        step_ratio = self.num_train_timesteps // num_inference_steps\n",
    "        self.timesteps = torch.arange(0, num_inference_steps) * step_ratio\n",
    "        self.timesteps = torch.flip(self.timesteps, [0])  # 從大到小\n",
    "    \n",
    "    def step(self, model_output, timestep, sample, eta=0.0):\n",
    "        \"\"\"\n",
    "        單步 DDIM 採樣\n",
    "        \n",
    "        eta=0: 完全確定性\n",
    "        eta=1: 等同 DDPM\n",
    "        \"\"\"\n",
    "        prev_timestep = timestep - self.num_train_timesteps // self.num_inference_steps\n",
    "        \n",
    "        alpha_prod_t = self.alphas_cumprod[timestep]\n",
    "        alpha_prod_t_prev = self.alphas_cumprod[prev_timestep] if prev_timestep >= 0 else torch.tensor(1.0)\n",
    "        \n",
    "        # 預測 x0\n",
    "        pred_x0 = (sample - torch.sqrt(1 - alpha_prod_t) * model_output) / torch.sqrt(alpha_prod_t)\n",
    "        \n",
    "        # 計算「方向」\n",
    "        sigma = eta * torch.sqrt((1 - alpha_prod_t_prev) / (1 - alpha_prod_t)) * \\\n",
    "                torch.sqrt(1 - alpha_prod_t / alpha_prod_t_prev)\n",
    "        \n",
    "        # 計算 x_{t-1}\n",
    "        dir_xt = torch.sqrt(1 - alpha_prod_t_prev - sigma**2) * model_output\n",
    "        prev_sample = torch.sqrt(alpha_prod_t_prev) * pred_x0 + dir_xt\n",
    "        \n",
    "        if eta > 0:\n",
    "            noise = torch.randn_like(sample)\n",
    "            prev_sample = prev_sample + sigma * noise\n",
    "        \n",
    "        return prev_sample\n",
    "\n",
    "print(\"DDIM Sampler 已實作\")\n",
    "print(\"優勢：可將 1000 步降到 50 步，大幅加速生成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Classifier-Free Guidance (CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_free_guidance(model, x_t, t, condition, guidance_scale=7.5):\n",
    "    \"\"\"\n",
    "    Classifier-Free Guidance\n",
    "    \n",
    "    在訓練時，隨機以 p_uncond 機率丟棄條件（用空條件替代）\n",
    "    在推理時，結合有條件和無條件的預測\n",
    "    \n",
    "    公式：\n",
    "    ε_guided = ε_uncond + guidance_scale * (ε_cond - ε_uncond)\n",
    "    \"\"\"\n",
    "    # 無條件預測\n",
    "    noise_pred_uncond = model(x_t, t, condition=None)\n",
    "    \n",
    "    # 有條件預測\n",
    "    noise_pred_cond = model(x_t, t, condition=condition)\n",
    "    \n",
    "    # CFG 公式\n",
    "    noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)\n",
    "    \n",
    "    return noise_pred\n",
    "\n",
    "print(\"\"\"CFG 說明：\n",
    "- guidance_scale = 1.0: 無引導\n",
    "- guidance_scale = 7.5: 標準值（Stable Diffusion 常用）\n",
    "- guidance_scale > 10: 更強的條件遵循，但可能失真\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Latent Diffusion (Stable Diffusion 架構)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────┐\n",
    "│                    Latent Diffusion 架構                                 │\n",
    "├─────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                         │\n",
    "│   Image (512x512x3)    Latent (64x64x4)    Image (512x512x3)            │\n",
    "│         │                    │                    ▲                     │\n",
    "│         ▼                    ▼                    │                     │\n",
    "│   ┌──────────┐        ┌──────────────┐     ┌──────────┐                │\n",
    "│   │  VAE     │        │   U-Net      │     │  VAE     │                │\n",
    "│   │ Encoder  │   →    │  Diffusion   │  →  │ Decoder  │                │\n",
    "│   └──────────┘        │   Process    │     └──────────┘                │\n",
    "│                       └──────────────┘                                  │\n",
    "│                              ▲                                          │\n",
    "│                              │                                          │\n",
    "│                    ┌─────────────────┐                                  │\n",
    "│                    │  Text Encoder   │                                  │\n",
    "│                    │    (CLIP)       │                                  │\n",
    "│                    └─────────────────┘                                  │\n",
    "│                              ▲                                          │\n",
    "│                              │                                          │\n",
    "│                      \"a photo of cat\"                                  │\n",
    "│                                                                         │\n",
    "│  優勢：                                                                  │\n",
    "│  1. 在低維 latent 空間操作，計算效率高                                    │\n",
    "│  2. VAE 壓縮 8 倍，大幅減少計算量                                         │\n",
    "│  3. 可以處理高解析度圖像                                                  │\n",
    "│                                                                         │\n",
    "└─────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 練習題\n",
    "\n",
    "### 練習 1：比較不同 CFG 值的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 練習 1：實驗不同 guidance_scale 的效果\n",
    "def compare_guidance_scales(model, prompt, scales=[1.0, 3.0, 7.5, 12.0]):\n",
    "    \"\"\"\n",
    "    TODO: 對比不同 guidance_scale 的生成結果\n",
    "    \n",
    "    觀察：\n",
    "    - scale 太低：圖像可能與 prompt 不相關\n",
    "    - scale 適中：最佳平衡\n",
    "    - scale 太高：過度飽和、失真\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "print(\"練習 1：實作 compare_guidance_scales 函數\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 總結\n",
    "\n",
    "| 技術 | 用途 |\n",
    "|------|------|\n",
    "| DDIM | 加速採樣（1000步→50步） |\n",
    "| CFG | 提高生成品質和條件遵循 |\n",
    "| Latent Diffusion | 在壓縮空間操作，高效處理高解析度 |\n",
    "| ControlNet | 添加額外條件控制（邊緣、姿態等） |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Diffusion 進階技術 - 完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
