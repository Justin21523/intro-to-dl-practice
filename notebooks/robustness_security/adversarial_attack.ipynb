{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å°æŠ—æ”»æ“Š (Adversarial Attack)\n",
    "\n",
    "## å­¸ç¿’ç›®æ¨™\n",
    "- ç†è§£å°æŠ—æ¨£æœ¬çš„æ¦‚å¿µ\n",
    "- å¯¦ä½œ FGSM æ”»æ“Š\n",
    "- å¯¦ä½œ PGD è¿­ä»£æ”»æ“Š\n",
    "- å­¸ç¿’å°æŠ—é˜²ç¦¦ç­–ç•¥\n",
    "\n",
    "## å°æ‡‰èª²ç¨‹\n",
    "- [æå®æ¯… ML 2021 - Adversarial Attack](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php)\n",
    "- [HW10: Adversarial Attack](https://github.com/ga642381/ML2021-Spring/tree/main/HW10)\n",
    "\n",
    "## å°æŠ—æ”»æ“Šæ¦‚è¿°\n",
    "\n",
    "```\n",
    "å°æŠ—æ”»æ“Šåˆ†é¡\n",
    "â”œâ”€â”€ æŒ‰ç›®æ¨™\n",
    "â”‚   â”œâ”€â”€ Non-targeted: è®“æ¨¡å‹é æ¸¬éŒ¯èª¤\n",
    "â”‚   â””â”€â”€ Targeted: è®“æ¨¡å‹é æ¸¬ç‚ºæŒ‡å®šé¡åˆ¥\n",
    "â”‚\n",
    "â”œâ”€â”€ æŒ‰çŸ¥è­˜\n",
    "â”‚   â”œâ”€â”€ White-box: å®Œå…¨äº†è§£æ¨¡å‹\n",
    "â”‚   â””â”€â”€ Black-box: åªèƒ½æŸ¥è©¢æ¨¡å‹\n",
    "â”‚\n",
    "â””â”€â”€ æŒ‰æ“¾å‹•\n",
    "    â”œâ”€â”€ Lâˆ: æ¯å€‹åƒç´ æœ€å¤§æ”¹è®Šé‡\n",
    "    â”œâ”€â”€ L2: æ“¾å‹•çš„æ­å¹¾é‡Œå¾—ç¯„æ•¸\n",
    "    â””â”€â”€ L0: æ”¹è®Šçš„åƒç´ æ•¸é‡\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ä½¿ç”¨è¨­å‚™: {device}\")\n",
    "\n",
    "# å›ºå®šéš¨æ©Ÿç¨®å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== æº–å‚™æ¨¡å‹å’Œè³‡æ–™ ==========\n",
    "\n",
    "# è¼‰å…¥é è¨“ç·´æ¨¡å‹\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# é è™•ç†\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# ImageNet æ­£è¦åŒ–åƒæ•¸\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1).to(device)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1).to(device)\n",
    "\n",
    "def normalize(x):\n",
    "    return (x - mean) / std\n",
    "\n",
    "def denormalize(x):\n",
    "    return x * std + mean\n",
    "\n",
    "print(\"æ¨¡å‹è¼‰å…¥å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== å»ºç«‹ç¯„ä¾‹åœ–ç‰‡ ==========\n",
    "\n",
    "def create_test_image():\n",
    "    \"\"\"\n",
    "    å»ºç«‹æ¸¬è©¦åœ–ç‰‡\n",
    "    \"\"\"\n",
    "    # å»ºç«‹ä¸€å€‹æœ‰ç‰¹å¾µçš„åœ–ç‰‡\n",
    "    img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›å½¢ç‹€å’Œé¡è‰²\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            # åœ“å½¢ç‰©é«”\n",
    "            if (i - 112)**2 + (j - 112)**2 < 60**2:\n",
    "                img[i, j] = [255, 180, 100]\n",
    "            # èƒŒæ™¯æ¼¸å±¤\n",
    "            else:\n",
    "                img[i, j] = [100 + i // 3, 150, 200 - j // 3]\n",
    "    \n",
    "    return Image.fromarray(img)\n",
    "\n",
    "# å»ºç«‹åœ–ç‰‡\n",
    "original_image = create_test_image()\n",
    "original_tensor = preprocess(original_image).unsqueeze(0).to(device)\n",
    "\n",
    "# åŸå§‹é æ¸¬\n",
    "with torch.no_grad():\n",
    "    output = model(normalize(original_tensor))\n",
    "    original_pred = output.argmax(dim=1).item()\n",
    "    original_conf = F.softmax(output, dim=1)[0, original_pred].item()\n",
    "\n",
    "print(f\"åŸå§‹é æ¸¬é¡åˆ¥: {original_pred}\")\n",
    "print(f\"åŸå§‹ä¿¡å¿ƒåº¦: {original_conf:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(original_image)\n",
    "plt.title(f'Original (Class: {original_pred}, Conf: {original_conf:.2%})')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: FGSM (Fast Gradient Sign Method)\n",
    "\n",
    "FGSM æ˜¯æœ€ç°¡å–®çš„å°æŠ—æ”»æ“Šæ–¹æ³•ï¼Œåªéœ€è¦ä¸€æ­¥æ¢¯åº¦è¨ˆç®—ã€‚\n",
    "\n",
    "### å…¬å¼\n",
    "\n",
    "**Non-targeted Attack:**\n",
    "$$x_{adv} = x + \\epsilon \\cdot \\text{sign}(\\nabla_x L(f(x), y))$$\n",
    "\n",
    "**Targeted Attack:**\n",
    "$$x_{adv} = x - \\epsilon \\cdot \\text{sign}(\\nabla_x L(f(x), y_{target}))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== FGSM æ”»æ“Š ==========\n",
    "\n",
    "def fgsm_attack(model, image, label, epsilon, targeted=False):\n",
    "    \"\"\"\n",
    "    FGSM æ”»æ“Š\n",
    "    \n",
    "    Args:\n",
    "        model: ç›®æ¨™æ¨¡å‹\n",
    "        image: åŸå§‹åœ–åƒ (0-1 ç¯„åœ)\n",
    "        label: æ¨™ç±¤ï¼ˆnon-targeted: åŸå§‹æ¨™ç±¤, targeted: ç›®æ¨™æ¨™ç±¤ï¼‰\n",
    "        epsilon: æ“¾å‹•å¤§å°\n",
    "        targeted: æ˜¯å¦ç‚ºç›®æ¨™æ”»æ“Š\n",
    "    \n",
    "    Returns:\n",
    "        å°æŠ—æ¨£æœ¬\n",
    "    \"\"\"\n",
    "    image = image.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # å‰å‘å‚³æ’­\n",
    "    output = model(normalize(image))\n",
    "    \n",
    "    # è¨ˆç®—æå¤±\n",
    "    loss = F.cross_entropy(output, torch.tensor([label]).to(device))\n",
    "    \n",
    "    # åå‘å‚³æ’­\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # ç²å–æ¢¯åº¦ç¬¦è™Ÿ\n",
    "    grad_sign = image.grad.data.sign()\n",
    "    \n",
    "    # ç”Ÿæˆå°æŠ—æ¨£æœ¬\n",
    "    if targeted:\n",
    "        # ç›®æ¨™æ”»æ“Šï¼šæ¸›å°‘ç›®æ¨™é¡åˆ¥çš„æå¤±\n",
    "        adv_image = image - epsilon * grad_sign\n",
    "    else:\n",
    "        # éç›®æ¨™æ”»æ“Šï¼šå¢åŠ åŸå§‹é¡åˆ¥çš„æå¤±\n",
    "        adv_image = image + epsilon * grad_sign\n",
    "    \n",
    "    # è£å‰ªåˆ°æœ‰æ•ˆç¯„åœ\n",
    "    adv_image = torch.clamp(adv_image, 0, 1)\n",
    "    \n",
    "    return adv_image.detach()\n",
    "\n",
    "# æ¸¬è©¦ä¸åŒ epsilon çš„æ•ˆæœ\n",
    "epsilons = [0, 0.01, 0.02, 0.05, 0.1, 0.2]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for ax, eps in zip(axes.flat, epsilons):\n",
    "    if eps == 0:\n",
    "        adv_tensor = original_tensor.clone()\n",
    "    else:\n",
    "        adv_tensor = fgsm_attack(model, original_tensor, original_pred, eps)\n",
    "    \n",
    "    # é æ¸¬\n",
    "    with torch.no_grad():\n",
    "        output = model(normalize(adv_tensor))\n",
    "        pred = output.argmax(dim=1).item()\n",
    "        conf = F.softmax(output, dim=1)[0, pred].item()\n",
    "    \n",
    "    # é¡¯ç¤º\n",
    "    adv_img = adv_tensor.squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "    ax.imshow(adv_img)\n",
    "    \n",
    "    color = 'green' if pred == original_pred else 'red'\n",
    "    ax.set_title(f'Îµ={eps}\\nPred: {pred} ({conf:.1%})', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('FGSM Attack with Different Epsilon', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== å¯è¦–åŒ–æ“¾å‹• ==========\n",
    "\n",
    "epsilon = 0.05\n",
    "adv_tensor = fgsm_attack(model, original_tensor, original_pred, epsilon)\n",
    "\n",
    "# è¨ˆç®—æ“¾å‹•\n",
    "perturbation = (adv_tensor - original_tensor).squeeze().permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# åŸåœ–\n",
    "axes[0].imshow(original_tensor.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "axes[0].set_title('Original')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# æ“¾å‹•ï¼ˆæ”¾å¤§é¡¯ç¤ºï¼‰\n",
    "perturbation_vis = (perturbation - perturbation.min()) / (perturbation.max() - perturbation.min())\n",
    "axes[1].imshow(perturbation_vis)\n",
    "axes[1].set_title(f'Perturbation (Îµ={epsilon})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# æ”¾å¤§çš„æ“¾å‹•\n",
    "axes[2].imshow(perturbation * 10 + 0.5)  # æ”¾å¤§ 10 å€\n",
    "axes[2].set_title('Perturbation (10x magnified)')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# å°æŠ—æ¨£æœ¬\n",
    "with torch.no_grad():\n",
    "    output = model(normalize(adv_tensor))\n",
    "    pred = output.argmax(dim=1).item()\n",
    "    conf = F.softmax(output, dim=1)[0, pred].item()\n",
    "\n",
    "axes[3].imshow(adv_tensor.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "axes[3].set_title(f'Adversarial (Pred: {pred}, {conf:.1%})')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è¨ˆç®—æ“¾å‹•çµ±è¨ˆ\n",
    "print(f\"æ“¾å‹•çµ±è¨ˆ:\")\n",
    "print(f\"  Lâˆ norm: {perturbation.max():.4f}\")\n",
    "print(f\"  L2 norm: {np.linalg.norm(perturbation):.4f}\")\n",
    "print(f\"  Mean: {perturbation.mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: PGD (Projected Gradient Descent)\n",
    "\n",
    "PGD æ˜¯è¿­ä»£ç‰ˆæœ¬çš„ FGSMï¼Œé€šå¸¸æ›´å¼·å¤§ã€‚\n",
    "\n",
    "### å…¬å¼\n",
    "$$x^{t+1} = \\Pi_{x + S} \\left( x^t + \\alpha \\cdot \\text{sign}(\\nabla_x L(f(x^t), y)) \\right)$$\n",
    "\n",
    "å…¶ä¸­ $\\Pi$ æ˜¯æŠ•å½±æ“ä½œï¼Œå°‡æ“¾å‹•é™åˆ¶åœ¨ $\\epsilon$-çƒå…§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== PGD æ”»æ“Š ==========\n",
    "\n",
    "def pgd_attack(model, image, label, epsilon, alpha, num_iter, targeted=False, random_start=True):\n",
    "    \"\"\"\n",
    "    PGD æ”»æ“Š\n",
    "    \n",
    "    Args:\n",
    "        model: ç›®æ¨™æ¨¡å‹\n",
    "        image: åŸå§‹åœ–åƒ\n",
    "        label: æ¨™ç±¤\n",
    "        epsilon: æœ€å¤§æ“¾å‹•ï¼ˆLâˆï¼‰\n",
    "        alpha: æ­¥é•·\n",
    "        num_iter: è¿­ä»£æ¬¡æ•¸\n",
    "        targeted: æ˜¯å¦ç‚ºç›®æ¨™æ”»æ“Š\n",
    "        random_start: æ˜¯å¦å¾éš¨æ©Ÿé»é–‹å§‹\n",
    "    \"\"\"\n",
    "    # åˆå§‹åŒ–\n",
    "    if random_start:\n",
    "        # å¾åŸå§‹åœ–åƒçš„ epsilon é„°åŸŸå…§éš¨æ©Ÿé¸æ“‡èµ·é»\n",
    "        adv_image = image + torch.empty_like(image).uniform_(-epsilon, epsilon)\n",
    "        adv_image = torch.clamp(adv_image, 0, 1)\n",
    "    else:\n",
    "        adv_image = image.clone()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        adv_image = adv_image.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        # å‰å‘å‚³æ’­\n",
    "        output = model(normalize(adv_image))\n",
    "        loss = F.cross_entropy(output, torch.tensor([label]).to(device))\n",
    "        \n",
    "        # åå‘å‚³æ’­\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # æ›´æ–°\n",
    "        grad_sign = adv_image.grad.data.sign()\n",
    "        \n",
    "        if targeted:\n",
    "            adv_image = adv_image - alpha * grad_sign\n",
    "        else:\n",
    "            adv_image = adv_image + alpha * grad_sign\n",
    "        \n",
    "        # æŠ•å½±åˆ° epsilon-çƒå…§\n",
    "        perturbation = torch.clamp(adv_image - image, -epsilon, epsilon)\n",
    "        adv_image = torch.clamp(image + perturbation, 0, 1)\n",
    "    \n",
    "    return adv_image.detach()\n",
    "\n",
    "# æ¸¬è©¦ PGD\n",
    "epsilon = 0.03\n",
    "alpha = 0.01\n",
    "num_iter = 10\n",
    "\n",
    "pgd_adv = pgd_attack(model, original_tensor, original_pred, epsilon, alpha, num_iter)\n",
    "\n",
    "# æ¯”è¼ƒ FGSM å’Œ PGD\n",
    "fgsm_adv = fgsm_attack(model, original_tensor, original_pred, epsilon)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# åŸåœ–\n",
    "axes[0].imshow(original_tensor.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "with torch.no_grad():\n",
    "    out = model(normalize(original_tensor))\n",
    "    pred = out.argmax(1).item()\n",
    "    conf = F.softmax(out, 1)[0, pred].item()\n",
    "axes[0].set_title(f'Original\\nPred: {pred} ({conf:.1%})')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# FGSM\n",
    "axes[1].imshow(fgsm_adv.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "with torch.no_grad():\n",
    "    out = model(normalize(fgsm_adv))\n",
    "    pred = out.argmax(1).item()\n",
    "    conf = F.softmax(out, 1)[0, pred].item()\n",
    "axes[1].set_title(f'FGSM (Îµ={epsilon})\\nPred: {pred} ({conf:.1%})')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# PGD\n",
    "axes[2].imshow(pgd_adv.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "with torch.no_grad():\n",
    "    out = model(normalize(pgd_adv))\n",
    "    pred = out.argmax(1).item()\n",
    "    conf = F.softmax(out, 1)[0, pred].item()\n",
    "axes[2].set_title(f'PGD ({num_iter} iter)\\nPred: {pred} ({conf:.1%})')\n",
    "axes[2].axis('off')\n",
    "\n",
    "# æ“¾å‹•å·®ç•°\n",
    "fgsm_pert = (fgsm_adv - original_tensor).abs().sum(1).squeeze().cpu().numpy()\n",
    "pgd_pert = (pgd_adv - original_tensor).abs().sum(1).squeeze().cpu().numpy()\n",
    "axes[3].imshow(pgd_pert - fgsm_pert, cmap='RdBu')\n",
    "axes[3].set_title('PGD - FGSM Perturbation Diff')\n",
    "axes[3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Targeted Attack\n",
    "\n",
    "ç›®æ¨™æ”»æ“Šï¼šè®“æ¨¡å‹é æ¸¬ç‚ºæŒ‡å®šçš„é¡åˆ¥ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Targeted Attack ==========\n",
    "\n",
    "def targeted_pgd_attack(model, image, target_class, epsilon, alpha, num_iter):\n",
    "    \"\"\"\n",
    "    ç›®æ¨™ PGD æ”»æ“Š\n",
    "    \"\"\"\n",
    "    adv_image = image.clone()\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        adv_image = adv_image.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        output = model(normalize(adv_image))\n",
    "        \n",
    "        # ç›®æ¨™æ”»æ“Šï¼šæœ€å°åŒ–èˆ‡ç›®æ¨™é¡åˆ¥çš„æå¤±\n",
    "        loss = F.cross_entropy(output, torch.tensor([target_class]).to(device))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # è² æ¢¯åº¦æ–¹å‘ï¼ˆæ¸›å°‘æå¤±ï¼‰\n",
    "        adv_image = adv_image - alpha * adv_image.grad.data.sign()\n",
    "        \n",
    "        # æŠ•å½±\n",
    "        perturbation = torch.clamp(adv_image - image, -epsilon, epsilon)\n",
    "        adv_image = torch.clamp(image + perturbation, 0, 1)\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦æˆåŠŸ\n",
    "        with torch.no_grad():\n",
    "            pred = model(normalize(adv_image)).argmax(1).item()\n",
    "            if pred == target_class:\n",
    "                break\n",
    "    \n",
    "    return adv_image.detach()\n",
    "\n",
    "# æ¸¬è©¦ç›®æ¨™æ”»æ“Š\n",
    "target_classes = [100, 200, 300, 400, 500]\n",
    "\n",
    "fig, axes = plt.subplots(1, len(target_classes) + 1, figsize=(18, 3))\n",
    "\n",
    "# åŸåœ–\n",
    "axes[0].imshow(original_tensor.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "with torch.no_grad():\n",
    "    pred = model(normalize(original_tensor)).argmax(1).item()\n",
    "axes[0].set_title(f'Original\\nPred: {pred}')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# ç›®æ¨™æ”»æ“Š\n",
    "for ax, target in zip(axes[1:], target_classes):\n",
    "    adv = targeted_pgd_attack(model, original_tensor, target, epsilon=0.1, alpha=0.02, num_iter=50)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(normalize(adv))\n",
    "        pred = out.argmax(1).item()\n",
    "        conf = F.softmax(out, 1)[0, pred].item()\n",
    "    \n",
    "    ax.imshow(adv.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    color = 'green' if pred == target else 'red'\n",
    "    ax.set_title(f'Target: {target}\\nPred: {pred} ({conf:.1%})', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Targeted PGD Attack', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: å°æŠ—é˜²ç¦¦\n",
    "\n",
    "### å¸¸è¦‹é˜²ç¦¦æ–¹æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== é˜²ç¦¦æ–¹æ³• 1: Input Transformation ==========\n",
    "\n",
    "def jpeg_compression(image, quality=75):\n",
    "    \"\"\"\n",
    "    JPEG å£“ç¸®ä½œç‚ºé˜²ç¦¦\n",
    "    å¯ä»¥å»é™¤å°æŠ—æ“¾å‹•\n",
    "    \"\"\"\n",
    "    from io import BytesIO\n",
    "    \n",
    "    # è½‰ç‚º PIL Image\n",
    "    img_np = (image.squeeze().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(img_np)\n",
    "    \n",
    "    # JPEG å£“ç¸®\n",
    "    buffer = BytesIO()\n",
    "    pil_img.save(buffer, format='JPEG', quality=quality)\n",
    "    buffer.seek(0)\n",
    "    compressed_img = Image.open(buffer)\n",
    "    \n",
    "    # è½‰å› tensor\n",
    "    compressed_tensor = transforms.ToTensor()(compressed_img).unsqueeze(0).to(device)\n",
    "    \n",
    "    return compressed_tensor\n",
    "\n",
    "def gaussian_blur(image, kernel_size=5, sigma=1.0):\n",
    "    \"\"\"\n",
    "    é«˜æ–¯æ¨¡ç³Šä½œç‚ºé˜²ç¦¦\n",
    "    \"\"\"\n",
    "    from torchvision.transforms.functional import gaussian_blur as blur\n",
    "    return blur(image, kernel_size, [sigma, sigma])\n",
    "\n",
    "# æ¸¬è©¦é˜²ç¦¦æ•ˆæœ\n",
    "adv_image = pgd_attack(model, original_tensor, original_pred, 0.05, 0.01, 20)\n",
    "\n",
    "# æ‡‰ç”¨é˜²ç¦¦\n",
    "jpeg_defended = jpeg_compression(adv_image, quality=50)\n",
    "blur_defended = gaussian_blur(adv_image, kernel_size=5, sigma=2.0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "images = [original_tensor, adv_image, jpeg_defended, blur_defended]\n",
    "titles = ['Original', 'Adversarial', 'JPEG Defense', 'Blur Defense']\n",
    "\n",
    "for ax, img, title in zip(axes, images, titles):\n",
    "    with torch.no_grad():\n",
    "        out = model(normalize(img))\n",
    "        pred = out.argmax(1).item()\n",
    "        conf = F.softmax(out, 1)[0, pred].item()\n",
    "    \n",
    "    ax.imshow(img.squeeze().permute(1, 2, 0).cpu().numpy())\n",
    "    color = 'green' if pred == original_pred else 'red'\n",
    "    ax.set_title(f'{title}\\nPred: {pred} ({conf:.1%})', color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== é˜²ç¦¦æ–¹æ³• 2: Adversarial Training ==========\n",
    "\n",
    "def adversarial_training_step(model, images, labels, epsilon, alpha, num_iter, optimizer):\n",
    "    \"\"\"\n",
    "    å°æŠ—è¨“ç·´çš„ä¸€å€‹æ­¥é©Ÿ\n",
    "    \n",
    "    1. ç”Ÿæˆå°æŠ—æ¨£æœ¬\n",
    "    2. ç”¨å°æŠ—æ¨£æœ¬è¨“ç·´æ¨¡å‹\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # ç”Ÿæˆå°æŠ—æ¨£æœ¬\n",
    "    adv_images = images.clone()\n",
    "    for _ in range(num_iter):\n",
    "        adv_images = adv_images.clone().detach().requires_grad_(True)\n",
    "        \n",
    "        outputs = model(adv_images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        adv_images = adv_images + alpha * adv_images.grad.sign()\n",
    "        perturbation = torch.clamp(adv_images - images, -epsilon, epsilon)\n",
    "        adv_images = torch.clamp(images + perturbation, 0, 1)\n",
    "    \n",
    "    # è¨“ç·´æ¨¡å‹\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(adv_images.detach())\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "print(\"å°æŠ—è¨“ç·´å‡½æ•¸å·²å®šç¾©\")\n",
    "print(\"\\nå°æŠ—è¨“ç·´æµç¨‹:\")\n",
    "print(\"1. å°æ¯å€‹è¨“ç·´æ‰¹æ¬¡ç”Ÿæˆå°æŠ—æ¨£æœ¬\")\n",
    "print(\"2. ç”¨å°æŠ—æ¨£æœ¬æ›´æ–°æ¨¡å‹\")\n",
    "print(\"3. é€™ä½¿æ¨¡å‹å°å°æŠ—æ”»æ“Šæ›´é­¯æ£’\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== é˜²ç¦¦æ–¹æ³• 3: Ensemble Defense ==========\n",
    "\n",
    "def ensemble_predict(models, image):\n",
    "    \"\"\"\n",
    "    é›†æˆé æ¸¬\n",
    "    \n",
    "    å¤šå€‹æ¨¡å‹æŠ•ç¥¨æ±ºå®šæœ€çµ‚é æ¸¬\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(normalize(image))\n",
    "            pred = output.argmax(1).item()\n",
    "            predictions.append(pred)\n",
    "    \n",
    "    # å¤šæ•¸æŠ•ç¥¨\n",
    "    from collections import Counter\n",
    "    vote = Counter(predictions).most_common(1)[0][0]\n",
    "    \n",
    "    return vote, predictions\n",
    "\n",
    "print(\"é›†æˆé˜²ç¦¦èªªæ˜:\")\n",
    "print(\"- ä½¿ç”¨å¤šå€‹ä¸åŒçš„æ¨¡å‹\")\n",
    "print(\"- å°æŠ—æ¨£æœ¬é€šå¸¸åªå°å–®ä¸€æ¨¡å‹æœ‰æ•ˆ\")\n",
    "print(\"- é›†æˆå¯ä»¥æé«˜é­¯æ£’æ€§\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: æ”»æ“ŠæˆåŠŸç‡è©•ä¼°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== è©•ä¼°æ”»æ“ŠæˆåŠŸç‡ ==========\n",
    "\n",
    "def evaluate_attack(model, images, labels, attack_fn, attack_params):\n",
    "    \"\"\"\n",
    "    è©•ä¼°æ”»æ“ŠæˆåŠŸç‡\n",
    "    \n",
    "    Returns:\n",
    "        success_rate: æ”»æ“ŠæˆåŠŸç‡\n",
    "        avg_perturbation: å¹³å‡æ“¾å‹•å¤§å°\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    total = len(images)\n",
    "    successful = 0\n",
    "    perturbations = []\n",
    "    \n",
    "    for i, (img, label) in enumerate(zip(images, labels)):\n",
    "        img = img.unsqueeze(0).to(device)\n",
    "        \n",
    "        # ç”Ÿæˆå°æŠ—æ¨£æœ¬\n",
    "        adv_img = attack_fn(model, img, label, **attack_params)\n",
    "        \n",
    "        # æª¢æŸ¥æ˜¯å¦æˆåŠŸ\n",
    "        with torch.no_grad():\n",
    "            pred = model(normalize(adv_img)).argmax(1).item()\n",
    "        \n",
    "        if pred != label:\n",
    "            successful += 1\n",
    "        \n",
    "        # è¨ˆç®—æ“¾å‹•\n",
    "        pert = (adv_img - img).abs().max().item()\n",
    "        perturbations.append(pert)\n",
    "    \n",
    "    success_rate = successful / total\n",
    "    avg_pert = np.mean(perturbations)\n",
    "    \n",
    "    return success_rate, avg_pert\n",
    "\n",
    "# ç”Ÿæˆæ¸¬è©¦è³‡æ–™\n",
    "test_images = [original_tensor.squeeze() for _ in range(10)]\n",
    "test_labels = [original_pred for _ in range(10)]\n",
    "\n",
    "# è©•ä¼°ä¸åŒæ”»æ“Š\n",
    "attacks = {\n",
    "    'FGSM Îµ=0.01': {'epsilon': 0.01},\n",
    "    'FGSM Îµ=0.05': {'epsilon': 0.05},\n",
    "    'FGSM Îµ=0.10': {'epsilon': 0.10},\n",
    "}\n",
    "\n",
    "print(\"æ”»æ“Šæ•ˆæœè©•ä¼°:\")\n",
    "print(\"-\" * 50)\n",
    "for name, params in attacks.items():\n",
    "    success_rate, avg_pert = evaluate_attack(\n",
    "        model, test_images, test_labels, fgsm_attack, params\n",
    "    )\n",
    "    print(f\"{name:20s} | æˆåŠŸç‡: {success_rate:.1%} | å¹³å‡æ“¾å‹•: {avg_pert:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ¯ ç¸½çµ\n",
    "\n",
    "### æ”»æ“Šæ–¹æ³•æ¯”è¼ƒ\n",
    "\n",
    "| æ–¹æ³• | å„ªé» | ç¼ºé» |\n",
    "|------|------|------|\n",
    "| **FGSM** | å¿«é€Ÿï¼ˆå–®æ¬¡å‰å‘+åå‘ï¼‰| æˆåŠŸç‡è¼ƒä½ |\n",
    "| **PGD** | æ›´å¼·å¤§ã€æ›´å¯é  | è¨ˆç®—è¼ƒæ…¢ |\n",
    "| **C&W** | ç”¢ç”Ÿæœ€å°æ“¾å‹• | éå¸¸æ…¢ |\n",
    "\n",
    "### é˜²ç¦¦æ–¹æ³•\n",
    "\n",
    "| æ–¹æ³• | åŸç† | æ•ˆæœ |\n",
    "|------|------|------|\n",
    "| **Input Transform** | å»é™¤æ“¾å‹• | æœ‰é™ |\n",
    "| **Adversarial Training** | è¨“ç·´æ™‚åŠ å…¥å°æŠ—æ¨£æœ¬ | æœ€æœ‰æ•ˆ |\n",
    "| **Ensemble** | å¤šæ¨¡å‹æŠ•ç¥¨ | å¢åŠ æ”»æ“Šé›£åº¦ |\n",
    "\n",
    "### æå®æ¯… HW10 æŠ€å·§\n",
    "\n",
    "```\n",
    "æ”»æ“Šè¦é»:\n",
    "1. ä½¿ç”¨ PGD å¤šæ¬¡è¿­ä»£\n",
    "2. é©ç•¶çš„ epsilon å’Œ alpha\n",
    "3. ä¸åŒçš„åˆå§‹åŒ–ç­–ç•¥\n",
    "4. çµ„åˆå¤šç¨®æ”»æ“Šæ–¹æ³•\n",
    "\n",
    "é˜²ç¦¦è¦é»:\n",
    "1. Adversarial Training æ˜¯æœ€æœ‰æ•ˆçš„\n",
    "2. çµåˆå¤šç¨®é˜²ç¦¦ç­–ç•¥\n",
    "3. è€ƒæ…®æ”»æ“Šçš„é·ç§»æ€§\n",
    "```\n",
    "\n",
    "### ä¸‹ä¸€æ­¥\n",
    "\n",
    "å‰å¾€ `transfer_adaptation/domain_adaptation.ipynb` å­¸ç¿’åŸŸé©æ‡‰ï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "---\n## ğŸ‹ï¸ ç·´ç¿’\n\n### ç·´ç¿’ 1: æ¯”è¼ƒä¸åŒæ”»æ“Šæ–¹æ³•çš„æˆåŠŸç‡èˆ‡æ“¾å‹•å¤§å°\n\nåœ¨ç›¸åŒçš„ Lâˆ é ç®—ä¸‹ï¼Œæ¯”è¼ƒ FGSMã€PGDï¼ˆä¸åŒè¿­ä»£æ¬¡æ•¸ï¼‰çš„æ”»æ“ŠæˆåŠŸç‡ã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========== ç·´ç¿’ 1: æ¯”è¼ƒä¸åŒæ”»æ“Šæ–¹æ³• ==========\n\ndef experiment_attack_methods(model, image, true_label, epsilon=0.05):\n    \"\"\"\n    æ¯”è¼ƒä¸åŒæ”»æ“Šæ–¹æ³•çš„æ•ˆæœ\n    \"\"\"\n    results = []\n    \n    # FGSM\n    adv_fgsm = fgsm_attack(model, image, true_label, epsilon)\n    with torch.no_grad():\n        pred_fgsm = model(normalize(adv_fgsm)).argmax(1).item()\n    pert_fgsm = (adv_fgsm - image).abs().max().item()\n    results.append({\n        'method': 'FGSM',\n        'success': pred_fgsm != true_label,\n        'perturbation': pert_fgsm,\n        'pred': pred_fgsm\n    })\n    \n    # PGD with different iterations\n    for num_iter in [5, 10, 20, 40]:\n        alpha = epsilon / 4\n        adv_pgd = pgd_attack(model, image, true_label, epsilon, alpha, num_iter)\n        with torch.no_grad():\n            pred_pgd = model(normalize(adv_pgd)).argmax(1).item()\n        pert_pgd = (adv_pgd - image).abs().max().item()\n        results.append({\n            'method': f'PGD-{num_iter}',\n            'success': pred_pgd != true_label,\n            'perturbation': pert_pgd,\n            'pred': pred_pgd\n        })\n    \n    return results\n\n# åŸ·è¡Œå¯¦é©—\nprint(\"ç·´ç¿’ 1: æ¯”è¼ƒä¸åŒæ”»æ“Šæ–¹æ³•\")\nprint(\"=\" * 60)\n\nepsilon = 0.05\nresults = experiment_attack_methods(model, original_tensor, original_pred, epsilon)\n\nprint(f\"\\nåŸå§‹é æ¸¬: {original_pred}\")\nprint(f\"æ“¾å‹•é ç®— (Îµ): {epsilon}\")\nprint(\"-\" * 60)\nprint(f\"{'æ–¹æ³•':<12} | {'æ”»æ“ŠæˆåŠŸ':^10} | {'Lâˆ æ“¾å‹•':^10} | {'æ–°é æ¸¬':^8}\")\nprint(\"-\" * 60)\n\nfor r in results:\n    status = \"âœ“ æˆåŠŸ\" if r['success'] else \"âœ— å¤±æ•—\"\n    print(f\"{r['method']:<12} | {status:^10} | {r['perturbation']:<10.4f} | {r['pred']:^8}\")\n\n# è¦–è¦ºåŒ–\nfig, axes = plt.subplots(1, len(results) + 1, figsize=(16, 3))\n\n# åŸåœ–\naxes[0].imshow(original_tensor.squeeze().permute(1, 2, 0).cpu().numpy())\naxes[0].set_title(f'Original\\nPred: {original_pred}')\naxes[0].axis('off')\n\n# å„æ”»æ“Šæ–¹æ³•\nfor idx, r in enumerate(results):\n    if r['method'] == 'FGSM':\n        adv = fgsm_attack(model, original_tensor, original_pred, epsilon)\n    else:\n        num_iter = int(r['method'].split('-')[1])\n        adv = pgd_attack(model, original_tensor, original_pred, epsilon, epsilon/4, num_iter)\n    \n    axes[idx + 1].imshow(adv.squeeze().permute(1, 2, 0).cpu().numpy())\n    color = 'red' if r['success'] else 'green'\n    axes[idx + 1].set_title(f\"{r['method']}\\nPred: {r['pred']}\", color=color)\n    axes[idx + 1].axis('off')\n\nplt.suptitle(f'Attack Comparison (Îµ={epsilon})', fontsize=12)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nçµè«–ï¼š\")\nprint(\"- FGSM æ˜¯æœ€å¿«çš„ä½†å¯èƒ½æˆåŠŸç‡è¼ƒä½\")\nprint(\"- PGD éš¨è‘—è¿­ä»£æ¬¡æ•¸å¢åŠ é€šå¸¸æ›´æœ‰æ•ˆ\")\nprint(\"- ä½†è¿­ä»£éå¤šå¯èƒ½æ”¶ç›Šéæ¸›\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### ç·´ç¿’ 2: æ¯”è¼ƒä¸åŒé˜²ç¦¦æ–¹æ³•çš„æ•ˆæœ\n\næ¸¬è©¦ JPEG å£“ç¸®ã€é«˜æ–¯æ¨¡ç³Šç­‰è¼¸å…¥è®Šæ›é˜²ç¦¦æ–¹æ³•åœ¨ä¸åŒæ”»æ“Šå¼·åº¦ä¸‹çš„æ•ˆæœã€‚",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ========== ç·´ç¿’ 2: æ¯”è¼ƒä¸åŒé˜²ç¦¦æ–¹æ³• ==========\n\ndef experiment_defense_methods(model, original_image, original_label, epsilons=[0.02, 0.05, 0.1]):\n    \"\"\"\n    æ¯”è¼ƒä¸åŒé˜²ç¦¦æ–¹æ³•åœ¨å„ç¨®æ”»æ“Šå¼·åº¦ä¸‹çš„æ•ˆæœ\n    \"\"\"\n    defense_methods = {\n        'No Defense': lambda x: x,\n        'JPEG-75': lambda x: jpeg_compression(x, quality=75),\n        'JPEG-50': lambda x: jpeg_compression(x, quality=50),\n        'Blur-3': lambda x: gaussian_blur(x, kernel_size=3, sigma=1.0),\n        'Blur-5': lambda x: gaussian_blur(x, kernel_size=5, sigma=2.0),\n    }\n    \n    results = {method: [] for method in defense_methods}\n    \n    for eps in epsilons:\n        # ç”Ÿæˆå°æŠ—æ¨£æœ¬\n        adv_image = pgd_attack(model, original_image, original_label, eps, eps/4, 20)\n        \n        for method_name, defense_fn in defense_methods.items():\n            defended = defense_fn(adv_image)\n            \n            with torch.no_grad():\n                pred = model(normalize(defended)).argmax(1).item()\n            \n            # è¨˜éŒ„æ˜¯å¦æˆåŠŸé˜²ç¦¦ï¼ˆæ¢å¾©åŸé æ¸¬ï¼‰\n            success = (pred == original_label)\n            results[method_name].append(success)\n    \n    return results, epsilons\n\n# åŸ·è¡Œå¯¦é©—\nprint(\"ç·´ç¿’ 2: æ¯”è¼ƒä¸åŒé˜²ç¦¦æ–¹æ³•\")\nprint(\"=\" * 60)\n\nepsilons = [0.02, 0.05, 0.1, 0.15]\nresults, eps_list = experiment_defense_methods(model, original_tensor, original_pred, epsilons)\n\n# ç¹ªè£½çµæœ\nfig, ax = plt.subplots(figsize=(10, 6))\n\nx = np.arange(len(eps_list))\nwidth = 0.15\nmultiplier = 0\n\ncolors = ['#e74c3c', '#3498db', '#2980b9', '#27ae60', '#1abc9c']\n\nfor idx, (method, successes) in enumerate(results.items()):\n    offset = width * multiplier\n    success_rates = [int(s) for s in successes]\n    bars = ax.bar(x + offset, success_rates, width, label=method, color=colors[idx])\n    multiplier += 1\n\nax.set_xlabel('æ”»æ“Šå¼·åº¦ (Îµ)')\nax.set_ylabel('é˜²ç¦¦æˆåŠŸ (1=æˆåŠŸæ¢å¾©åŸé æ¸¬)')\nax.set_title('ä¸åŒé˜²ç¦¦æ–¹æ³•åœ¨å„æ”»æ“Šå¼·åº¦ä¸‹çš„è¡¨ç¾')\nax.set_xticks(x + width * 2)\nax.set_xticklabels([f'Îµ={e}' for e in eps_list])\nax.legend(loc='upper right')\nax.set_ylim(0, 1.2)\nax.axhline(y=1, color='gray', linestyle='--', alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# æ‰“å°ç¸½çµ\nprint(\"\\né˜²ç¦¦æ–¹æ³•ç¸½çµ:\")\nprint(\"-\" * 60)\nprint(f\"{'æ–¹æ³•':<15} | \" + \" | \".join([f'Îµ={e}' for e in eps_list]))\nprint(\"-\" * 60)\nfor method, successes in results.items():\n    success_str = \" | \".join(['âœ“' if s else 'âœ—' for s in successes])\n    print(f\"{method:<15} | {success_str}\")\n\nprint(\"\\nçµè«–ï¼š\")\nprint(\"- è¼ƒå¼·çš„é˜²ç¦¦ï¼ˆå¦‚é«˜å£“ç¸® JPEGã€å¤§æ ¸æ¨¡ç³Šï¼‰å°å¼·æ”»æ“Šæ›´æœ‰æ•ˆ\")\nprint(\"- ä½†éåº¦é˜²ç¦¦å¯èƒ½å½±éŸ¿ä¹¾æ·¨åœ–åƒçš„æº–ç¢ºç‡\")\nprint(\"- éœ€è¦åœ¨å®‰å…¨æ€§å’Œæº–ç¢ºç‡é–“å–å¾—å¹³è¡¡\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}